/* -*- mode: C++; fill-column: 100; c-basic-offset: 4; -*-
 *
 * HOFFMAN - a chess endgame tablebase builder
 *
 * by Brent Baccala
 *
 * begun coding    August 2006
 * last modified   September 2014
 *
 * no rights reserved; you may freely copy, modify, or distribute HOFFMAN
 *
 * written in a mismash of C, C99, C++, and C++11
 *
 * This program is formated for a (minimum) 100 character wide display.
 *
 * INTRODUCTION
 *
 * This program calculates chess tablebases, which are large files containing all possible
 * configurations of chess pieces in an endgame and the best play to either win or draw.  Unlike a
 * conventional chess engine, which uses a heuristic evaluation function, a retrograde engine is
 * almost completely non-heuristic.  When it labels a position as a win, it is because it has
 * considered all possibles lines, be they 10, 20, or 100 moves long, and determined that the win is
 * forced, even with best play by the opposing side.  Some chess-like games, such as the Japanese
 * game Shogi, are not suitable for retrograde analysis because pieces never leave the game
 * (captured pieces in Shogi can be put back into play by the capturing player).  Yet for chess, the
 * frequent reduction of games to positions where only a handful of pieces remain has created an
 * entire subfield of endgame analysis.
 *
 * Systematic analysis of chess endgames dates at least to the ninth century.  Pioneering work in
 * computer retrograde analysis was done in the 1980s by Ken Thompson, of UNIX fame, and
 * S.J. Edwards, but the most popular tablebases today are those generated by a program written by
 * E.V. Nalimov.  Suffice it to say that while Nalimov's program has completely solved all chess
 * endgames with six or fewer pieces remaining, and while Nalimov tablebases are widely available on
 * the Internet, the Nalimov approach of solving an endgame completely results in very slow run
 * times and exceptionally large tablebases.  The K+P+P vs K+P endgame, for example, due to the
 * possibility of all pawns queening, requires the K+Q+Q vs K+Q endgame to be solved before it can
 * be calculated.  The Nalimov kppkp tablebase occupies 64MB; Hoffman's current, less efficient
 * storage scheme requires 225MB for the same tablebase.
 *
 * Hoffman takes a somewhat different approach, one pioneered by Alth√∂fer and Bleicher's Freezer,
 * now a commercial program. When faced with something like K+P+P vs K+P, rather than calculate all
 * possible resulting positions, it may ignore the possibility of more than two pawns queening at
 * the same time, thus computing nothing more complex than K+Q+P vs K+Q.  While incomplete, such a
 * tablebase is nevertheless useful.  For the player with two pawns, if the tablebase discards any
 * move that queens the third pawn and still finds a winning line, then that line is still playable
 * for a win, even though a faster winning line may exist.  From the opposing point of view, if the
 * tablebase treats any position where the third pawn queens as a loss, then the player can be
 * confident that any drawing line can not be improved upon by the superior side.  From a
 * computational perspective, we have reduced the complexity requirements to a point where the
 * calculation can be performed in a reasonable amount of time.  While still too slow for
 * over-the-board use, we now have a useful tool for the analysis of more complex endgames, useful
 * for either static analysis, or for the slow time controls of correspondence games.
 *
 * Hoffman improves upon Freezer with a more sophisticated method of chaining one endgame analysis
 * into another, allowing more realistic modeling of queening combinations and exchanges.  For
 * example, in a bishop vs knight endgame (with pawns), we can (if we wish) analyze first the king
 * and pawn endgame resulting after a trade of the minors, then use this information to analyze a
 * similar set of king vs knight and king vs bishop endgames, and finally combine all this
 * information together to analyze the original endgame.  While the current version of Freezer can
 * only regard the capture of the knight or bishop as a forced win for one side or the other,
 * Hoffman can look through the exchange to determine the result more accurately.
 *
 * Hoffman thus attempts to combine the best of Nalimov and Freezer.  Unlike Freezer, the program is
 * powerful enough to solve any endgame completely (given enough computing resources), reproducing
 * any Nalimov tablebase.  Unlike Nalimov, the program is capable of pruning pawn moves, queening
 * combinations, movement options and exchanges, giving it Freezer's ability to solve complex
 * endgames in a reasonable amount of time.  The exact tradeoff between the two extremes is made
 * using a XML-based configuration that can seem daunting at first, but ultimately offers the user
 * the ability to extensively tailor the program's operation.  Combined with a human being's common
 * sense and chess judgement, it is my hope that this flexibility with ultimately make the program
 * more useful for endgame retrograde analysis than either Nalimov or Freezer.
 *
 * For those not up on Americana, the program is named after Trevor Hoffman, an All Star baseball
 * pitcher who specializes in "closing" games.  It was written specifically for the first
 * chessgames.com The World vs. Arno Nickel game, which was ultimately won by the World team with no
 * help needed from Hoffman.  I resigned from the World team at the end of the second Arno Nickel
 * game when the team agreed to a draw rather than play into a drawish endgame in the hopes of using
 * an early version of Hoffman as the game simplified.
 *
 * I've tried to achieve capability (mostly done) and then speed (still needs a lot of work).
 *
 * Read the tutorial and reference manual, both distributed as PDFs, next.
 *
 * Basic Usage: hoffman -g <xml-control-file>                           (generate mode)
 *              hoffman -v <tablebase> ...                              (verify mode)
 *              hoffman -i <tablebase> ...                              (identify mode)
 *              hoffman -p <tablebase> ...                              (probe mode)
 */

#include "config.h"	/* GNU configure script figures out our build options and writes them here */

#include "version.h"	/* Automatically generated Hoffman_program_version and Hoffman_program_modified */

/* C99 requires a macro to be defined prior to including <inttypes.h> to obtain printf formatting
 * macros PRIu32 and PRIu64.  Under cygwin, however, one of the other include files seems to include
 * <inttypes.h> without this macro set, and the file's protection against multiple inclusion then
 * prevents us from including it again to obtain the needed macros.  Therefore, we set the macro and
 * include <inttypes.h> before almost anything else.
 */

#define __STDC_FORMAT_MACROS
#include <inttypes.h>

#include <algorithm>		/* for std::sort */
#include <deque>
#include <vector>
#include <set>

#include <thread>
#include <atomic>
#include <mutex>
#include <condition_variable>
#include <type_traits>

#include <fstream>
#include <iostream>

#include <boost/lexical_cast.hpp>

#include <boost/algorithm/string.hpp>

#include <boost/iostreams/detail/ios.hpp>  // for failure exception

#include <boost/iostreams/device/file.hpp>
#include <boost/iostreams/device/file_descriptor.hpp>
#include <boost/iostreams/stream.hpp>
#include <boost/iostreams/filtering_stream.hpp>
#include <boost/iostreams/filter/symmetric.hpp>
#include <boost/iostreams/filter/counter.hpp>
#include <boost/iostreams/filter/gzip.hpp>
#include <boost/iostreams/seek.hpp>
#include <boost/iostreams/restrict.hpp>

namespace io = boost::iostreams;

#pragma GCC diagnostic push	/* because libxml++ still uses auto_ptr */
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
#include <libxml++/libxml++.h>
#pragma GCC diagnostic pop

#ifndef _LARGEFILE64_SOURCE
#define _LARGEFILE64_SOURCE	/* because some of our files will require 64-bit offsets */
#endif

#ifndef _GNU_SOURCE
#define _GNU_SOURCE		/* to get strsignal() and FNM_CASEFOLD */
#endif

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <strings.h>
#include <unistd.h>		/* for write(), lseek(), gethostname() */
#include <time.h>		/* for putting timestamps on the output tablebases */
#include <fcntl.h>		/* for O_RDONLY */
#include <netdb.h>		/* for gethostbyname() */
#include <getopt.h>		/* for GNU getopt_long() */

#include <fnmatch.h>		/* for glob matching of pruning statements */

#include <signal.h>		/* so user interrupts and internal errors are reported to the error URL */

#include <sys/time.h>		/* for reporting resource utilization */
#include <sys/resource.h>

#include <errno.h>		/* for errno and strerror() */

#ifdef HAVE_LIBREADLINE
#include <readline.h>		/* The GNU readline library (optional) */
#include <history.h>
#endif

#include "zlib.h"

#include "bitlib.h"

/* Our DTD.  We compile it into the program because we want to validate our input against the
 * version of the DTD that the program was compiled with, not some newer version from the network.
 */

#include "tablebase_dtd.h"

#ifdef USE_SMALL_INDICES
typedef uint32_t index_t;
#define PRIindex PRIu32
#define INVALID_INDEX UINT32_MAX
#else
typedef uint64_t index_t;
#define PRIindex PRIu64
#define INVALID_INDEX UINT64_MAX
#endif

unsigned int num_threads = 1;

/***** GLOBAL CONSTANTS *****/

/* Maximum number of pieces; used to simplify various arrays
 *
 * Since this includes frozen as well as mobile pieces, "16" may seem absurd, but it's probably
 * about right.  4 fully mobile pieces are easily doable in memory.  5 mobiles can often be done in
 * memory if you use either symmetry or a machine with lots of RAM.  6 mobiles requires sweeping
 * passes across a file on disk.  7 or more mobiles are only doable with severe restrictions on the
 * movements of the pieces.
 */

#define MAX_PIECES 16

/* Maximum number of possibilities for pawn promotions (see promotion_possibilities below). */

#define MAX_PROMOTION_POSSIBILITIES 5

/* seven possible pieces: KQRBNP; 64 possible squares, up to 8 directions per piece, up to 7
 * movements in one direction
 */

#define NUM_PIECES 6
#define NUM_SQUARES 64
#define NUM_DIR 8
#define NUM_MOVEMENTS 7

/* Variables for gathering statistics */

std::atomic<uint64_t> total_legal_positions(0);
std::atomic<uint64_t> total_PNTM_mated_positions(0);
std::atomic<uint64_t> total_stalemate_positions(0);
std::atomic<uint64_t> total_moves(0);
std::atomic<uint64_t> total_futuremoves(0);
uint64_t total_backproped_moves = 0;
std::atomic<uint64_t> player_wins[2] {ATOMIC_VAR_INIT(0), ATOMIC_VAR_INIT(0)};
int max_dtm = 0;
int min_dtm = 0;

/* How we were called - XXX hardwired max */
char options_string[256];

struct timeval program_start_time;
struct timeval program_end_time;

unsigned int progress_dots = 100;

/* per-pass statistics */

int total_passes = 0;
int max_passes = 0;

const char ** pass_type = nullptr;
int * pass_target_dtms = nullptr;

std::atomic<int> positions_finalized_this_pass;
std::vector<int> positions_finalized;

std::atomic<uint64_t> backproped_moves_this_pass;
std::vector<uint64_t> backproped_moves;

/* If we're generating a DTM tablebase, then we make a series of passes, one for each DTM value in
 * the tablebase.  A DTM 15 position, for example, won't get finalised until the DTM 15 pass, which
 * ensures that if a better mate (say DTM 12) appears, it will change the position into a DTM 12.
 *
 * How, you might wonder, could a DTM 15 position appear except from the DTM -14 pass?  Futurebases.
 * Furthermore, we don't want to waste time running passes for DTM values that don't appear at all,
 * so we track DTMs, mainly during futurebase backpropagation, keeping a record of which DTM values
 * have been seen, and skipping passes entirely for non-existent DTM values.
 *
 * If we're generating a bitbase (no DTM metric), we don't delay finalising a position, since all
 * wins are equivalent.
 */

bool tracking_dtm = true;   // XXX should clear this variable if we're generating a bitbase
int min_tracked_dtm = -2;
int max_tracked_dtm = 2;
bool * positive_passes_needed = nullptr;
bool * negative_passes_needed = nullptr;


/***** C++ TEMPLATE TRICKS *****/

/* dynamic_cast'ing a pointer returns nullptr if the cast fails, but usually I want an exception
 * instead.  exception_cast<Type> works just like dynamic_cast<Type> except that it throws an
 * exception instead of returning nullptr.
 */

template<typename T, typename P>
T exception_cast(P p) {
    T val;
    val = dynamic_cast<T>(p);
    if (val == nullptr) throw new std::bad_cast();
    else return val;
}

/* dereferencing a pointer type passed as a template argument
 *
 * Usage: dereference<TypePtr>::type will be the type that TypePtr points to
 */

template<typename> struct dereference;

template <typename T>
struct dereference<T*> {
    typedef T type;
};

template <typename T>
struct dereference<std::shared_ptr<T>> {
    typedef T type;
};

/* Java-like synchronized classes
 *
 * An object of type synchronized<Class> will be just like an object of type Class, except that it
 * comes with a mutex and can be locked.
 */

template <class T>
class synchronized : public T, public std::mutex { };


/***** DATA STRUCTURES *****/

/* From Guru of The Week #29 [http://www.gotw.ca/gotw/029.htm]
 *
 * The key here is to understand what a "string" actually is in standard C++. If you look in your
 * trusty string header, you'll see something like this:
 *
 *  typedef basic_string<char> string;
 *
 * So string isn't really a class... it's a typedef of a template...
 *
 * basic_string supplies useful comparison functions that let you compare whether a string is equal
 * to another, less than another, and so on...
 *
 * If we want these to behave differently, all we have to do is provide a different char_traits
 * template!
 *
 */

/* Hmmm... modifying char_traits sounds interesting, but I'm using Glib::ustring because that's what
 * glib++ uses to get UTF-8 strings, and Glib::ustring doesn't use char_traits.  What it's got
 * instead is a casefold() method that "returns a caseless representation of the UTF-8 string.  The
 * resulting string doesn't correspond to any particular case, therefore the result is only useful
 * to compare strings and should never be displayed to the user."
 */

/* Class 'bimap' is used for converting from strings in the XML to integer flags, but sometimes we
 * need to convert a flag back to a string.  The crazy "using" statement is a C++11-ism to inherit
 * the constructor.
 */

/* XXX use templates for this! */

struct casefold_compare {
    bool operator() (const Glib::ustring a, const Glib::ustring b) const {
	return a.casefold() < b.casefold();
    }
};

class bimap : public std::map<Glib::ustring, int, casefold_compare> {
public:
    using std::map<Glib::ustring, int, casefold_compare>::map;
    Glib::ustring operator[] (int value)
    {
	for (auto it = begin(); it != end(); it++) {
	    if (it->second == value) return it->first;
	}
	// XXX this isn't consistent with std::map usage
	return nullptr;
    }
};

struct casefold_compare2 {
    bool operator() (const std::string a, const std::string b) const {
	return boost::ilexicographical_compare(a, b);
    }
};

class bimap2 : public std::map<std::string, int, casefold_compare2> {
public:
    using std::map<std::string, int, casefold_compare2>::map;
    const char * operator[] (int value)
    {
	for (auto it = begin(); it != end(); it++) {
	    if (it->second == value) return it->first.c_str();
	}
	return nullptr;
    }
};

/* Sometimes we want to catch and rethrow an exception after adding some information to it.
 * nested_exception does this, but imperfectly.  First, it carries around a pointer to the inner
 * exception; it'd be nice to make a copy of it, but we can't do this without knowing more about its
 * type.  So we keep a pointer to an object that could evaporate at any time, but probably won't be
 * destroyed until after we've dealt with the nested exception, then the inner exception will be
 * destroyed.  The most important thing we do with the exception is print a message.
 *
 * What I'd really like is to inherit from the actual class of the inner exception, but I see no way
 * of doing this without knowing the inner class at compile time.  Then a higher level exception
 * handler would see that nested_exception, or maybe nested_exception<std::bad_alloc>, can be caught
 * as a std::bad_alloc.  Writing a templated nested_exception<T> is easy, but how to use it?
 *
 * It's important to catch the exception by value, too.  Example usage:
 *
 *	try {
 *	    output_proptable = new proptable(format, proptable_MBs << 20);
 *	} catch (std::exception& ex) {
 *	    throw nested_exception("Constructing output_proptable", ex);
 *	}
 *
 * See: http://stackoverflow.com/questions/6755991/catching-stdexception-by-reference
 */

class nested_exception : public std::exception {
    std::exception * exp;
    std::string msg;
public:
    nested_exception(std::string msg) : msg(msg), exp(nullptr) { }
    nested_exception(std::string msg, std::exception &ex) : msg(msg + ":  " + ex.what()), exp(&ex) { }

    const char * what() const throw() { return msg.c_str(); }
};

/* Colors */

#define WHITE 0
#define BLACK 1

bimap colors = {{"WHITE", WHITE}, {"BLACK", BLACK}};

/* Futuremoves are moves like captures and promotions that lead to a different tablebase.
 * 'futurevectors' are bit vectors used to track which futuremoves have been handled in a particular
 * position.  They are of type futurevector_t, and the primary operations used to construct them are
 * FUTUREVECTOR(move) to get a futurevector with a bit set in move's position, and
 * FUTUREVECTORS(move,n) to get a futurevector with n bits set starting with move, although the
 * actual tables are now stored in a more compact format that only uses as many bits as are needed
 * for the particular tablebase being generated.
 */

typedef uint32_t futurevector_t;
#define get_futurevector_t_field get_uint32_t_field
#define set_futurevector_t_field set_uint32_t_field
#define FUTUREVECTOR_HEX_FORMAT "0x%" PRIx32
#define FUTUREVECTOR(move) (1ULL << (move))
#define FUTUREVECTORS(move, n) (((1ULL << (n)) - 1) << (move))
#define NO_FUTUREMOVE -1
#define DISCARD_FUTUREMOVE -2
#define CONCEDE_FUTUREMOVE -3
#define RESIGN_FUTUREMOVE -4

/* These arrays hold the bit locations in the futurevector of various posible futuremoves -
 * captures, capture-promotions, promotions, and normal movements of a piece to all 64 squares.  The
 * values are either a bit location (starting at 0), or one of four negative numbers: -1 means that
 * the move in question isn't a futuremove in the given tablebase (for example, promotion of a
 * non-pawn, or movement of a piece to a legal square) and that any attempt to assign that
 * futuremove is therefore an error.  -2 means that no futurebase exists for the futuremove, and
 * that a 'discard' pruning statement exists for it, so the futuremove can be immediately discarded
 * when it is encountered during initialization.  -3 means that no futurebase exists and a 'concede'
 * pruning statement is present, so the futuremove results in an immediate win during
 * initialization.  -4 means that no futurebase exists and a 'resign' pruning statement is present
 * (useful only for suicide analysis), resulting in an immediate lose during initialization.
 *
 * XXX We don't actually have a 'resign' option on a prune statement, but RESIGN_FUTUREMOVE is used
 * implicitly if a player's last piece is captured in a suicide analysis.
 *
 * num_futuremoves[WHITE] and num_futuremoves[BLACK] are the total number of futurevector bits
 * assigned for each color, NOT the total number of possible futuremoves, since futuremoves can be
 * multiply assigned to bits (if two futuremoves can't both happen from the same position, they can
 * be safely assigned to the same bit), or completely pruned with a -2, -3, or -4 (no bit position).
 *
 * There is one place in the code (propagate_moves_from_promotion_futurebase) that assumes that the
 * piece ordering in the last array index of promotions and promotion_captures matches the piece
 * ordering in piece_name and piece_char.
 */

unsigned int num_futuremoves[2] = {0, 0};
int futurecaptures[MAX_PIECES][MAX_PIECES];
int promotion_captures[MAX_PIECES][MAX_PIECES][MAX_PROMOTION_POSSIBILITIES];
int promotions[MAX_PIECES][MAX_PROMOTION_POSSIBILITIES];
int futuremoves[MAX_PIECES][64];

/* XXX hardwired 100 futuremove max per color here */
#define MOVESTR_CHARS 16
char movestr[2][100][MOVESTR_CHARS];

/* Pairs of futurevectors (one for each color) indicating which futuremoves have been pruned by
 * either conceding or discarding them.  pruned_futuremoves = conceded_futuremoves |
 * discarded_futuremoves, and unpruned_futuremoves = ~pruned_futuremoves.  optimized_futuremoves
 * indicates futuremoves that have been flagged for optimization, as they have no futurebases that
 * could match them and can thus be handled during initialization.
 */

futurevector_t pruned_futuremoves[2] = {0, 0};
futurevector_t unpruned_futuremoves[2] = {0, 0};
futurevector_t conceded_futuremoves[2] = {0, 0};
futurevector_t discarded_futuremoves[2] = {0, 0};
futurevector_t optimized_futuremoves[2] = {0, 0};

/* position - the data structures that represents a board position
 *
 * There are two kinds of positions: local and global.  Locals are faster but are tied to a specific
 * tablebase.  Globals are more general and are used for probing.
 *
 * Both types use a 64-bit board_vector with one bit for each board position, in addition to a flag
 * to indicate which side is to move and the en passant capture square (or -1 if no en passant
 * capture is possible).  We use board_vector to easily check if possible moves are legal by looking
 * for pieces that block our moving piece.  This is done during futurebase propagation, during
 * intratable propagation, and during initialization.  It could be used to check if en passant
 * positions are legal (are the two squares behind the pawn blocked or not), but that is problematic
 * now because the board_vector isn't correct at the point where we need to make that check.
 *
 * Local positions use numbers (0-63) indicating the positions of the pieces, and also have a quick
 * way to check captures using a PTM_vector (pieces of the Player to Move).  You have to look into
 * the tablebase structure to figure out what piece corresponds to each number.  PTM_vector is only
 * used during tablebase initialization and in the probe code.  During initialization, we consider
 * captures to determine if they're legal moves, or pruned moves, so we might set one piece position
 * to ILLEGAL_POSITION.
 *
 * It makes sense to include these vectors in the position structures because it's easiest to
 * compute them in the routines that convert indices to positions, but if you alter the position,
 * then they get out of sync, and its tempting to just leave them that way because you rarely need
 * them to be right at that point.  This really came back to haunt me when implementing en passant.
 *
 * "Multiplicity" is used in conjunction with symmetric indices, and indicates the actual number of
 * board positions that corresponds to this one.
 *
 * Global positions contain an 8x8 unsigned char array with ASCII characters representing each
 * piece.
 *
 * Sometimes I allow the board and PTM vectors to get out of sync with the position (for speed).
 * This can be a problem, so it has to be done really carefully.
 *
 * We don't worry about moving a piece that's pinned on our king, for example.  The resulting
 * position will already have been flagged illegal in the table.
 *
 */

#define BITVECTOR(square) (1ULL << (square))

/* pawn can't be on the first or last eight squares of the board */
#define ALL_ONES_BITVECTOR   0xffffffffffffffffLL
#define LEGAL_PAWN_BITVECTOR 0x00ffffffffffff00LL

/* XXX use a custom type for piece positions */
const uint8_t ILLEGAL_POSITION = 0xff;

/* XXX only needed here for the friend declaration below */
struct translation_result;

/* XXX these friends use tablebase_t and local_position_t, which haven't been defined yet. */

class tablebase_t;
class local_position_t;

/* XXX initialize local_position meaningfully so we can drop a lot of these friends */

template<typename primative>
class ReadOnly {
    friend local_position_t;
    friend class index_encoding;
    friend class naive_index;
    friend class naive2_index;
    friend class simple_index;
    friend class compact_index;
    friend class combinadic_index;

    friend void normalize_position(const tablebase_t *, local_position_t *);
    friend index_t normalized_position_to_index(const tablebase_t *, local_position_t *);
    friend bool index_to_local_position(const tablebase_t *tb, index_t index, int reflection, local_position_t *position);
    friend int check_1000_positions(tablebase_t *);
    friend translation_result translate_foreign_position_to_local_position(tablebase_t *foreign_tb, local_position_t *foreign_position,
									   tablebase_t *local_tb, local_position_t *local_position,
									   bool invert_colors);
    friend translation_result global_position_to_local_position(tablebase_t *tb, struct global_position *global, local_position_t *local);
    friend bool place_piece_in_local_position(tablebase_t *tb, local_position_t *pos, int square, int color, int type);
    friend bool parse_FEN_to_local_position(char *, tablebase_t *, local_position_t *);

public:
    inline operator primative() const                 { return x; }
    //ReadOnly() { }
    //ReadOnly(const primative x) : x(x) { }

protected:
    template<typename number> inline number operator= (const number& y) { return x = y; }
    template<typename number> inline number operator+=(const number& y) { return x += y; }
    template<typename number> inline number operator&=(const number& y) { return x &= y; }
    template<typename number> inline number operator|=(const number& y) { return x |= y; }
    primative x;
};

class local_position_t {

    const tablebase_t *tb;

public:

    /* decoded - Does the structure accurately decode the index/reflection?
     *
     * 'decoded' can be set even for indices that decode to invalid positions.  The 'valid' flag
     * indicates if the position decodes to a valid position, i.e, if index_to_local_position()
     * returns true for this index.  Calling index_to_local_position() on an index that decodes to
     * an invalid position will return false and produce a local_position with 'decoded' true,
     * 'valid' false, and 'index'/'reflection' set to the requested values.
     *
     * How do we handle reflections?  Store a copy of the unreflected positions along with a flag
     * (unreflected_valid) that indicates if the position calculation was valid up to the point
     * where we apply reflections.  Reflections are always requested serially on a single position.
     *
     * Permutations to normalize semilegal groups?
     */

    bool decoded = false;
    bool unreflected_valid;
    bool valid;
    index_t index;
    int pawngen_index;
    index_t pawngen_base_index;
    int reflection;

    ReadOnly<uint64_t> board_vector;
    ReadOnly<uint64_t> PTM_vector;
    //std::array<ReadOnly<uint8_t>, MAX_PIECES> piece_position = {{ILLEGAL_POSITION}};
    std::array<ReadOnly<uint8_t>, MAX_PIECES> unreflected_piece_position;
    std::array<ReadOnly<uint8_t>, MAX_PIECES> piece_position;
    std::array<ReadOnly<uint8_t>, MAX_PIECES> permuted_piece;
    ReadOnly<uint8_t> side_to_move;
    ReadOnly<uint8_t> unreflected_en_passant_square;
    ReadOnly<uint8_t> en_passant_square;
    ReadOnly<uint8_t> multiplicity;

    local_position_t(const tablebase_t *tb) : tb(tb) { }

    /* I go to the trouble to update board_vector here so we can check en passant legality in
     * propagate_one_move_within_table().
     *
     * XXX Should we update PTM_vector?
     */

    void move_piece(int piece, int destination_square);

    void place_piece(int piece, int destination_square) {
	if (piece_position[piece] != ILLEGAL_POSITION) {
	    throw nested_exception("Attempted to place_piece that was already placed");
	}
	piece_position[piece] = destination_square;
	board_vector |= BITVECTOR(piece_position[piece]);
	decoded = false;
    };

    void capture_piece(int capturing_piece, int captured_piece) {
	board_vector &= ~BITVECTOR(piece_position[capturing_piece]);
	piece_position[capturing_piece] = piece_position[captured_piece];
	piece_position[captured_piece] = ILLEGAL_POSITION;
	decoded = false;
    };

    void uncapture_piece(int capturing_piece, int captured_piece, int square) {
	piece_position[captured_piece] = piece_position[capturing_piece];
	piece_position[capturing_piece] = square;
	board_vector |= BITVECTOR(square);
	decoded = false;
    }

    void swap_pieces(int piece1, int piece2) {
	std::swap(piece_position[piece1], piece_position[piece2]);
    }

    void flip_side_to_move(void);

    void clear_en_passant_square(void)
    {
	if (en_passant_square != ILLEGAL_POSITION) {
	    en_passant_square = ILLEGAL_POSITION;
	    decoded = false;
	}
    }

    void set_en_passant_square(int square)
    {
	en_passant_square = square;
	decoded = false;
    }

};

/* This is a global position, that doesn't depend on a particular tablebase.  It's slower to
 * manipulate, but is suitable for probing tablebases.  Each char in the array is either 0 for an
 * empty square, and one of the FEN characters for a chess piece.
 */

typedef struct global_position {
    unsigned char board[64];
    short side_to_move;
    short en_passant_square;
    short variant;
} global_position_t;




#define REFLECTION_NONE 0
#define REFLECTION_HORIZONTAL 1
#define REFLECTION_VERTICAL 2
#define REFLECTION_DIAGONAL 4
#define REFLECTION_COLOR 8

/* tablebase - the data structure used to hold tablebases
 *
 * WHITE and BLACK are also used for the side_to_move variable in the position type above
 */

#define KING 0
#define QUEEN 1
#define ROOK 2
#define BISHOP 3
#define KNIGHT 4
#define PAWN 5

bimap2 piece_name = {{"KING", KING}, {"QUEEN", QUEEN}, {"ROOK", ROOK},
		    {"BISHOP", BISHOP}, {"KNIGHT", KNIGHT}, {"PAWN", PAWN}};

const char piece_char[NUM_PIECES+1] = {'K', 'Q', 'R', 'B', 'N', 'P', 0};

unsigned char global_pieces[2][NUM_PIECES] = {{'K', 'Q', 'R', 'B', 'N', 'P'},
					      {'k', 'q', 'r', 'b', 'n', 'p'}};

/* Possibilities for pawn promotions.  "2" means queen and knight, but that can cause some problems,
 * as I've learned the hard (and embarrassing) way.  "4" is typical, but "5" is used for suicide
 * analysis, where promotion to king is allowed.
 */

int promotion_possibilities = 4;
int promoted_pieces[] = {QUEEN, ROOK, BISHOP, KNIGHT, KING};


/* Hoffman uses "dynamic structures" extensively, for its entries and proptable arrays.  A dynamic
 * structure is one whose bit layout is specified at run time by the XML control file.  Since we
 * can't use standard C structures (they require bit layouts to be set at compile time), we've got
 * to jump through hoops.  A lot of this is handled by 'bitlib'.
 *
 * Does it slow down the program?  You bet.  But for larger tablebases, which are disk bound and not
 * CPU bound, this actually speeds things up by giving us the flexibility of setting structure
 * layouts based on the needs of individual tablebases, and not having to use generic structures
 * big enough to accommodate every possibility.
 *
 * A 'struct format' gives the layout of such a dynamic structure.
 */

struct format {
    int bits;
    int dtm_offset;
    int dtm_bits;
    int flag_offset;
    int flag_type;
    int basic_offset;
};

#define FORMAT_FIELD_DTM 0
#define FORMAT_FIELD_FLAG 1
#define FORMAT_FIELD_BASIC 2

bimap format_fields = {{"dtm", FORMAT_FIELD_DTM}, {"flag", FORMAT_FIELD_FLAG}, {"basic", FORMAT_FIELD_BASIC}};

#define FORMAT_FLAG_NONE 0
#define FORMAT_FLAG_WHITE_WINS 1
#define FORMAT_FLAG_WHITE_DRAWS 2

bimap format_flag_types = {{"white-wins", FORMAT_FLAG_WHITE_WINS}, {"white-draws", FORMAT_FLAG_WHITE_DRAWS}};

#define MAX_FORMAT_BYTES 16

/* This is the "one-byte-dtm" format */

struct format one_byte_dtm_format = {8, 0,8, -1,FORMAT_FLAG_NONE, -1};
struct format dtm_format = {0, 0,0, -1,FORMAT_FLAG_NONE, -1};


/* tablebase_t
 *
 * The 'xml' in the tablebase is authoritative; much of the other info is extracted from it
 * for efficiency.
 *
 * To make this work for either white or black positions, let's adopt the notation PTM (Player to
 * move) and PNTM (Player not to move)
 *
 * 'movecnt' is is the number of moves FORWARD from this position that haven't been analyzed yet,
 * with the high bit (128) set if PTM is in check.
 *
 * 'dtm' (Distance to Mate) is the number of moves required to force a mate.  It is positive
 * for a PTM mate and negative for a PNTM mate.
 *
 * Now PTM can mate with even a single move out of a position, so a postive dtm means PTM mates.
 * PNTM can only mate if PTM has no possible move that leads to mate, so a negative dtm coupled with
 * a 0 or 128 movecnt means PNTM mates.
 *
 * So, if we backtrace from a single PTM WINS, then this position becomes PTM WINS.  If we backtrace
 * from PNTM WINS, we decrement movecnt and adjust dtm to the lowest value (the slowest mate).  If
 * movecnt reaches 0 or 128, then the position becomes PNTM WINS.  When we're all done backtracing
 * possible wins, anything left with a non-zero movecnt, or a zero dtm, is a DRAW.
 *
 * We also need a mate-in count and a stalemate (conversion) count.
 *
 */

#define RESTRICTION_NONE 0
#define RESTRICTION_DISCARD 1
#define RESTRICTION_CONCEDE 2

bimap restriction_types = {{"NONE", RESTRICTION_NONE}, {"DISCARD", RESTRICTION_DISCARD}, {"CONCEDE", RESTRICTION_CONCEDE}};

#define FORMAT_FOURBYTE 0
#define FORMAT_ONE_BYTE_DTM 1

bimap formats = {{"fourbyte", FORMAT_FOURBYTE}, {"one-byte-dtm", FORMAT_ONE_BYTE_DTM}};

#define NAIVE_INDEX 0
#define NAIVE2_INDEX 1
#define SIMPLE_INDEX 2
#define COMPACT_INDEX 3
#define NO_EN_PASSANT_INDEX 4
#define COMBINADIC3_INDEX 5
#define COMBINADIC4_INDEX 6
#define PAWNGEN_INDEX 7

#define DEFAULT_INDEX COMBINADIC4_INDEX

bimap index_types = {{"naive", NAIVE_INDEX}, {"naive2", NAIVE2_INDEX}, {"simple", SIMPLE_INDEX},
		     {"compact", COMPACT_INDEX}, {"no-en-passant", NO_EN_PASSANT_INDEX},
		     {"combinadic3", COMBINADIC3_INDEX}, {"combinadic4", COMBINADIC4_INDEX},
		     {"pawngen", PAWNGEN_INDEX}};

#define FUTUREBASE_CAPTURE 0
#define FUTUREBASE_PROMOTION 1
#define FUTUREBASE_CAPTURE_PROMOTION 2
#define FUTUREBASE_NORMAL 3

bimap futurebase_types = 
    {{"capture", FUTUREBASE_CAPTURE}, {"promotion", FUTUREBASE_PROMOTION},
     {"capture-promotion", FUTUREBASE_CAPTURE_PROMOTION}, {"normal", FUTUREBASE_NORMAL}};

#define VARIANT_NORMAL 0
#define VARIANT_SUICIDE 1

std::map<Glib::ustring, int> variant_names =
    {{"", VARIANT_NORMAL}, {"normal", VARIANT_NORMAL}, {"suicide", VARIANT_SUICIDE}};

struct piece {

    short piece_type;
    short color;

    /* Pieces can restricted according to which squares they are allowed to move on.
     *
     * Legal squares are just that - squares that a piece is allowed to be on.
     *
     * Semilegal squares are squares that might be legal for a given piece, but we can't be sure
     * until we've considered other pieces in the position as well.  This becomes a factor when
     * we've got multiple identical pieces with overlapping, non-identical move restrictions.
     * Consider, for example, a tablebase with two rooks: one unrestricted, the other restricted to
     * its back rank.  Let's say we're moving a rook off the back rank.  If the other rook is on the
     * back rank, then the move is legal.  If the other rook is somewhere else, then the move would
     * be illegal.  So we make the entire board "semilegal" for both rooks, process the move
     * normally, and only when it's time to convert the entire position to an index in the tablebase
     * do we actually decide if the position is fully legal.
     *
     * Semilegal groups are groups of pieces with the same color and type, and the same semilegal
     * squares.  For each piece type of each color, semilegal groups partition the board.  If two
     * otherwise identical pieces have move restrictions that don't overlap (so they can't exchange
     * places), then they're in different semilegal groups.
     */

    Glib::ustring location;
    uint64_t legal_squares;
    uint64_t semilegal_squares;
    int prev_piece_in_semilegal_group;
    int next_piece_in_semilegal_group;

    int blocking_piece;

    int color_symmetric_transpose;

    int *permutations;

    /* For each square on the board and piece in the futurebase, record the first piece in the
     * corresponding local semilegal group.  Unlike the previous variables, this one isn't
     * initialized when the instance is created, but rather in compute_extra_and_missing_pieces()
     * when a futurebase is being translated.
     */

    int matching_local_semilegal_group[64];

    piece(short color, short type, uint64_t legal_squares = ALL_ONES_BITVECTOR)
	: color(color), piece_type(type), legal_squares(legal_squares) {}
    piece(xmlpp::Node *);
};

int eval_to_number_or_zero(xmlpp::Node *node, std::string xpath);

class index_encoding;
struct pawngen;

class tablebase_t {
public:
    /* I want an xmlpp::DomParser instance variable, to hold the tablebase's associated XML
     * structures, like this:
     *
     * xmlpp::DomParser parser;
     *
     * Unfortunately, xmlpp::DomParser is NonCopyable and libxml++ 2.6 doesn't implement C++11 move
     * semantics, so this would make tablebase objects non-movable and non-copyable, creating
     * problems putting them in an array.
     *
     * I use a unique_ptr to get around this.  It's ugly, but the net result is a xmlpp::DomParser
     * that is attached to each tablebase, movable, and cleanly destroyed.
     */

    std::unique_ptr<xmlpp::DomParser> parser = std::unique_ptr<xmlpp::DomParser>(new xmlpp::DomParser);
    xmlpp::Document * xml;

    int variant;
    int index_type;
    index_t num_indices;
    bool positions_with_adjacent_kings_are_illegal;
    int symmetry;
    uint8_t reflections[64][64];

    std::unique_ptr<struct pawngen> pawngen;
    std::unique_ptr<index_encoding> encoding;

    /* white_king and black_king are the piece numbers of the two kings */

    int white_king;
    int black_king;

    struct format format;

    index_t fetch_entry(index_t index);
    int get_DTM(index_t index);
    bool get_flag(index_t index);
    unsigned int get_basic(index_t index);

    /* for futurebases only */
    Glib::ustring filename;
    std::unique_ptr<io::filtering_istream> instream;

    int futurebase_type;
    index_t next_read_index;
    off_t offset;
    int max_dtm;
    int min_dtm;
    bool invert_colors;
    int extra_piece;
    int missing_pawn;
    int missing_non_pawn;
    int promotion;

    /* Pieces */

    int num_pieces;
    short num_pieces_by_color[2];
    std::vector<piece> pieces;

    uint64_t frozen_pieces_vector;

    bool encode_stm;

    int prune_enable[2];		/* one for each color */
    int stalemate_prune_type;		/* only RESTRICTION_NONE (0) or RESTRICTION_CONCEDE (2) allowed */
    int stalemate_prune_color;

    char *futurevectors;
    int futurevector_bits;

    bool is_color_symmetric(void);

    tablebase_t(void) : offset(0), invert_colors(false), num_pieces(0) { }
    tablebase_t(std::istream *);
    tablebase_t(Glib::ustring);

    //tablebase(const tablebase &) = delete;

private:
    void parse_pawngen_element(xmlpp::Node *);
    void parse_XML(std::istream *);

};

tablebase_t *current_tb = nullptr;

std::vector<tablebase_t> futurebases;
int num_futurebases;

bool using_proptables = false;		/* Proptables (see below) */
bool compress_proptables = false;
bool compress_entries_table = false;
size_t proptable_MBs = 0;

xmlpp::Element * generation_statistics;

xmlpp::Element * completion_time;
xmlpp::Element * user_time;
xmlpp::Element * system_time;
xmlpp::Element * real_time;
xmlpp::Element * page_faults;
xmlpp::Element * page_reclaims;


/* PROPTABLE_BITS for 16 byte entries:
 *
 * 8 = 256 entries = 4KB (testing)
 * 16 = 64K entries (what I've been using)
 * 20 = 1M entries = 16MB
 * 24 = 16M entries = 256MB
 */

#define LOCK_MEMORY 0

int verbose = 1;

/* Use '-d' option to set debug_move to an index in the current tablebase, or the negative of an
 * index in a futurebase to print more verbose debugging information about what the program is doing
 * to process a single move.
 *
 * XXX Use a custom type for index_t that allows something like INVALID_INDEX to always compare
 * false, then debug_move can be made a const INVALID_INDEX to remove its code without using the
 * preprocessor.
 */

index_t debug_move = INVALID_INDEX;
index_t debug_futuremove = INVALID_INDEX;
#define DEBUG_MOVE debug_move
#define DEBUG_FUTUREMOVE debug_futuremove


/***** UTILITY FUNCTIONS *****/

/* printing_progress_dots is used to indicate that we're in the middle of printing a line of progress
 * dots, so a text message of any kind should be prefixed with a newline.
 */

int fatal_errors = 0;

std::atomic<bool> printing_progress_dots(false);

#define MAX_FATAL_ERRORS 10

 __attribute__((noreturn)) void terminate (void)
{

    if (fatal_errors > 0) {
	exit(EXIT_FAILURE);
    } else {
	exit(EXIT_SUCCESS);
    }
}

void fatal (const char * format, ...)
{
    va_list va;

    /* BREAKPOINT */
    if (index(format, '\n')) fatal_errors ++;

    if (printing_progress_dots) {
	fputc('\n', stderr);
	printing_progress_dots = false;
    }

    va_start(va, format);
    vfprintf(stderr, format, va);
    va_end(va);

    if (fatal_errors >= MAX_FATAL_ERRORS) terminate();
}

void warning (const char * format, ...)
{
    va_list va;

    if (printing_progress_dots) {
	fputc('\n', stderr);
	printing_progress_dots = false;
    }

    va_start(va, format);
    fputs("WARNING: ", stderr);
    vfprintf(stderr, format, va);
    va_end(va);
}

void info (const char * format, ...)
{
    va_list va;

    if (printing_progress_dots) {
	fputc('\n', stderr);
	printing_progress_dots = false;
    }

    va_start(va, format);
    if (verbose) vfprintf(stderr, format, va);
    va_end(va);
}

/* We aim to print progress_dots progress dots as we move through a tablebase.  That means one
 * progress dot every tb->num_indices/progress_dots indices.  We keep an internal count of how many
 * times this routine gets called, expecting it to be called once for each index in the tablebase.
 * I also take care to precompute next_target_index to avoid division every time this routine gets
 * called.
 */

void print_progress_dot(tablebase_t *tb, bool reset)
{
    static std::atomic<unsigned int> progress_dots_printed(0);
    static std::atomic<index_t> indices_processed(0);
    static std::atomic<index_t> next_target_index(0);

    if (progress_dots > 0) {

	if (reset) {
	    progress_dots_printed = 0;
	    indices_processed = 0;
	    next_target_index = tb->num_indices / progress_dots;
	    return;
	}

	if ((++ indices_processed) == next_target_index) {

	    if (! printing_progress_dots) {
		for (auto i=1U; i <= progress_dots_printed; i++) {
		    fputc(' ', stderr);
		}
	    }
	    fputc('.', stderr);
	    printing_progress_dots = true;
	    progress_dots_printed ++;

	    next_target_index = tb->num_indices * (progress_dots_printed + 1) / progress_dots;
	}
    }

}

void print_progress_dot(tablebase_t *tb)
{
    print_progress_dot(tb, false);
}

void reset_progress_dots(tablebase_t *tb)
{
    print_progress_dot(tb, true);
}

void sigaction_user_interrupt (int signal, siginfo_t * siginfo, void * ucontext)
{
    fatal("Interrupted by user\n");
    terminate();
}

void sigaction_internal_error (int signal, siginfo_t * siginfo, void * ucontext)
{
    fatal("Internal error: %s at 0x%08x\n", strsignal(signal), siginfo->si_addr);
    terminate();
}

int ROW(int square) {
    return square / 8;
}

int COL(int square) {
    return square % 8;
}

inline int rowcol2square(int row, int col)
{
    return (col + row*8);
}

/* diagonal_reflection() flips along the a1/h8 diagonal by simply interchanging the row and column */

int diagonal_reflection(int square)
{
    return rowcol2square(COL(square), ROW(square));
}

int horizontal_reflection(int square)
{
    return rowcol2square(ROW(square), 7-COL(square));
}

int vertical_reflection(int square)
{
    return rowcol2square(7-ROW(square), COL(square));
}

void subtract_timeval(struct timeval *dest, struct timeval *src)
{
    dest->tv_sec -= src->tv_sec;
    if (dest->tv_usec >= src->tv_usec) {
	dest->tv_usec -= src->tv_usec;
    } else {
	dest->tv_usec = 1000000 + dest->tv_usec - src->tv_usec;
	dest->tv_sec --;
    }
}

void add_timeval(struct timeval *dest, struct timeval *src)
{
    dest->tv_sec += src->tv_sec;
    dest->tv_usec += src->tv_usec;
    if (dest->tv_usec >= 1000000) {
	dest->tv_usec -= 1000000;
	dest->tv_sec ++;
    }
}

void sprint_timeval(char *strbuf, struct timeval *timevalp)
{
    if (timevalp->tv_sec < 60) {
	sprintf(strbuf, "%ld.%03lds", timevalp->tv_sec, timevalp->tv_usec/1000);
    } else if (timevalp->tv_sec < 3600) {
	sprintf(strbuf, "%ldm%02ld.%03lds", timevalp->tv_sec/60, timevalp->tv_sec%60,
		timevalp->tv_usec/1000);
    } else if (timevalp->tv_sec < 24*3600) {
	sprintf(strbuf, "%ldh%02ldm%02ld.%03lds", timevalp->tv_sec/3600,
		(timevalp->tv_sec/60)%60, timevalp->tv_sec%60, timevalp->tv_usec/1000);
    } else {
	sprintf(strbuf, "%ldd%02ldh%02ldm%02ld.%03lds",
		timevalp->tv_sec/(24*3600), (timevalp->tv_sec/3600)%24,
		(timevalp->tv_sec/60)%60, timevalp->tv_sec%60, timevalp->tv_usec/1000);
    }
}

void fprint_system_time(void)
{
    struct rusage rusage;
    char strbuf[256];

    getrusage(RUSAGE_SELF, &rusage);
    sprint_timeval(strbuf, &rusage.ru_stime);
    fprintf(stderr, "System time: %s\n", strbuf);
}

void expand_per_pass_statistics(void)
{
    if (max_passes == 0) max_passes = 100;
    else max_passes *= 2;

    pass_type = (const char **) realloc(pass_type, max_passes * sizeof(const char *));
    pass_target_dtms = (int *) realloc(pass_target_dtms, max_passes * sizeof(int));
    positions_finalized.resize(max_passes, 0);
    backproped_moves.resize(max_passes, 0);

    /* not all of these arrays are cumulative, but just zero them all to be on the safe size */
    bzero(pass_type + total_passes, (max_passes-total_passes)*sizeof(char *));
    bzero(pass_target_dtms + total_passes, (max_passes-total_passes)*sizeof(int));
}

/***** MOVEMENT VECTORS *****/

/* The idea here is to calculate piece movements, and to do it FAST.
 *
 * We build a table of "movements" organized into "directions".  Each direction is just that - the
 * direction that a piece (like a queen) moves.  When we want to check for what movements are
 * possible in a given direction, we run through the direction until we "hit" another pieces - until
 * the bit in the vector matches something already in the position vector.  At the end of the
 * direction, an all-ones vector will "hit" the end of the board and end the direction.  I know,
 * kinda confusing.  It's because it's designed to be fast; we have to do this a lot.
 */

struct movement {
    uint64_t vector;
    short square;
};

/* we add one to NUM_MOVEMENTS to leave space at the end for the all-ones bitmask that signals the
 * end of the list
 */

struct movement movements[NUM_PIECES][NUM_SQUARES][NUM_DIR][NUM_MOVEMENTS+1];

/* Pawns are, of course, special.  We have seperate vectors for different types of pawn movements.
 * Each array is indexed first by square number, then by side (WHITE or BLACK - this doesn't exist
 * for other pieces), then by the number of possibilities (at most two normal movements, at most two
 * captures, and one more for the all-ones bitvector to terminate)
 *
 * All of these are FORWARD motions.
 */

struct movement normal_pawn_movements[NUM_SQUARES][2][3];
struct movement capture_pawn_movements[NUM_SQUARES][2][3];

struct movement normal_pawn_movements_bkwd[NUM_SQUARES][2][3];
struct movement capture_pawn_movements_bkwd[NUM_SQUARES][2][3];

/* How many different directions can each piece move in?  Knights have 8 directions because they
 * can't be blocked in any of them.  Pawns are handled separately.
 */

int number_of_movement_directions[NUM_PIECES] = {8,8,4,4,8,0};
int maximum_movements_in_one_direction[NUM_PIECES] = {1,7,7,7,1,0};

enum {RIGHT, LEFT, UP, DOWN, DIAG_UL, DIAG_UR, DIAG_DL, DIAG_DR, KNIGHTmove}
movementdir[5][8] = {
    {RIGHT, LEFT, UP, DOWN, DIAG_UL, DIAG_UR, DIAG_DL, DIAG_DR},	/* King */
    {RIGHT, LEFT, UP, DOWN, DIAG_UL, DIAG_UR, DIAG_DL, DIAG_DR},	/* Queen */
    {RIGHT, LEFT, UP, DOWN},						/* Rook */
    {DIAG_UL, DIAG_UR, DIAG_DL, DIAG_DR},				/* Bishop */
    {KNIGHTmove, KNIGHTmove, KNIGHTmove, KNIGHTmove, KNIGHTmove, KNIGHTmove, KNIGHTmove, KNIGHTmove},	/* Knights are special... */
};



char algebraic_notation[64][3];

void init_movements()
{
    int square, piece, dir, mvmt, color;

    for (square=0; square < NUM_SQUARES; square++) {
	algebraic_notation[square][0] = 'a' + square%8;
	algebraic_notation[square][1] = '1' + square/8;
	algebraic_notation[square][2] = '\0';
    }

    for (piece=KING; piece <= KNIGHT; piece++) {

	for (square=0; square < NUM_SQUARES; square++) {

	    for (dir=0; dir < number_of_movement_directions[piece]; dir++) {

		int current_square = square;

		for (mvmt=0; mvmt < maximum_movements_in_one_direction[piece]; mvmt ++) {

		    bool RIGHT_MOVEMENT_POSSIBLE = ((current_square%8)<7);
		    bool RIGHT2_MOVEMENT_POSSIBLE = ((current_square%8)<6);
		    bool LEFT_MOVEMENT_POSSIBLE = ((current_square%8)>0);
		    bool LEFT2_MOVEMENT_POSSIBLE = ((current_square%8)>1);
		    bool UP_MOVEMENT_POSSIBLE = (current_square<56);
		    bool UP2_MOVEMENT_POSSIBLE = (current_square<48);
		    bool DOWN_MOVEMENT_POSSIBLE = (current_square>7);
		    bool DOWN2_MOVEMENT_POSSIBLE = (current_square>15);

		    switch (movementdir[piece][dir]) {
		    case RIGHT:
			if (RIGHT_MOVEMENT_POSSIBLE) {
			    current_square++;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case LEFT:
			if (LEFT_MOVEMENT_POSSIBLE) {
			    current_square--;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case UP:
			if (UP_MOVEMENT_POSSIBLE) {
			    current_square+=8;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case DOWN:
			if (DOWN_MOVEMENT_POSSIBLE) {
			    current_square-=8;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case DIAG_UL:
			if (LEFT_MOVEMENT_POSSIBLE && UP_MOVEMENT_POSSIBLE) {
			    current_square+=8;
			    current_square--;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case DIAG_UR:
			if (RIGHT_MOVEMENT_POSSIBLE && UP_MOVEMENT_POSSIBLE) {
			    current_square+=8;
			    current_square++;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case DIAG_DL:
			if (LEFT_MOVEMENT_POSSIBLE && DOWN_MOVEMENT_POSSIBLE) {
			    current_square-=8;
			    current_square--;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case DIAG_DR:
			if (RIGHT_MOVEMENT_POSSIBLE && DOWN_MOVEMENT_POSSIBLE) {
			    current_square-=8;
			    current_square++;
			    movements[piece][square][dir][mvmt].square = current_square;
			    movements[piece][square][dir][mvmt].vector = BITVECTOR(current_square);
			} else {
			    movements[piece][square][dir][mvmt].square = -1;
			    movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;
			}
			break;
		    case KNIGHTmove:
			current_square=square;
			switch (dir) {
			case 0:
			    if (RIGHT2_MOVEMENT_POSSIBLE && UP_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square + 2 + 8;
				movements[piece][square][dir][0].vector = BITVECTOR(square + 2 + 8);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 1:
			    if (RIGHT2_MOVEMENT_POSSIBLE && DOWN_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square + 2 - 8;
				movements[piece][square][dir][0].vector = BITVECTOR(square + 2 - 8);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 2:
			    if (LEFT2_MOVEMENT_POSSIBLE && UP_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square - 2 + 8;
				movements[piece][square][dir][0].vector = BITVECTOR(square - 2 + 8);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 3:
			    if (LEFT2_MOVEMENT_POSSIBLE && DOWN_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square - 2 - 8;
				movements[piece][square][dir][0].vector = BITVECTOR(square - 2 - 8);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 4:
			    if (RIGHT_MOVEMENT_POSSIBLE && UP2_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square + 1 + 16;
				movements[piece][square][dir][0].vector = BITVECTOR(square + 1 + 16);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 5:
			    if (RIGHT_MOVEMENT_POSSIBLE && DOWN2_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square + 1 - 16;
				movements[piece][square][dir][0].vector = BITVECTOR(square + 1 - 16);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 6:
			    if (LEFT_MOVEMENT_POSSIBLE && UP2_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square - 1 + 16;
				movements[piece][square][dir][0].vector = BITVECTOR(square - 1 + 16);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			case 7:
			    if (LEFT_MOVEMENT_POSSIBLE && DOWN2_MOVEMENT_POSSIBLE) {
				movements[piece][square][dir][0].square = square - 1 - 16;
				movements[piece][square][dir][0].vector = BITVECTOR(square - 1 - 16);
				movements[piece][square][dir][1].square = -1;
				movements[piece][square][dir][1].vector = ALL_ONES_BITVECTOR;
			    } else {
				movements[piece][square][dir][0].square = -1;
				movements[piece][square][dir][0].vector = ALL_ONES_BITVECTOR;
			    }
			    break;
			}
			break;

		    }
		}

		/* Always put an ALL_ONES_BITVECTOR at the end of the movement vector
		 * to make sure we stop!
		 */

		movements[piece][square][dir][mvmt].square = -1;
		movements[piece][square][dir][mvmt].vector = ALL_ONES_BITVECTOR;

	    }
	}
    }

    /* Now for the pawns... */

    for (square=0; square < NUM_SQUARES; square ++) {

	for (color = WHITE; color <= BLACK; color ++) {

	    int forwards_pawn_move = ((color == WHITE) ? 8 : -8);
	    int backwards_pawn_move = ((color == WHITE) ? -8 : 8);

	    /* Forward pawn movements
	     *
	     * An ordinary pawn move... unless its a white pawn on the second rank, or a black
	     * pawn on the seventh.  In these two cases, there is a possible double move as
	     * well.
	     */

	    mvmt = 0;

	    if ((ROW(square) >= 1) && (ROW(square) <= 6)) {

		normal_pawn_movements[square][color][mvmt].square = square + forwards_pawn_move;
		normal_pawn_movements[square][color][mvmt].vector = BITVECTOR(square + forwards_pawn_move);

		mvmt ++;
	    }

	    if (((color == WHITE) && (ROW(square) == 1)) || ((color == BLACK) && (ROW(square) == 6))) {

		normal_pawn_movements[square][color][mvmt].square = square + 2*forwards_pawn_move;
		normal_pawn_movements[square][color][mvmt].vector = BITVECTOR(square + 2*forwards_pawn_move);

		mvmt ++;

	    }

	    normal_pawn_movements[square][color][mvmt].square = -1;
	    normal_pawn_movements[square][color][mvmt].vector = ALL_ONES_BITVECTOR;

	    /* Backwards pawn movements */

	    mvmt = 0;

	    if (((color == WHITE) && (ROW(square) > 1)) || ((color == BLACK) && (ROW(square) < 6))) {

		normal_pawn_movements_bkwd[square][color][mvmt].square = square + backwards_pawn_move;
		normal_pawn_movements_bkwd[square][color][mvmt].vector = BITVECTOR(square + backwards_pawn_move);
		mvmt ++;
	    }

	    if (((color == WHITE) && (ROW(square) == 3)) || ((color == BLACK) && (ROW(square) == 4))) {

		normal_pawn_movements_bkwd[square][color][mvmt].square = square + 2*backwards_pawn_move;
		normal_pawn_movements_bkwd[square][color][mvmt].vector = BITVECTOR(square + 2*backwards_pawn_move);
		mvmt ++;
	    }

	    normal_pawn_movements_bkwd[square][color][mvmt].square = -1;
	    normal_pawn_movements_bkwd[square][color][mvmt].vector = ALL_ONES_BITVECTOR;

	    /* Forward pawn captures. */

	    mvmt = 0;

	    if ((ROW(square) >= 1) && (ROW(square) <= 6)) {

		if (COL(square) > 0) {

		    capture_pawn_movements[square][color][mvmt].square
			= square + forwards_pawn_move - 1;
		    capture_pawn_movements[square][color][mvmt].vector
			= BITVECTOR(square + forwards_pawn_move - 1);

		    mvmt ++;

		}

		if (COL(square) < 7) {

		    capture_pawn_movements[square][color][mvmt].square
			= square + forwards_pawn_move + 1;
		    capture_pawn_movements[square][color][mvmt].vector
			= BITVECTOR(square + forwards_pawn_move + 1);

		    mvmt ++;

		}
	    }

	    capture_pawn_movements[square][color][mvmt].square = -1;
	    capture_pawn_movements[square][color][mvmt].vector = ALL_ONES_BITVECTOR;

	    /* Backwards pawn captures */

	    mvmt = 0;

	    if (((color == WHITE) && (ROW(square) > 1)) || ((color == BLACK) && (ROW(square) < 6))) {

		if (COL(square) > 0) {

		    capture_pawn_movements_bkwd[square][color][mvmt].square
			= square + backwards_pawn_move - 1;
		    capture_pawn_movements_bkwd[square][color][mvmt].vector
			= BITVECTOR(square + backwards_pawn_move - 1);

		    mvmt ++;

		}

		if (COL(square) < 7) {

		    capture_pawn_movements_bkwd[square][color][mvmt].square
			= square + backwards_pawn_move + 1;
		    capture_pawn_movements_bkwd[square][color][mvmt].vector
			= BITVECTOR(square + backwards_pawn_move + 1);

		    mvmt ++;

		}
	    }

	    capture_pawn_movements_bkwd[square][color][mvmt].square = -1;
	    capture_pawn_movements_bkwd[square][color][mvmt].vector = ALL_ONES_BITVECTOR;

	}

    }

}

/* This routine is pretty fast, so I just call it once every time the program runs.  It has to be
 * used after any changes to the code above to verify that those complex movement vectors are
 * correct, or at least consistent.  We're using this in a game situation.  We can't afford bugs in
 * this code.
 */

void verify_movements()
{
    int piece;
    int squareA, squareB;
    int dir;
    int color;
    struct movement * movementptr;
    int pawn_option;

    /* For everything except pawns, if it can move from A to B, then it better be able to move from
     * B to A...
     */

    for (piece=KING; piece <= KNIGHT; piece ++) {

	for (squareA=0; squareA < NUM_SQUARES; squareA ++) {

	    for (squareB=0; squareB < NUM_SQUARES; squareB ++) {

		int movement_possible = 0;
		int reverse_movement_possible = 0;

		/* check for possible self-movement, if A and B are the same square */

		if (squareA == squareB) {
		    for (dir = 0; dir < number_of_movement_directions[piece]; dir++) {
			for (movementptr = movements[piece][squareA][dir];
			     (movementptr->vector & BITVECTOR(squareB)) == 0;
			     movementptr++) ;
			if ((movementptr->square != -1) || (movementptr->vector != ALL_ONES_BITVECTOR)) {
			    fatal("Self movement possible!? %s %d %d\n",
				  piece_name[piece], squareA, movementptr->square);
			}
		    }
		    continue;
		}

		/* check for possible A to B move */

		for (dir = 0; dir < number_of_movement_directions[piece]; dir++) {

		    for (movementptr = movements[piece][squareA][dir];
			 (movementptr->vector & BITVECTOR(squareB)) == 0;
			 movementptr++) {
			if ((movementptr->square < 0) || (movementptr->square >= NUM_SQUARES)) {
			    fatal("Bad movement square: %s %d %d %d\n",
				  piece_name[piece], squareA, squareB, movementptr->square);
			}
		    }

		    if (movementptr->square == -1) {
			if (movementptr->vector != ALL_ONES_BITVECTOR) {
			    fatal("-1 movement lacks ALL_ONES_BITVECTOR: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
		    } else if ((movementptr->square < 0) || (movementptr->square >= NUM_SQUARES)) {
			fatal("Bad movement square: %s %d %d\n", piece_name[piece], squareA, squareB);
		    } else {
			if (movementptr->square != squareB) {
			    fatal("bitvector does not match destination square: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
			if (movement_possible) {
			    fatal("multiple idential destinations from same origin: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
			movement_possible = 1;
			if (movementptr->vector == ALL_ONES_BITVECTOR) {
			    fatal("ALL_ONES_BITVECTOR on a legal movement: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
		    }
		}


		for (dir = 0; dir < number_of_movement_directions[piece]; dir++) {

		    for (movementptr = movements[piece][squareB][dir];
			 (movementptr->vector & BITVECTOR(squareA)) == 0;
			 movementptr++) ;

		    if (movementptr->square != -1) reverse_movement_possible=1;
		}


		if (movement_possible && !reverse_movement_possible) {
		    fatal("reverse movement impossible: %s %d %d\n", piece_name[piece], squareA, squareB);
		}

	    }
	}
    }

    /* Pawns are special */

    piece = PAWN;

    for (pawn_option = 0; pawn_option < 4; pawn_option ++) {

	struct movement * fwd_movement;
	struct movement * rev_movement;

	for (color = WHITE; color <= BLACK; color ++) {

	    /* fprintf(stderr, "Pawn option %d; color %s\n", pawn_option, colors[color]); */

	    for (squareA=0; squareA < NUM_SQUARES; squareA ++) {

		for (squareB=0; squareB < NUM_SQUARES; squareB ++) {

		    int movement_possible = 0;
		    int reverse_movement_possible = 0;

		    switch (pawn_option) {
		    case 0:
			fwd_movement = normal_pawn_movements[squareA][color];
			rev_movement = normal_pawn_movements_bkwd[squareB][color];
			break;
		    case 1:
			fwd_movement = normal_pawn_movements_bkwd[squareA][color];
			rev_movement = normal_pawn_movements[squareB][color];
			break;
		    case 2:
			fwd_movement = capture_pawn_movements[squareA][color];
			rev_movement = capture_pawn_movements_bkwd[squareB][color];
			break;
		    case 3:
			fwd_movement = capture_pawn_movements_bkwd[squareA][color];
			rev_movement = capture_pawn_movements[squareB][color];
			break;
		    default:
			fatal("Internal error: pawn_option not in [0,3]");
			return;
		    }

		    /* check for self-movement */

		    if (squareA == squareB) {
			for (movementptr = fwd_movement;
			     (movementptr->vector & BITVECTOR(squareB)) == 0;
			     movementptr++) ;
			if ((movementptr->square != -1) || (movementptr->vector != ALL_ONES_BITVECTOR)) {
			    fatal("Self movement possible!? PAWN %d %d\n", squareA, movementptr->square);
			}
		    }

		    /* check for possible A to B move */

		    for (movementptr = fwd_movement;
			 (movementptr->vector & BITVECTOR(squareB)) == 0;
			 movementptr++) {
			if ((movementptr->square < 0) || (movementptr->square >= NUM_SQUARES)) {
			    fatal("Bad movement square: %s %d %d %d\n",
				  piece_name[piece], squareA, squareB, movementptr->square);
			}
		    }

		    if (movementptr->square == -1) {
			if (movementptr->vector != ALL_ONES_BITVECTOR) {
			    fatal("-1 movement lacks ALL_ONES_BITVECTOR: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
		    } else if ((movementptr->square < 0) || (movementptr->square >= NUM_SQUARES)) {
			fatal("Bad movement square: %s %d %d\n", piece_name[piece], squareA, squareB);
		    } else {
			if (movementptr->square != squareB) {
			    fatal("bitvector does not match destination square: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
			if (movement_possible) {
			    fatal("multiple idential destinations from same origin: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
			movement_possible = 1;
			if (movementptr->vector == ALL_ONES_BITVECTOR) {
			    fatal("ALL_ONES_BITVECTOR on a legal movement: %s %d %d\n",
				  piece_name[piece], squareA, squareB);
			}
		    }


		    /* check for possible B to A reverse move */

		    for (movementptr = rev_movement;
			 (movementptr->vector & BITVECTOR(squareA)) == 0;
			 movementptr++) ;

		    if (movementptr->square != -1) reverse_movement_possible=1;

		    if (movement_possible && !reverse_movement_possible) {
			fatal("reverse movement impossible: %s %d %d\n",
			      piece_name[piece], squareA, squareB);
		    }
		}
	    }
	}
    }
}


/***** PAWNGEN *****/

/* Although early versions of hoffman included a Perl script to generate a complex set of
 * interrelated tablebases resulting from a starting pawn position, it was Pedro P√©rez Moreno's
 * program "finalgen" that really pioneered the analysis of endgames in this manner.
 *
 * The <pawngen/> element takes a starting pawn position and generates a table of all possible pawn
 * positions that can result from it.  For typical endgame scenarios with half a dozen pawns
 * or so, this results in a manageable table with a few thousand entries.  Pawn positions
 * are encoded using this table, and the other pieces are encoded separately.
 *
 * Because hoffman requires the number, type, and color of pieces to be fixed for each tablebase,
 * the <pawngen/> element specifies the number of pawns of each color allowed.  Multiple tablebases
 * must be chained together using <futurebase/> elements to completely analyze a pawngen position.
 * For example, given a position with 3 pawns on each side, and both kppkp and kpppk available as
 * futurebases, we'd first compute three tablebases for the four pawn configurations (3 vs 1, 2 vs
 * 2, 1 vs 3), then back propagate into two tablebases for the five pawn configurations (3 vs 2 and
 * 2 vs 3), then finally back propagate into a single tablebase for the six pawn configurations,
 * that would include the original position.
 *
 * Pawn captures simply lead to another pawngen futurebase (i.e, 3 vs 2 leads into 3 vs 1 and 2 vs
 * 2), but what about piece captures?  Attributes on the <pawngen/> element specify how many pieces
 * of each color are allowed to be captured, and additional pawn positions are generated to account
 * for those capture moves.  For example, a 3 vs 2 position that includes a rook would require
 * futurebases for 3 vs 1 and 2 vs 2 (each with the rook present), as well as a 3 vs 2 futurebase
 * without the rook, but with a "captures-allowed" attribute on the pawngen element.
 *
 * Likewise, we wish to consider queening combinations.  In this case, queens are not "allowed", but
 * actually "required", since we need not consider positions where a pawn has not yet advanced to
 * the back rank.  So, continuing the example above, we'd also want a 3 vs 1 futurebase with a queen
 * required, as well as a 2 vs 2 futurebase with a queen of the opposite color required.
 *
 * If the resulting positions are too complicated to analyze, prune elements can be used to handle
 * the queens and/or captures.
 *
 * Currently, there are some restrictions.  No non-pawngen pawns are allowed, and encoding groups
 * are computed according to where the pawngen element appears in the piece list, but the index is
 * always encoded with the pawn index in the most significant bits.
 */

int white_pawns_required = 0;
int black_pawns_required = 0;

/* pawn_position - tracks a single placement of pawns on the board, without other pieces
 *
 * Will be used to form into two std::sets that track valid_pawn_positions and
 * invalid_pawn_positions, ordered by the default operators.  operator<, in particular, is somewhat
 * slow.  The valid_pawn_positions will be sorted into two std::vectors, pawn_positions_by_position
 * (ordered by pawn_position_fast_compare) and pawn_positions_by_index (ordered by the standard
 * operators).
 */

class pawn_position {

    friend bool operator< (const pawn_position & LHS, const pawn_position & RHS);
    friend bool operator== (const pawn_position & LHS, const pawn_position & RHS);
    friend bool pawn_position_fast_compare (const pawn_position & LHS, const pawn_position & RHS);

    uint64_t white_pawns = 0;
    uint64_t black_pawns = 0;

    int total_white_pawns = 0;
    int total_black_pawns = 0;

public:

    int white_pawn_captures_black_piece_allowed = 0;
    int black_pawn_captures_white_piece_allowed = 0;

    int white_queens_required = 0;
    int black_queens_required = 0;

    int en_passant_square = ILLEGAL_POSITION;

    /* These next variables are computed from prior information to speed access. */

    int index;
    uint8_t position[MAX_PIECES];
    int en_passant_pawn;

    uint8_t prev_position[MAX_PIECES];
    int delta_pawngen_index[MAX_PIECES];

    bool valid(void) const
    {
	return ((white_queens_required == 0) && (black_queens_required == 0) &&
		(total_white_pawns == white_pawns_required) && (total_black_pawns == black_pawns_required));
    }

    bool white_pawn_at (int square) const
    {
	return (white_pawns & (1ULL << square));
    }

    void remove_white_pawn(int square)
    {
	white_pawns &= ~(1ULL << square);
	total_white_pawns --;
    }

    void add_white_pawn(int square)
    {
	white_pawns |= (1ULL << square);
	total_white_pawns ++;
    }

    bool black_pawn_at(int square) const
    {
	return (black_pawns & (1ULL << square));
    }

    void remove_black_pawn(int square)
    {
	black_pawns &= ~(1ULL << square);
	total_black_pawns --;
    }

    void add_black_pawn(int square)
    {
	black_pawns |= (1ULL << square);
	total_black_pawns ++;
    }

    bool pawn_at(int square) const
    {
	return white_pawn_at(square) || black_pawn_at(square);
    }

};

/* Comparison operator for pawn position.
 *
 * We want to order pawn positions so that later pawn positions depend only on early ones, and also
 * so that we can easily tell how many board squares are occupied by pawns.
 *
 * We order first by total number of pawns, then by number of white pawns on the 2nd rank, then 3rd,
 * up to 7th, then by number of black pawns on the 7th rank, then 6th, down to 2nd, then by any
 * remaining differences.
 *
 * Any capture will reduce the total number of pawns and thus lead to a smaller index.
 *
 * Any pawn move will reduce the number of pawns on a rank earlier in the sort order, and thus lead
 * to a smaller index.
 *
 * XXX We might want to group en passant positions together, because they don't need the
 * side-to-move flag encoded, as the side-to-move is always the opposite color of the en passant
 * pawn.
 *
 * XXX We might want a second, faster comparison operator to use when searching for a particular
 * position after the index numbers have been assigned.
 */

/* bit count of the number of bits in a 8-bit number */

class pawns_on_rank_class : public std::array<short, 256>
{
public:
    pawns_on_rank_class()
    {
	for (int i=0; i < 256; i++) {
	    int bits = 0;
	    for (int bit=0; bit < 7; bit ++) {
		if (i & (1 << bit)) bits++;
	    }
	    at(i) = bits;
	}
    }
} pawns_on_rank;

bool operator< (const pawn_position & LHS, const pawn_position & RHS)
{
    if ((LHS.total_white_pawns + LHS.total_black_pawns) != (RHS.total_white_pawns + RHS.total_black_pawns)) {
	return ((LHS.total_white_pawns + LHS.total_black_pawns) < (RHS.total_white_pawns + RHS.total_black_pawns));
    } else {
	for (int rank = 2; rank <= 7; rank ++) {
	    auto LHS_white_rank_pawns = pawns_on_rank[(LHS.white_pawns >> 8*(rank-1)) & 0xff];
	    auto RHS_white_rank_pawns = pawns_on_rank[(RHS.white_pawns >> 8*(rank-1)) & 0xff];
	    if (LHS_white_rank_pawns != RHS_white_rank_pawns) {
		return (LHS_white_rank_pawns < RHS_white_rank_pawns);
	    }
	}
	for (int rank = 7; rank >= 2; rank --) {
	    auto LHS_black_rank_pawns = pawns_on_rank[(LHS.black_pawns >> 8*(rank-1)) & 0xff];
	    auto RHS_black_rank_pawns = pawns_on_rank[(RHS.black_pawns >> 8*(rank-1)) & 0xff];
	    if (LHS_black_rank_pawns != RHS_black_rank_pawns) {
		return (LHS_black_rank_pawns < RHS_black_rank_pawns);
	    }
	}
    }

    if (LHS.white_pawns != RHS.white_pawns) {
	return (LHS.white_pawns < RHS.white_pawns);
    }

    if (LHS.black_pawns != RHS.black_pawns) {
	return (LHS.black_pawns < RHS.black_pawns);
    }

    return LHS.en_passant_square < RHS.en_passant_square;
}

bool operator== (const pawn_position & LHS, const pawn_position & RHS)
{
    return ((LHS.white_pawns == RHS.white_pawns) &&
	    (LHS.black_pawns == RHS.black_pawns) &&
	    (LHS.en_passant_square == RHS.en_passant_square));
}

bool operator!= (const pawn_position & LHS, const pawn_position & RHS)
{
    return !(LHS == RHS);
}

bool pawn_position_fast_compare (const pawn_position & LHS, const pawn_position & RHS)
{
    if (LHS.white_pawns != RHS.white_pawns) {
	return LHS.white_pawns < RHS.white_pawns;
    } else if (LHS.black_pawns != RHS.black_pawns) {
	return LHS.black_pawns < RHS.black_pawns;
    } else {
	return LHS.en_passant_square < RHS.en_passant_square;
    }
}

/* Recursively compute all possible pawn positions that can arise from a starting position.
 *
 * Pawns can always be captured by a piece.  They can always move forward and can always capture
 * each other.  They can only queen if required to, and can only capture a piece if allowed to.
 *
 * The two std::sets here are global variables, but are only used when a tablebase's indexing
 * function is being computed.  The resulting information is stored in tablebase_t's std::vector
 * pawn_positions.  These std::sets are then clear()ed, so they can be used again to compute another
 * tablebase's indexing function.
 */

std::set<pawn_position> valid_pawn_positions;
std::set<pawn_position> invalid_pawn_positions;

struct pawngen {
    std::vector<pawn_position> pawn_positions_by_position;
    std::vector<pawn_position> pawn_positions_by_index;
};

void process_pawn_position(class pawn_position position)
{
    std::pair<std::set<pawn_position>::iterator,bool> ret;

    if (position.valid()) {
	ret = valid_pawn_positions.insert(position);
    } else {
	ret = invalid_pawn_positions.insert(position);
    }

    if (! ret.second) return;

    for (int square=0; square < 64; square ++) {

	/* White pawns */

	if (position.white_pawn_at(square)) {
	    pawn_position position2 = position;

	    /* Remove pawn (captured by piece), and reuse position2 with pawn removed */
	    position2.remove_white_pawn(square);
	    position2.en_passant_square = ILLEGAL_POSITION;
	    process_pawn_position(position2);

	    /* Queen it if queens are required */
	    if (square >= 48 && position2.white_queens_required) {
		pawn_position position3 = position2;
		position3.white_queens_required --;
		process_pawn_position(position3);
	    }

	    if (square < 48) {
		/* Move forward if unblocked */
		if (! position2.pawn_at(square + 8)) {
		    pawn_position position3 = position2;

		    position3.add_white_pawn(square + 8);
		    process_pawn_position(position3);
		}

		/* Left pawn capture */
		if ((square % 8) != 0) {
		    if (position2.black_pawn_at(square + 8 - 1)) {
			pawn_position position3 = position2;
			position3.remove_black_pawn(square + 8 - 1);
			position3.add_white_pawn(square + 8 - 1);
			process_pawn_position(position3);
		    } else if (position2.white_pawn_captures_black_piece_allowed
			       && !position2.white_pawn_at(square + 8 - 1)) {
			pawn_position position3 = position2;
			position3.add_white_pawn(square + 8 - 1);
			position3.white_pawn_captures_black_piece_allowed --;
			process_pawn_position(position3);
		    }
		}

		/* Right pawn capture */
		if ((square % 8) != 7) {
		    if (position2.black_pawn_at(square + 8 + 1)) {
			pawn_position position3 = position2;
			position3.remove_black_pawn(square + 8 + 1);
			position3.add_white_pawn(square + 8 + 1);
			process_pawn_position(position3);
		    } else if (position2.white_pawn_captures_black_piece_allowed
			       && !position2.white_pawn_at(square + 8 + 1)) {
			pawn_position position3 = position2;
			position3.add_white_pawn(square + 8 + 1);
			position3.white_pawn_captures_black_piece_allowed --;
			process_pawn_position(position3);
		    }
		}
	    }

	    /* En passant movement */
	    if (square < 16) {
		if (! position2.pawn_at(square + 8) && ! position2.pawn_at(square + 16)) {
		    if ((square != 8) && (position2.black_pawn_at(square + 16 - 1))
			|| (square != 15) && (position2.black_pawn_at(square + 16 + 1))) {
			position2.add_white_pawn(square + 16);
			position2.en_passant_square = square + 8;
			process_pawn_position(position2);
		    }
		}
	    }
	}

	/* Ditto for black pawns */

	if (position.black_pawn_at(square)) {
	    pawn_position position2 = position;
	    position2.remove_black_pawn(square);
	    position2.en_passant_square = ILLEGAL_POSITION;
	    process_pawn_position(position2);

	    if (square < 16 && position2.black_queens_required) {
		pawn_position position3 = position2;
		position3.black_queens_required --;
		process_pawn_position(position3);
	    }
	    if (square >= 16) {
		if (! position2.pawn_at(square - 8)) {
		    pawn_position position3 = position2;
		    position3.add_black_pawn(square - 8);
		    process_pawn_position(position3);
		}
		if ((square % 8) != 0) {
		    if (position2.white_pawn_at(square - 8 - 1)) {
			pawn_position position3 = position2;
			position3.remove_white_pawn(square - 8 - 1);
			position3.add_black_pawn(square - 8 - 1);
			process_pawn_position(position3);
		    } else if (position2.black_pawn_captures_white_piece_allowed
			       && !position2.black_pawn_at(square - 8 - 1)) {
			pawn_position position3 = position2;
			position3.add_black_pawn(square - 8 - 1);
			position3.black_pawn_captures_white_piece_allowed --;
			process_pawn_position(position3);
		    }
		}
		if ((square % 8) != 7) {
		    if (position.white_pawn_at(square - 8 + 1)) {
			pawn_position position3 = position2;
			position3.remove_white_pawn(square - 8 + 1);
			position3.add_black_pawn(square - 8 + 1);
			process_pawn_position(position3);
		    } else if (position2.black_pawn_captures_white_piece_allowed
			       && !position2.black_pawn_at(square - 8 + 1)) {
			pawn_position position3 = position2;
			position3.add_black_pawn(square - 8 + 1);
			position3.black_pawn_captures_white_piece_allowed --;
			process_pawn_position(position3);
		    }
		}
	    }
	    if (square >= 48) {
		if (! position2.pawn_at(square - 8) && ! position2.pawn_at(square - 16)) {
		    if ((square != 48) && (position2.white_pawn_at(square - 16 - 1))
			|| (square != 55) && (position2.white_pawn_at(square - 16 + 1))) {
			position2.add_black_pawn(square - 16);
			position2.en_passant_square = square - 8;
			process_pawn_position(position2);
		    }
		}
	    }
	}
    }
}

void tablebase_t::parse_pawngen_element(xmlpp::Node * xml)
{
    pawn_position initial_position;

    for (short color = WHITE; color <= BLACK; color ++) {

	Glib::ustring location;
	int j = 0;

	if (color == WHITE) {
	    location = xml->eval_to_string("@white-pawn-locations");
	} else {
	    location = xml->eval_to_string("@black-pawn-locations");
	}

	while ((location[j] >= 'a') && (location[j] <= 'h')
	       && (location[j+1] >= '1') && (location[j+1] <= '8')) {
	    int square = rowcol2square(location[j+1] - '1', location[j] - 'a');

	    if (color == WHITE) {
		initial_position.add_white_pawn(square);
	    } else {
		initial_position.add_black_pawn(square);
	    }

	    j += 2;
	    while (location[j] == ' ') j ++;
	}

	if (location[j] != '\0') {
	    fatal("Illegal pawn location (%s)\n", location.c_str());
	}
    }

    white_pawns_required = eval_to_number_or_zero(xml, "@white-pawns-required");
    black_pawns_required = eval_to_number_or_zero(xml, "@black-pawns-required");

    initial_position.white_queens_required = eval_to_number_or_zero(xml, "@white-queens-required");
    initial_position.black_queens_required = eval_to_number_or_zero(xml, "@black-queens-required");

    initial_position.white_pawn_captures_black_piece_allowed = eval_to_number_or_zero(xml, "@white-captures-allowed");
    initial_position.black_pawn_captures_white_piece_allowed = eval_to_number_or_zero(xml, "@black-captures-allowed");

    process_pawn_position(initial_position);

    pawngen.reset(new struct pawngen);

    pawngen->pawn_positions_by_position.resize(valid_pawn_positions.size());
    pawngen->pawn_positions_by_index.resize(valid_pawn_positions.size());

    int first_white_pawn = num_pieces;
    int first_black_pawn = num_pieces + white_pawns_required;

    uint64_t legal_white_squares = 0ULL;
    uint64_t legal_black_squares = 0ULL;

    int index=0;
    for (auto it = valid_pawn_positions.begin(); it != valid_pawn_positions.end(); it ++) {

	int white_pawn = first_white_pawn;
	int black_pawn = first_black_pawn;

	/* std::set doesn't allow its objects to be modified once inserted */

	pawn_position pp = *it;

	for (int square = 0; square < 64; square ++) {
	    if (pp.white_pawn_at(square)) {
		pp.position[white_pawn] = square;
		if (pp.en_passant_square == square - 8) {
		    pp.en_passant_pawn = white_pawn;
		}
		legal_white_squares |= BITVECTOR(square);
		white_pawn ++;
	    }
	    if (pp.black_pawn_at(square)) {
		pp.position[black_pawn] = square;
		if (pp.en_passant_square == square + 8) {
		    pp.en_passant_pawn = black_pawn;
		}
		legal_black_squares |= BITVECTOR(square);
		black_pawn ++;
	    }
	}

	pp.index = index;
	pawngen->pawn_positions_by_index[index] = pp;
	pawngen->pawn_positions_by_position[index] = pp;

	index ++;
    }

    /* Figure which pawn positions arise from moving each pawn one step backwards, and save the
     * corresponding change in index in delta_pawngen_index.
     */

    for (index = 0; index < pawngen->pawn_positions_by_index.size(); index ++) {
	for (int piece = 0; piece < num_pieces; piece ++) {
	    pawngen->pawn_positions_by_index[index].prev_position[piece] = ILLEGAL_POSITION;
	    if (pieces[piece].piece_type == PAWN) {
		pawn_position prev_pp = pawngen->pawn_positions_by_index[index];
		if (pieces[piece].color == WHITE) {
		    prev_pp.remove_white_pawn(prev_pp.position[piece]);
		    prev_pp.add_white_pawn(prev_pp.position[piece] - 8);
		} else {
		    prev_pp.remove_black_pawn(prev_pp.position[piece]);
		    prev_pp.add_black_pawn(prev_pp.position[piece] + 8);
		}
		auto it = std::find(pawngen->pawn_positions_by_index.begin(),
				    pawngen->pawn_positions_by_index.end(),
				    prev_pp);
		if (it != pawngen->pawn_positions_by_index.end()) {
		    pawngen->pawn_positions_by_index[index].prev_position[piece] = prev_pp.position[piece];
		    pawngen->pawn_positions_by_index[index].delta_pawngen_index[piece]
			= it->index - pawngen->pawn_positions_by_index[index].index;
		}
	    }
	}
	pawngen->pawn_positions_by_position[index] = pawngen->pawn_positions_by_index[index];
    }

    std::sort(pawngen->pawn_positions_by_position.begin(), pawngen->pawn_positions_by_position.end(), pawn_position_fast_compare);

#if DEBUG
    fprintf(stderr, "%" PRIx64 " %" PRIx64 "\n", legal_white_squares, legal_black_squares);
#endif

    for (int i=0; i < white_pawns_required; i++) {
	pieces.push_back(piece(WHITE, PAWN, legal_white_squares));
	num_pieces ++;
    }

    for (int i=0; i < black_pawns_required; i++) {
	pieces.push_back(piece(BLACK, PAWN, legal_black_squares));
	num_pieces ++;
    }

    valid_pawn_positions.clear();
    invalid_pawn_positions.clear();
}


/***** NORMALIZATION *****/

/* Not all positions are created equal, but some are.  For example, interchanging two identical
 * pieces doesn't change the position at all, so a position with rook #1 on e4 and rook #2 on g6 is
 * the same as one with rook #1 on g6 and rook #2 on e4.  When converting to an index, we deal with
 * this by sorting identical pieces so the piece on the lowest numbered square always appears first
 * in the position.
 *
 * But this creates problems when trying to move a piece.  Consider for example, the two rooks.  If
 * we are moving rook #1 along the e file, it moves to e5, then e6, then e7.  Now, at e7, it has
 * become the rook on the higher numbered square, so the pieces have just "flipped" in the position
 * structure!  Additionally, if we have symmetry involved, then which piece is on the higher
 * numbered square can depend on the reflections required to get the kings to their restricted
 * areas.
 *
 * And we can't simply hide all of this in the guts of the position-to-index functions, because we
 * track futuremoves.  Figuring out "which one" of an identical pair of pieces got captured is
 * critical to figuring out which bit in the futuremoves vector corresponds to this move.
 *
 * So, we deal with this using "normalization".  We call normalize_position() to apply all the
 * reflection and sorting needed to get the position to a point where it can be directly converted
 * to an index.  We record these transformations using the 'reflection' variable and a permutation
 * array in the position structure.
 *
 * We can look into the permutation array to figure out which piece has been swapped where, so we
 * can figure out futuremove bit vectors accordingly.  So the way we move a rook, like in the
 * example above, is to move it e5, normalize, back prop, move it to e6, normalize, back prop, move
 * it to e7, etc.
 *
 * We also recompute the board vector, because the reflections can change it around.
 */

/* Forward reflections are used when converting a position to an index, are the ones returned by a
 * lookup in the tablebase's reflections array, and are applied in the order horizontal, vertical,
 * diagonal.
 *
 * Reverse reflections are used when converted an index to a position, and are applied in the order
 * diagonal, vertical, horizontal.  We need to reverse the ordering in order to ensure that the
 * positions generated from the index are the same ones that convert back to the index.
 */

uint8_t forward_reflection[8][64];
uint8_t reverse_reflection[8][64];

void init_reflections(void)
{
    for (int reflect = 0; reflect < 8; reflect ++) {
	for (int square = 0; square < 64; square ++) {
	    forward_reflection[reflect][square] = square;
	    if (reflect & REFLECTION_HORIZONTAL)
		forward_reflection[reflect][square]
		    = horizontal_reflection(forward_reflection[reflect][square]);
	    if (reflect & REFLECTION_VERTICAL)
		forward_reflection[reflect][square]
		    = vertical_reflection(forward_reflection[reflect][square]);
	    if (reflect & REFLECTION_DIAGONAL)
		forward_reflection[reflect][square]
		    = diagonal_reflection(forward_reflection[reflect][square]);

	    reverse_reflection[reflect][square] = square;
	    if (reflect & REFLECTION_DIAGONAL)
		reverse_reflection[reflect][square]
		    = diagonal_reflection(reverse_reflection[reflect][square]);
	    if (reflect & REFLECTION_VERTICAL)
		reverse_reflection[reflect][square]
		    = vertical_reflection(reverse_reflection[reflect][square]);
	    if (reflect & REFLECTION_HORIZONTAL)
		reverse_reflection[reflect][square]
		    = horizontal_reflection(reverse_reflection[reflect][square]);
	}
    }
}

bool semilegal_group_is_legal(const tablebase_t *tb, const local_position_t *position, int first_piece_in_group)
{
    for (int piece = first_piece_in_group; piece != -1; piece = tb->pieces[piece].next_piece_in_semilegal_group) {
	if (! (tb->pieces[piece].legal_squares & BITVECTOR(position->piece_position[piece]))) {
	    return false;
	}
    }
    return true;
}

bool permute_semilegal_group_until_legal(const tablebase_t *tb, local_position_t *position,
					 int first_piece_in_group, uint8_t *permutation = NULL)
{
    for (int perm = 0; tb->pieces[first_piece_in_group].permutations[perm] != 0; perm ++) {

	if (semilegal_group_is_legal(tb, position, first_piece_in_group)) return true;

	std::swap(position->piece_position[tb->pieces[first_piece_in_group].permutations[perm] & 0xff],
		  position->piece_position[tb->pieces[first_piece_in_group].permutations[perm] >> 8]);
	if (permutation) {
	    std::swap(permutation[tb->pieces[first_piece_in_group].permutations[perm] & 0xff],
		      permutation[tb->pieces[first_piece_in_group].permutations[perm] >> 8]);
	}
    }

    if (semilegal_group_is_legal(tb, position, first_piece_in_group)) return true;

    /* If none of the permutations result in a legal position, then the permutation list is
     * structured so that this final transposition takes us back to the original position and we
     * return false.
     */

    std::swap(position->piece_position[first_piece_in_group],
	      position->piece_position[tb->pieces[first_piece_in_group].next_piece_in_semilegal_group]);
    return false;
}

void normalize_position(const tablebase_t *tb, local_position_t *position)
{
    int piece, piece2;
    uint8_t permutation[MAX_PIECES];

    if (position->decoded) return;

    /* The 'combinadic4' index might not encode side-to-move at all.  In this case, if black is to
     * move, then we have to invert the entire board.  We've precomputed how to exchange the pieces;
     * that information is in the color_symmetric_transpose array.  We do this transformation first
     * because it will change the king positions that are used next to compute reflections.
     */

    if ((! tb->encode_stm) && (position->side_to_move == BLACK)) {

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    permutation[piece] = tb->pieces[piece].color_symmetric_transpose;
	    if (tb->pieces[piece].color_symmetric_transpose > piece) {
		position->piece_position[piece] = 63 - position->piece_position[piece];
		std::swap(position->piece_position[piece],
			  position->piece_position[tb->pieces[piece].color_symmetric_transpose]);
		position->piece_position[piece] = 63 - position->piece_position[piece];
	    }
	}
	if (position->en_passant_square != ILLEGAL_POSITION) {
	    position->en_passant_square = 63 - position->en_passant_square;
	}
	position->side_to_move = WHITE;

    } else {
	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    permutation[piece] = piece;
	}
    }

    /* Reflect the pieces around to get the white king where we want him for symmetry.
     *
     * 2-way symmetry: white king always on left side of board
     *
     * 4-way symmetry: white king always in lower left quarter of board
     *
     * 8-way symmetry: white king always in a1-a4-d4 triangle, and if white king is on a1-d4
     * diagonal, then black king is on or below a1-h8 diagonal
     */

    if (tb->symmetry > 1) {

	int reflection = tb->reflections
	    [position->piece_position[tb->white_king]]
	    [position->piece_position[tb->black_king]];

	if (reflection != 0) {
	    for (piece = 0; piece < tb->num_pieces; piece ++) {
		position->piece_position[piece]
		    = forward_reflection[reflection][position->piece_position[piece]];
	    }
	    if (position->en_passant_square != ILLEGAL_POSITION) {
		position->en_passant_square
		    = forward_reflection[reflection][position->en_passant_square];
	    }
	}

	position->reflection = reflection;

    } else {

	position->reflection = 0;

    }

    /* Sort any identical pieces so that the lowest square number always comes first. */

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	piece2 = piece;
	while ((tb->pieces[piece2].prev_piece_in_semilegal_group != -1)
	       && (position->piece_position[piece2]
		   < position->piece_position[tb->pieces[piece2].prev_piece_in_semilegal_group])) {
	    std::swap(position->piece_position[piece2],
		      position->piece_position[tb->pieces[piece2].prev_piece_in_semilegal_group]);
	    std::swap(permutation[piece2],
		      permutation[tb->pieces[piece2].prev_piece_in_semilegal_group]);
	    piece2 = tb->pieces[piece2].prev_piece_in_semilegal_group;
	}
    }

    /* Now permute identical pieces to try and get them onto legal squares (if needed).
     *
     * The order of the permutations is significant only in that identical board positions must
     * always generate identical indices.  So we first sort the pieces into a standard order (the
     * previous step), and then systematically apply permutations until we find the first one that
     * places all the pieces onto legal squares.  If none of the permutations work, we don't care.
     * This position is then illegal and will get rejected when we try to convert it to an index.
     *
     * Here's an obvious improvement if we have a lot of pieces in a semilegal group.  Count the
     * number of illegally positioned pieces, then only check legality of the pieces we're swapping
     * in each transposition to update the count.  Keep going until the count reaches zero.
     * Only improves speed if we have a lot of pieces in the group, though, so the current
     * code is definitely better for two pieces in the group.
     *
     * We don't check the return value from permute_semilegal_group_until_legal().  Why?  Well, this
     * function returns void, so what should it do if the position isn't legal?  On the other hand,
     * normalized_position_to_index (the next step after this one in local_position_to_index) will
     * check the position for legality and return INVALID_INDEX if it isn't.
     */

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	if (tb->pieces[piece].permutations) {
	    permute_semilegal_group_until_legal(tb, position, piece, permutation);
	}
    }

    /* Finally, reconstruct the board vector and invert the permutation, so that the permuted_piece
     * array in the position gives the new pieces as a function of the old ones.
     */

    position->board_vector = 0;

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	position->board_vector |= BITVECTOR(position->piece_position[piece]);
	position->permuted_piece[permutation[piece]] = piece;
    }

    /* If the position was 'decoded', it's still decoded. */
}

/***** INDICES *****/

/* Basically there are two functions here - one converts an index to a local position, the other
 * converts a local position to an index - but they exist in several different versions, depending
 * on the type of index we're using for a particular tablebase.  These functions are used
 * extensively during all types of back propagation.
 *
 * local_position_to_index() returns either an index into the table, or INVALID_INDEX if the
 * position is illegal.  The only change it makes to the position is to set the multiplicity.
 *
 * index_to_local_position(), given an index, fills in a board position.  Obviously has to correspond
 * to local_position_to_index() and it's a big bug if it doesn't.  The bool that gets returned is
 * TRUE if the operation succeeded and FALSE if the index was illegal.
 *
 * Several issues crop up for all index types.
 *
 * What exactly is an illegal position?  Well, for starters, one that index_to_local_position()
 * reports as illegal, because that's the function that initialize_tablebase() uses to figure which
 * positions are flagged illegal, as well as which positions to consider during back prop, and the
 * program screams if you try to back prop into an illegal position.  So the two functions have to
 * agree on illegality.  But there's also a subtle interaction between the legality tests here and
 * the move counting code in initialize_tablebase().  If we count a move, and it's not considered a
 * futuremove, then it'd better lead to a legal position, because we'll never backprop from an
 * illegal one, and that would imbalance the forward and reverse move counting.  For speed purposes,
 * the move counting code currently does not actually check positions to see if they are illegal.
 *
 * En passant.  This is another case where subtle concepts of "legality" show up.  When we back
 * propagate a local position from either a futurebase or intratable, we generate en passant
 * positions simply by running through the pawns on the fourth and fifth ranks.  We look then to see
 * if there was a piece behind the "en passant" pawn (that would have prevented it from moving), but
 * (unlike Nalimov) we don't check if there is an enemy pawn that actually could have captured.
 * Again, the code has to match up between the two places, or we would try to back propagate to a
 * position that had been labeled illegal during initialization by index_to_local_position().
 *
 * Identical pieces.  Identical positions need to generate identical indices.  If we have two
 * identical pieces, then transposing them in a position can't affect the outcome of
 * local_position_to_index().  Right now, I deal with this by making a copy of the local position
 * and sorting identical pieces into ascending position numbers.
 *
 * So how about a static 64-bit vector with bits set for pieces frozen on a single square?
 * Everytime we call index_to_local_position, copy from the static vector into the position
 * structure.  Then we compute the positions of the mobile pieces and plug their bits into the
 * structure's vector at the right places.  Might implement this some day.
 */

bool check_king_legality(int kingA, int kingB) {
    if ((ROW(kingA) < ROW(kingB) - 1) || (ROW(kingA) > ROW(kingB) + 1)) return true;
    if ((COL(kingA) < COL(kingB) - 1) || (COL(kingA) > COL(kingB) + 1)) return true;
    return false;
}

class index_encoding {
public:
    virtual index_t position_to_index(const tablebase_t *tb, local_position_t *pos) = 0;
    virtual bool index_to_position(const tablebase_t * tb, index_t index, local_position_t *pos) = 0;

    virtual bool move_piece(const tablebase_t * tb, local_position_t *pos, const int piece, const int destination_square) {
	pos->board_vector &= ~BITVECTOR(pos->piece_position[piece]);
	pos->piece_position[piece] = destination_square;
	pos->board_vector |= BITVECTOR(pos->piece_position[piece]);
	pos->decoded = false;
    }

    /* 'size' is the number of indices generated the index encoding, which is different from the
     * number of indices in the tablebase, because 'size' excludes side-to-move and pawngen.
     */

    index_t size;

    /* index_encoding is a polymorphic base type
     *
     * It has a trivial constructor, a virtual destructor (so its derived classes can destroy their
     * own data), and no copy or copy assignment operators, since it will only exist within a
     * std::unique_ptr in a tablebase_t.
     */

    index_encoding() { }
    virtual ~index_encoding() { }
    index_encoding(const index_encoding &) = delete;
    index_encoding & operator=(const index_encoding &) = delete;
};

/* "Naive" index.  Just assigns a number from 0 to 63 to each square on the board and multiplies
 * them together for the various pieces.  Simple and fast.  Actually is now a little more complex in
 * its white king encoding, since it works with 2-way and 4-way symmetry.
 */

class naive_index : public index_encoding {

public:

    index_t position_to_index(const tablebase_t *tb, local_position_t *pos)
    {
	int shift_count = 0;
	index_t index = 0;
	int piece;

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    /* The way we encode en passant capturable pawns is use the column number of the
	     * pawn.  Since there can never be a pawn (of either color) on the first rank,
	     * this is completely legit.
	     */
	    if ((tb->pieces[piece].piece_type == PAWN) && (pos->en_passant_square != ILLEGAL_POSITION)
		&& (((tb->pieces[piece].color == WHITE)
		     && (pos->en_passant_square + 8 == pos->piece_position[piece]))
		    || ((tb->pieces[piece].color == BLACK)
			&& (pos->en_passant_square - 8 == pos->piece_position[piece])))) {
		index |= COL(pos->en_passant_square) << shift_count;
		shift_count += 6;  /* because 2^6=64 */
	    } else if ((piece == tb->white_king) && (tb->symmetry == 2)) {
		/* white king is in left half of board */
		index |= ROW(pos->piece_position[piece]) << shift_count;
		shift_count += 3;
		index |= COL(pos->piece_position[piece]) << shift_count;
		shift_count += 2;
	    } else if ((piece == tb->white_king) && (tb->symmetry == 4)) {
		/* white king is in lower left quarter of board */
		index |= ROW(pos->piece_position[piece]) << shift_count;
		shift_count += 2;
		index |= COL(pos->piece_position[piece]) << shift_count;
		shift_count += 2;
	    } else {
		index |= pos->piece_position[piece] << shift_count;
		shift_count += 6;  /* because 2^6=64 */
	    }
	}

	return index;
    }

    bool index_to_position(const tablebase_t * tb, index_t index, local_position_t *p)
    {
	for (int piece = 0; piece < tb->num_pieces; piece++) {

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    int square;

	    if ((tb->symmetry == 2) && (piece == tb->white_king)) {
		square = rowcol2square(index & 7, (index >> 3) & 3);
		index >>= 5;
	    } else if ((tb->symmetry == 4) && (piece == tb->white_king)) {
		square = rowcol2square(index & 3, (index >> 2) & 3);
		index >>= 4;
	    } else {
		square = index & 63;
		index >>= 6;
	    }

	    /* En passant */
	    if ((tb->pieces[piece].piece_type == PAWN) && (square < 8)) {
		if (p->en_passant_square != ILLEGAL_POSITION) return false;  /* can't have two en passant pawns */
		if (tb->pieces[piece].color == WHITE) {
		    if (p->side_to_move != BLACK) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = square + 2*8;
		    square += 3*8;
		} else {
		    if (p->side_to_move != WHITE) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = square + 5*8;
		    square += 4*8;
		}
	    }

	    p->piece_position[piece] = square;

	    /* Identical pieces have to appear in sorted order. */

	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1)
		&& (p->piece_position[piece] < p->piece_position[tb->pieces[piece].prev_piece_in_semilegal_group])) {
		return false;
	    }
	}

	return true;
    }

    naive_index(const tablebase_t *tb)
    {
	int encoded_pieces = 0;

	for (int piece = 0; piece < tb->num_pieces; piece++) {
	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;
	    encoded_pieces ++;
	}

	if (encoded_pieces == 0) {
	    fatal("naive_index: At least one piece must be encoded\n");
	}

	/* The "6" is for the 2^6 squares on the board */
	switch (tb->symmetry) {
	case 1:
	    size = 1<<(6*encoded_pieces);
	    break;
	case 2:
	    size = 1<<(6*encoded_pieces - 1);
	    break;
	case 4:
	    size = 1<<(6*encoded_pieces - 2);
	    break;
	}
    }
};

/* "Naive2" index.  Assigns a number from 0 to 63 to each square on the board and multiplies them
 * together for the various pieces.  Differs from "naive" in its handling of multiple identical
 * pieces, which it stores as a base and an offset (an "encoding group"), thus saving a single bit.
 * Currently, only pairs of identical pieces are correctly handled.
 */

class naive2_index : public index_encoding
{
    int prev_piece_in_encoding_group[MAX_PIECES];
    int next_piece_in_encoding_group[MAX_PIECES];

public:

    index_t position_to_index(const tablebase_t * tb, local_position_t *pos)
    {
	int shift_count = 0;
	index_t index = 0;
	int piece;
	uint8_t vals[MAX_PIECES];

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    /* The way we encode en passant capturable pawns is use the column number of the
	     * pawn.  Since there can never be a pawn (of either color) on the first rank,
	     * this is completely legit.
	     */
	    if ((tb->pieces[piece].piece_type == PAWN) && (pos->en_passant_square != ILLEGAL_POSITION)
		&& (((tb->pieces[piece].color == WHITE)
		     && (pos->en_passant_square + 8 == pos->piece_position[piece]))
		    || ((tb->pieces[piece].color == BLACK)
			&& (pos->en_passant_square - 8 == pos->piece_position[piece])))) {
		vals[piece] = COL(pos->en_passant_square);
	    } else {
		vals[piece] = pos->piece_position[piece];
	    }
	}

	/* What's all this?
	 *
	 * The idea is to encode two identical pieces using one less bit than needed for encoding
	 * them separately, because n identical pieces introduce n! (n factorial) multiplicity.
	 *
	 * We encode the first piece "normally" and the second piece using a number from 1 to 32
	 * (encoded from 0 to 31) that should be added to the square number of the first piece to
	 * obtain the square number of the second.  We wrap around when doing that math, so if the
	 * first piece is on square 50 and the offset is 20, then the second piece is at square
	 * 50+20-64=6.
	 *
	 * What if the second piece is further away than 32 squares?  Then we swap the pieces with
	 * each other before doing anything else...
	 */

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;
	    if (next_piece_in_encoding_group[piece] != -1) {

		if (((vals[piece] < vals[next_piece_in_encoding_group[piece]])
		     && (vals[piece] + 32 < vals[next_piece_in_encoding_group[piece]]))
		    || ((vals[next_piece_in_encoding_group[piece]] < vals[piece])
			&& (vals[next_piece_in_encoding_group[piece]] + 32 >= vals[piece]))) {

		    unsigned char val;
		    val = vals[piece];
		    vals[piece] = vals[next_piece_in_encoding_group[piece]];
		    vals[next_piece_in_encoding_group[piece]] = val;
		}
	    }

	    if ((piece == tb->white_king) && (tb->symmetry == 2)) {
		/* white king is in left half of board */
		index |= ROW(vals[piece]) << shift_count;
		shift_count += 3;
		index |= COL(vals[piece]) << shift_count;
		shift_count += 2;
	    } else if ((piece == tb->white_king) && (tb->symmetry == 4)) {
		/* white king is in lower left quarter of board */
		index |= ROW(vals[piece]) << shift_count;
		shift_count += 2;
		index |= COL(vals[piece]) << shift_count;
		shift_count += 2;
	    } else if (prev_piece_in_encoding_group[piece] == -1) {
		index |= vals[piece] << shift_count;
		shift_count += 6;  /* because 2^6=64 */
	    } else {
		if (vals[piece] > vals[prev_piece_in_encoding_group[piece]]) {
		    index |= (vals[piece] - vals[prev_piece_in_encoding_group[piece]] - 1) << shift_count;
		} else {
		    index |= (64 + vals[piece] - vals[prev_piece_in_encoding_group[piece]] - 1) << shift_count;
		}
		shift_count += 5; /* the whole point of "naive2" */
	    }
	}

	return index;
    }

    bool index_to_position(const tablebase_t * tb, index_t index, local_position_t *p)
    {
	int piece;
	uint8_t vals[MAX_PIECES];

	for (piece = 0; piece < tb->num_pieces; piece++) {

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    if ((tb->symmetry == 2) && (piece == tb->white_king)) {
		vals[piece] = rowcol2square(index & 7, (index >> 3) & 3);
		index >>= 5;
	    } else if ((tb->symmetry == 4) && (piece == tb->white_king)) {
		vals[piece] = rowcol2square(index & 3, (index >> 2) & 3);
		index >>= 4;
	    } else if (prev_piece_in_encoding_group[piece] == -1) {
		vals[piece] = index & 63;
		index >>= 6;
	    } else {
		vals[piece] = (vals[prev_piece_in_encoding_group[piece]] + (index & 31) + 1) % 64;
		index >>= 5;

		if (vals[piece] < vals[prev_piece_in_encoding_group[piece]]) {
		    unsigned char val;

		    /* One of the important tasks of any index_to_position() function is to return
		     * false on all but one of the indices that correspond to identical positions.
		     * Here, that can only happen when two grouped pieces are exactly 32 squares
		     * apart, which can be encoded using either piece first.  In this case, we toss
		     * out the index with the larger of the two squares encoded as the base value,
		     * and make sure that the "<" and the ">=" match up just right in the previous
		     * function.
		     */

		    if (vals[prev_piece_in_encoding_group[piece]] - vals[piece] == 32) return false;

		    val = vals[piece];
		    vals[piece] = vals[prev_piece_in_encoding_group[piece]];
		    vals[prev_piece_in_encoding_group[piece]] = val;
		}
	    }

	}

	for (piece = 0; piece < tb->num_pieces; piece++) {

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    int square = vals[piece];

	    /* En passant */
	    if ((tb->pieces[piece].piece_type == PAWN) && (square < 8)) {
		if (p->en_passant_square != ILLEGAL_POSITION) return false;  /* can't have two en passant pawns */
		if (tb->pieces[piece].color == WHITE) {
		    if (p->side_to_move != BLACK) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = square + 2*8;
		    square += 3*8;
		} else {
		    if (p->side_to_move != WHITE) return 0; /* en passant pawn has to be capturable */
		    p->en_passant_square = square + 5*8;
		    square += 4*8;
		}
	    }

	    p->piece_position[piece] = square;

	    /* Identical pieces have to appear in sorted order. */

	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1)
		&& (p->piece_position[piece] < p->piece_position[tb->pieces[piece].prev_piece_in_semilegal_group])) {
		return false;
	    }
	}

	return true;
    }

    naive2_index(const tablebase_t *tb)
    {
	size = 1;

	/* do the white king "by hand" */
	switch (tb->symmetry) {
	case 1:
	    size <<= 6;
	    break;
	case 2:
	    size <<= 5;
	    break;
	case 4:
	    size <<= 4;
	    break;
	}

	prev_piece_in_encoding_group[tb->white_king] = -1;
	next_piece_in_encoding_group[tb->white_king] = -1;

	/* now do everything else */
	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    if (piece == tb->white_king) continue;

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1)
		&& (tb->pieces[piece].next_piece_in_semilegal_group != -1)) {
		throw "Can't have more than two identical pieces with 'naive2' index";
	    }

	    prev_piece_in_encoding_group[piece] = tb->pieces[piece].prev_piece_in_semilegal_group;
	    next_piece_in_encoding_group[piece] = tb->pieces[piece].next_piece_in_semilegal_group;

	    if (prev_piece_in_encoding_group[piece] == -1) size <<= 6;
	    else size <<=5;
	}
    }

};

/* "Simple" index.  Like naive, but only assigns numbers to squares that are legal for a particular
 * piece.  Slower to compute than naive, but more compact for tablebases with lots of movement
 * restrictions on the pieces.
 */

class simple_index : public index_encoding
{
    int piece_position[MAX_PIECES][64];
    index_t piece_index[MAX_PIECES][64];

    int total_legal_positions[MAX_PIECES] = {};

public:

    index_t position_to_index(const tablebase_t * tb, local_position_t *pos)
    {
	index_t index = 0;

	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    index *= total_legal_positions[piece];

	    /* The way we encode en passant capturable pawns is use the column number of the pawn.
	     * Since there can never be a pawn (of either color) on the first rank, this is
	     * completely legit.
	     */
	    if ((tb->pieces[piece].piece_type == PAWN) && (pos->en_passant_square != ILLEGAL_POSITION)
		&& (((tb->pieces[piece].color == WHITE)
		     && (pos->en_passant_square + 8 == pos->piece_position[piece]))
		    || ((tb->pieces[piece].color == BLACK)
			&& (pos->en_passant_square - 8 == pos->piece_position[piece])))) {
		index += piece_index[piece][COL(pos->en_passant_square)];
	    } else {
		index += piece_index[piece][pos->piece_position[piece]];
	    }
	}

	return index;
    }

    bool index_to_position(const tablebase_t * tb, index_t index, local_position_t *p)
    {
	int piece;

	for (piece = tb->num_pieces - 1; piece >= 0; piece --) {

	    int square = piece_position[piece][index % total_legal_positions[piece]];
	    index /= total_legal_positions[piece];

	    /* En passant */
	    if ((tb->pieces[piece].piece_type == PAWN) && (square < 8)) {
		if (p->en_passant_square != ILLEGAL_POSITION) return false;  /* can't have two en passant pawns */
		if (tb->pieces[piece].color == WHITE) {
		    if (p->side_to_move != BLACK) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = square + 2*8;
		    square += 3*8;
		} else {
		    if (p->side_to_move != WHITE) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = square + 5*8;
		    square += 4*8;
		}
	    }

	    p->piece_position[piece] = square;
	}

	/* Identical pieces have to appear in sorted order. */

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1)
		&& (p->piece_position[piece] < p->piece_position[tb->pieces[piece].prev_piece_in_semilegal_group])) {
		return false;
	    }
	}

	if (index != 0) {
	    fatal("index != 0 at end of simple_index::index_to_position!\n");
	    return false;
	}

	return true;
    }

    simple_index(const tablebase_t *tb)
    {
	size = 1;

	for (int piece = 0; piece < tb->num_pieces; piece ++) {
	    for (int square = 0; square < 64; square ++) {
		if (! (tb->pieces[piece].legal_squares & BITVECTOR(square))) continue;
		if ((piece == tb->white_king) && (tb->symmetry >= 2) && (COL(square) >= 4)) continue;
		if ((piece == tb->white_king) && (tb->symmetry >= 4) && (ROW(square) >= 4)) continue;
		if ((piece == tb->white_king) && (tb->symmetry == 8) && (ROW(square) > COL(square))) continue;
		piece_position[piece][total_legal_positions[piece]] = square;
		piece_index[piece][square] = total_legal_positions[piece];
		total_legal_positions[piece] ++;

		/* if the pawn is en-passant capturable, add an index for that */
		if ((tb->pieces[piece].piece_type == PAWN)
		    && (((tb->pieces[piece].color == WHITE) && (ROW(square) == 3))
			|| ((tb->pieces[piece].color == BLACK) && (ROW(square) == 4)))) {
		    piece_position[piece][total_legal_positions[piece]] = COL(square);
		    piece_index[piece][COL(square)] = total_legal_positions[piece];
		    total_legal_positions[piece] ++;
		}
	    }
	    size *= total_legal_positions[piece];
	}
    }

};

/* "compact" index
 *
 * A combination of the delta encoding for identical pieces used in "naive2", the encoding of
 * restricted pieces used in "simple", plus a paired encoding of the kings so they can never be
 * adjacent.
 *
 * Pairs of identical pieces can be handled in at least three ways that I can think of:
 *
 * 1. Treat the pieces as paired and encode using the full semilegal range for each of them, using
 * delta encoding to cut the total size in half, and then throw out as illegal those positions where
 * the pieces can't be put onto legal squares.  Makes the most sense if the move restrictions are
 * completely overlapping.
 *
 * 2. Treat the pieces as independent and encode each using its legal range, and then throw out as
 * illegal half of those positions where both the pieces are on interchangable legal squares.  Makes
 * the most sense if one of the move restrictions is significantly smaller than the other.
 *
 * 3. Build an array in memory like we do with the kings to encode only the legal possibilities.  No
 * bogus illegal positions here, but doesn't really scale to more than two pieces.
 *
 * 4. Use a combinadic encoding that encodes n selections from k objects, without replacement,
 * unordered.
 *
 * Right now, we use method (1) in the 'compact', 'naive2', and 'no-en-passant' schemes, method (4)
 * in the combinadic schemes, and method (2) everywhere else.
 *
 * Some additional things could be done to make an even more compact encoding:
 *
 * Take advantage of previous pieces occupying squares to cut encoding down from 64*64*64*...  to
 * 64*63*62*...  Actually, since we've already got the kings encoded pretty compactly, it would be
 * cutting down from 64*64*64*... to 62*61*60*...  Move restrictions would complicate this; maybe
 * only do it for pieces whose move restriction can be fit entirely in the move restrictions of
 * previous pieces.
 *
 * Encode en passant position-wide instead of adding an extra square for each pawn.  Would be a win
 * in positions with lots of pawns.
 *
 * The 'compact' routines are also used for the 'no-en-passant' index type, which is identical to
 * compact except that opposing plus-pawns are encoded in the same group.  So long as we leave en
 * passant out of the picture, opposing plus-pawns occupy an identical range of squares and, so long
 * as we know which two squares are occupied, we can always figure out which pawn is white and which
 * is black because they can't jump over each other.  En passant would complicate this, because then
 * the two pawns wouldn't be identical in their ranges.
 */

class compact_index : public index_encoding
{
    int prev_piece_in_encoding_group[MAX_PIECES];
    int next_piece_in_encoding_group[MAX_PIECES];

    int piece_position[MAX_PIECES][64];
    index_t piece_index[MAX_PIECES][64];

    /* Kings are usually encoded together to take advantage of them never being adjacent.  Given a
     * pair of king positions, king_index[WHITE_KING_POSITION][BLACK_KING_POSITION] returns the
     * associated index, while white_king_position[INDEX] and black_king_position[INDEX] reverse
     * that function.
     */

    uint8_t white_king_position[64*64];
    uint8_t black_king_position[64*64];
    index_t king_index[64][64];
    uint total_legal_king_positions;

    int total_legal_positions[MAX_PIECES] = {};

public:

    index_t position_to_index(const tablebase_t * tb, local_position_t *pos)
    {
	index_t index = 0;
	uint8_t vals[MAX_PIECES];

	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    /* The way we encode en passant capturable pawns is use the column number of the
	     * pawn.  Since there can never be a pawn (of either color) on the first rank,
	     * this is completely legit.
	     */
	    if ((tb->pieces[piece].piece_type == PAWN) && (pos->en_passant_square != ILLEGAL_POSITION)
		&& (((tb->pieces[piece].color == WHITE)
		     && (pos->en_passant_square + 8 == pos->piece_position[piece]))
		    || ((tb->pieces[piece].color == BLACK)
			&& (pos->en_passant_square - 8 == pos->piece_position[piece])))) {
		vals[piece] = piece_index[piece][COL(pos->en_passant_square)];
	    } else {
		vals[piece] = piece_index[piece][pos->piece_position[piece]];
	    }
	}

	/* Compute the index.
	 *
	 * We encode two identical pieces using one less bit than needed for encoding them
	 * separately, because n identical pieces introduce n! (n factorial) multiplicity.
	 *
	 * We encode the first piece "normally" and the second piece using a number from 1 to 32
	 * (encoded from 0 to 31) that should be added to the square number of the first piece to
	 * obtain the square number of the second.  We wrap around when doing that math, so if the
	 * first piece is on square 50 and the offset is 20, then the second piece is at square
	 * 50+20-64=6.
	 *
	 * What if the second piece is further away than 32 squares?  Then we swap the pieces with
	 * each other before doing anything else...
	 */

	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    if (piece == tb->white_king) {
		index *= total_legal_king_positions;
		index += king_index[pos->piece_position[tb->white_king]]
		    [pos->piece_position[tb->black_king]];
	    }

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (next_piece_in_encoding_group[piece] != -1) {

		if (((vals[piece] < vals[next_piece_in_encoding_group[piece]])
		     && (vals[piece] + total_legal_positions[piece]/2
			 < vals[next_piece_in_encoding_group[piece]]))
		    || ((vals[next_piece_in_encoding_group[piece]] < vals[piece])
			&& (vals[next_piece_in_encoding_group[piece]] + total_legal_positions[piece]/2
			    >= vals[piece]))) {

		    unsigned char val;
		    val = vals[piece];
		    vals[piece] = vals[next_piece_in_encoding_group[piece]];
		    vals[next_piece_in_encoding_group[piece]] = val;
		}
	    }

	    if (prev_piece_in_encoding_group[piece] == -1) {
		index *= total_legal_positions[piece];
		index += vals[piece];
	    } else {
		index *= total_legal_positions[piece] / 2;

		if (vals[piece] > vals[prev_piece_in_encoding_group[piece]]) {
		    index += (vals[piece] - vals[prev_piece_in_encoding_group[piece]] - 1);
		} else {
		    index += (total_legal_positions[piece] + vals[piece] - vals[prev_piece_in_encoding_group[piece]] - 1);
		}
	    }
	}

	return index;
    }

    bool index_to_position(const tablebase_t * tb, index_t index, local_position_t *p)
    {
	int piece;
	uint8_t vals[MAX_PIECES];
	int king_index = 0;

	/* First, split index into an array of encoding values. */

	for (piece = tb->num_pieces - 1; piece >= 0; piece --) {

	    if (piece == tb->white_king) {
		king_index = index % total_legal_king_positions;
		index /= total_legal_king_positions;
	    }

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (prev_piece_in_encoding_group[piece] == -1) {
		vals[piece] = index % total_legal_positions[piece];
		index /= total_legal_positions[piece];
	    } else {
		vals[piece] = index % (total_legal_positions[piece]/2);
		index /= total_legal_positions[piece]/2;
	    }
	}

	/* Next, back out any delta encoding and convert the encoding numbers to square numbers on
	 * the board.  This loop has to run in reverse order over the pieces, since the delta
	 * encodings are based on previous encoding numbers, and we're converting to square numbers
	 * as we go.  We run a seperate loop here because we might need previous encoding values to
	 * back out the deltas.
	 */

	for (piece = tb->num_pieces - 1; piece >= 0; piece --) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (prev_piece_in_encoding_group[piece] != -1) {

		vals[piece] += vals[prev_piece_in_encoding_group[piece]] + 1;
		vals[piece] %= total_legal_positions[piece];

		/* One of the important tasks of any index_to_local_position() function is to return
		 * false on all but one of the indices that correspond to identical positions.
		 * Here, that can only happen when two grouped pieces are exactly half their total
		 * legal piece positions squares apart, which can be encoded using either piece
		 * first.  In this case, we toss out the index with the larger of the two squares
		 * encoded as the base value, and make sure that the "<" and the ">=" match up just
		 * right in the previous function.
		 */

		if (vals[prev_piece_in_encoding_group[piece]] - vals[piece]
		    == total_legal_positions[piece]/2) return false;
	    }

	    vals[piece] = piece_position[piece][vals[piece]];

	    /* En passant */
	    if ((tb->pieces[piece].piece_type == PAWN) && (vals[piece] < 8)) {
		if (p->en_passant_square != ILLEGAL_POSITION) return false;  /* can't have two en passant pawns */
		if (tb->pieces[piece].color == WHITE) {
		    if (p->side_to_move != BLACK) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = vals[piece] + 2*8;
		    vals[piece] += 3*8;
		} else {
		    if (p->side_to_move != WHITE) return false; /* en passant pawn has to be capturable */
		    p->en_passant_square = vals[piece] + 5*8;
		    vals[piece] += 4*8;
		}
	    }

	}

	/* Now we have to decide the actual ordering in the piece array.  Right now, since we only
	 * use this code for pairs of identical pieces, we swap if the higher numbered piece is
	 * first, then swap (maybe again) if the pieces aren't on legal squares.  The net result is
	 * to put them both on legal squares, if possible, and to put the lower numbered square
	 * first if both possibilities are legal.
	 *
	 * This loop also has to run in reverse order for the swap code to work right.  We run a
	 * seperate loop here because the legality checks are based on square numbers and not
	 * encoding values, and we need for all the previous encoding values to have been converted
	 * into square numbers first.
	 */

	for (piece = tb->num_pieces - 1; piece >= 0; piece --) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (prev_piece_in_encoding_group[piece] != -1) {

		if (vals[piece] < vals[prev_piece_in_encoding_group[piece]]) {
		    uint8_t val = vals[piece];
		    vals[piece] = vals[prev_piece_in_encoding_group[piece]];
		    vals[prev_piece_in_encoding_group[piece]] = val;
		}

		if (! (tb->pieces[piece].legal_squares & BITVECTOR(vals[piece]))
		    || ! (tb->pieces[prev_piece_in_encoding_group[piece]].legal_squares
			  & BITVECTOR(vals[prev_piece_in_encoding_group[piece]]))) {

		    uint8_t val = vals[piece];
		    vals[piece] = vals[prev_piece_in_encoding_group[piece]];
		    vals[prev_piece_in_encoding_group[piece]] = val;
		}
	    }
	}

	for (piece = tb->num_pieces - 1; piece >= 0; piece --) {

	    int square = vals[piece];

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    p->piece_position[piece] = square;

	}

	p->piece_position[tb->white_king] = white_king_position[king_index];
	p->piece_position[tb->black_king] = black_king_position[king_index];

#if 0
	/* Identical pieces have to appear in sorted order. */

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1)
		&& (p->piece_position[piece] < p->piece_position[tb->pieces[piece].prev_piece_in_semilegal_group])) {
		return false;
	    }
	}
#endif

	if (index != 0) {
	    fatal("index != 0 at end of compact_index::index_to_position!\n");
	    return false;
	}

	return true;
    }

    compact_index(const tablebase_t *tb)
    {
	if (tb->variant == VARIANT_SUICIDE) {
	    throw nested_exception("'compact' index type not allowed with 'suicide' variable");
	}

	total_legal_king_positions = 0;

	for (int white_king_square = 0; white_king_square < 64; white_king_square ++) {
	    if (! (tb->pieces[tb->white_king].legal_squares & BITVECTOR(white_king_square))) continue;
	    for (int black_king_square = 0; black_king_square < 64; black_king_square ++) {
		if (! (tb->pieces[tb->black_king].legal_squares & BITVECTOR(black_king_square))) continue;
		if ((tb->symmetry >= 2) && (COL(white_king_square) >= 4)) continue;
		if ((tb->symmetry >= 4) && (ROW(white_king_square) >= 4)) continue;
		if ((tb->symmetry == 8) && (ROW(white_king_square) > COL(white_king_square))) continue;
		if ((tb->symmetry == 8) && (ROW(white_king_square) == COL(white_king_square))
		    && (ROW(black_king_square) > COL(black_king_square))) continue;

		if (tb->positions_with_adjacent_kings_are_illegal
		    && ! check_king_legality(white_king_square, black_king_square)) continue;

		white_king_position[total_legal_king_positions] = white_king_square;
		black_king_position[total_legal_king_positions] = black_king_square;
		king_index[white_king_square][black_king_square] = total_legal_king_positions;
		total_legal_king_positions ++;
	    }
	}

	size = total_legal_king_positions;

	prev_piece_in_encoding_group[tb->white_king] = -1;
	next_piece_in_encoding_group[tb->white_king] = -1;
	prev_piece_in_encoding_group[tb->black_king] = -1;
	next_piece_in_encoding_group[tb->black_king] = -1;

	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1)
		&& (tb->pieces[piece].next_piece_in_semilegal_group != -1)) {
		throw "Can't have more than two identical pieces with 'compact' index";
	    }

	    prev_piece_in_encoding_group[piece] = tb->pieces[piece].prev_piece_in_semilegal_group;
	    next_piece_in_encoding_group[piece] = tb->pieces[piece].next_piece_in_semilegal_group;

	    /* We count semilegal and not legal squares here because the pair encoding used for
	     * identical pieces assumes that both pieces occupy the same range of squares.
	     */

	    for (int square = 0; square < 64; square ++) {

		if (! (tb->pieces[piece].semilegal_squares & BITVECTOR(square))) continue;

		if ((piece == tb->white_king) && (tb->symmetry >= 2) && (COL(square) >= 4)) continue;
		if ((piece == tb->white_king) && (tb->symmetry >= 4) && (ROW(square) >= 4)) continue;
		if ((piece == tb->white_king) && (tb->symmetry == 8) && (ROW(square) > COL(square))) continue;
		piece_position[piece][total_legal_positions[piece]] = square;
		piece_index[piece][square] = total_legal_positions[piece];
		total_legal_positions[piece] ++;

		/* if the pawn is en-passant capturable, add an index for that */
		if ((tb->pieces[piece].piece_type == PAWN)
		    && (((tb->pieces[piece].color == WHITE) && (ROW(square) == 3))
			|| ((tb->pieces[piece].color == BLACK) && (ROW(square) == 4)))) {
		    piece_position[piece][total_legal_positions[piece]] = COL(square);
		    piece_index[piece][COL(square)] = total_legal_positions[piece];
		    total_legal_positions[piece] ++;
		}
	    }
	    if (prev_piece_in_encoding_group[piece] == -1) {
		size *= total_legal_positions[piece];
	    } else if (total_legal_positions[piece]
		       != total_legal_positions[prev_piece_in_encoding_group[piece]]) {
		/* Semilegal positions are the union of legal positions for an entire encoding group */
		fatal("BUG: Encoding group don't have the same number of total semilegal positions\n");
	    } else {
		size *= total_legal_positions[piece]/2;
	    }
	}
    }
};

/* "combinadic3/4" index
 *
 * The encoding of restricted pieces used in "simple", paired encoding of the kings so they can
 * never be adjacent, a combinatorial-based encoding of identical pieces, and later pieces wholly
 * contained within the semilegal positions of earlier pieces are encoded using fewer positions.
 * Pawns require special consideration, as we encode en-passant capturable pawns using the squares
 * on the first rank.  When using a pawn to reduce the encoding value of a later piece, we ignore
 * the en-passant status of the pawn and use its board position.  When reducing the encoding value
 * of a pawn, we use the encoding value, with en-passant factored in.
 *
 * Encoding groups are usually identical pieces, but pawns restricted to a single file using plus
 * syntax are grouped, even if they are not the same color.  They can't pass each other because
 * there are no captures within a tablebase, so the color ordering of the pawns on the file can't
 * change.
 *
 * 'combinadic4' differs from 'combinadic3' in that it omits side-to-move if the position
 * can be inverted.
 */

int choose(int n, int k) {
    long retval = 1;
    int i;

    for (i=0; i<k; i++) retval *= (n-i);
    for (i=1; i<=k; i++) retval /= i;

    return retval;
}

class combinadic_index : public index_encoding
{
    int prev_piece_in_encoding_group[MAX_PIECES];
    int next_piece_in_encoding_group[MAX_PIECES];

    int piece_position[MAX_PIECES][64];
    index_t piece_index[MAX_PIECES][64];
    int value[MAX_PIECES][64];

    uint8_t white_king_position[64*64];
    uint8_t black_king_position[64*64];
    index_t king_index[64][64];
    uint total_legal_king_positions;

    int total_legal_positions[MAX_PIECES] = {};
    int total_legal_piece_values[MAX_PIECES];

    /* "Overlapping" pieces happen when a piece's semilegal range completely contains the semilegal
     * range of a earlier piece.  We'll be able to remove some of our positions since they must be
     * occupied by the earlier piece.  When decoding, we construct, for each piece, a board vector
     * of all positions occupied by it and all the pieces its range overlaps.  When we have multiple
     * pieces in a semilegal group, we need to both build this vector, and reference the last
     * overlapping piece not in the current semilegal group.
     */

    int last_overlapping_piece[MAX_PIECES];
    int last_overlapping_group[MAX_PIECES];

    /* A bitvector of the smaller squares than this one.  Initialized in constructor.
     *
     * XXX smaller_pieces needs to take restricted locations into account
     */

    uint64_t smaller_pieces[64] = {0};

public:

    index_t position_to_index(const tablebase_t * tb, local_position_t *pos)
    {
	index_t index;
	int piece, piece2;
	uint8_t vals[MAX_PIECES];

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    int decrement = 0;

	    /* The way we encode en passant capturable pawns is use the column number of the pawn.
	     * Since there can never be a pawn (of either color) on the first rank, this is
	     * completely legit.
	     */
	    if ((tb->pieces[piece].piece_type == PAWN) && (pos->en_passant_square != ILLEGAL_POSITION)
		&& (((tb->pieces[piece].color == WHITE)
		     && (pos->en_passant_square + 8 == pos->piece_position[piece]))
		    || ((tb->pieces[piece].color == BLACK)
			&& (pos->en_passant_square - 8 == pos->piece_position[piece])))) {
		vals[piece] = value[piece][COL(pos->en_passant_square)];
		continue;  /* Have to do this, as we never change en-passant values */
	    } else {
		vals[piece] = value[piece][pos->piece_position[piece]];
	    }

	    /* Remove positions for overlapping pieces, but we don't touch the kings, and we don't
	     * consider anything in the current encoding group, because the combinadic encoding
	     * already takes care of them.  For all other overlapping pieces before us in the piece
	     * list, if that piece is earlier than us in board order, decrement our position by one.
	     *
	     * Pawns require special consideration, as we encode en-passant capturable pawns using
	     * the squares on the first rank.  When using a pawn to reduce the encoding value of a
	     * later piece, we ignore the en-passant status of the pawn and use its board position.
	     * When reducing the encoding value of a pawn, we use the encoding value, with
	     * en-passant factored in.  A consequence of this is that we never change the value of
	     * an en-passant encoded pawn.
	     */

	    for (piece2 = piece; prev_piece_in_encoding_group[piece2] != -1; piece2 = prev_piece_in_encoding_group[piece2]);

	    for (piece2 = last_overlapping_piece[piece2]; piece2 != -1; piece2 = last_overlapping_piece[piece2]) {
		if (pos->piece_position[piece] > pos->piece_position[piece2]) decrement ++;
	    }

	    vals[piece] -= decrement;
	}

	/* Sort encoding groups so that the lowest values always come first. */

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;
	    piece2 = piece;
	    while ((prev_piece_in_encoding_group[piece2] != -1)
		   && (vals[piece2] < vals[prev_piece_in_encoding_group[piece2]])) {
		std::swap(vals[piece2], vals[prev_piece_in_encoding_group[piece2]]);
		piece2 = prev_piece_in_encoding_group[piece2];
	    }
	}

	/* Encode the pieces */

	index = 0;

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    index += piece_index[piece][vals[piece]];
	}

	/* Kings have their own encoding table */

	if (tb->white_king != -1) {
	    index += king_index[pos->piece_position[tb->white_king]]
		[pos->piece_position[tb->black_king]];
	}

	return index;
    }

    bool index_to_position(const tablebase_t * tb, index_t index, local_position_t *p)
    {
	int piece;
	int en_passant_pawn = -1;
	int en_passant_color = 0;
	uint8_t vals[MAX_PIECES];
	uint64_t overlapping_pieces[MAX_PIECES] = {0};

	/* Binary search for the largest value in index[] that is less than or equal to the
	 * (running) index, subtract it out of the index, and store the encoding values.  This loop
	 * has to run in reverse order over the pieces, since a combinadic encoding must be backed
	 * out from the largest piece first.
	 */

	for (piece = tb->num_pieces - 1; piece >= 0; piece --) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    vals[piece]
		= std::lower_bound(piece_index[piece], piece_index[piece] + 64, index+1)
		- piece_index[piece] - 1;

	    index -= piece_index[piece][vals[piece]];

	    if ((tb->pieces[piece].piece_type == PAWN) && (piece_position[piece][vals[piece]] < 8)) {

		if (en_passant_pawn != -1) return false; /* can't have two en passant pawns */

		en_passant_pawn = piece;

		/* If there's an en passant pawn, it must be the opposite color of PTM */
		en_passant_color = 1 - p->side_to_move;

		/* En passant pawns are encoded on the first row and never have their values reduced */
		p->piece_position[en_passant_pawn] = piece_position[en_passant_pawn][vals[en_passant_pawn]];

		if (en_passant_color == WHITE) {
		    p->en_passant_square = p->piece_position[en_passant_pawn] + 2*8;
		    p->piece_position[en_passant_pawn] += 3*8;
		} else {
		    p->en_passant_square = p->piece_position[en_passant_pawn] + 5*8;
		    p->piece_position[en_passant_pawn] += 4*8;
		}

	    }

	}

	if (tb->variant != VARIANT_SUICIDE) {

	    if (index >= total_legal_king_positions) {
		fatal("index >= total legal king positions in combinadic_index::index_to_position!\n");
		return false;
	    }

	    p->piece_position[tb->white_king] = white_king_position[index];
	    p->piece_position[tb->black_king] = black_king_position[index];

	} else {

	    if (index != 0) {
		fatal("index > 0 in combinadic_index::index_to_position!\n");
		return false;
	    }

	}

	/* "You've got to be kidding me"
	 *
	 * If we have overlapping pieces, some of the position numbers of the later pieces might
	 * have been reduced.  We fix up the positions by going back through the earlier overlapping
	 * pieces and incrementing our position if we're past them.  This has to be done in order
	 * from the smallest position to the largest.  Consider unrestricted pieces; kings on
	 * squares 12 and 33, and a queen on square 34 that got encoded as 32.  We need to increment
	 * 32 to 33 for 12, then increment 33 to 34 for 33, and if we try to handle the king on 33
	 * first, we won't increment because 32 is less than 33.
	 *
	 * I've tried to minimize the number of loops by maintaining a bit vector
	 * (overlapping_pieces) for each piece that has a bit set both for that piece's position and
	 * for the positions of any earlier overlapping pieces.  For each piece, we count the bits
	 * set at earlier positions in the bit vector, but we have to be careful to check additional
	 * bits as we increment.  In the example above, we can count all the bits from 0 to 32, find
	 * that 12 is set, but then we have to check 33 as we increment to know that we need to
	 * increment again to 34.
	 */

	for (piece = 0; piece < tb->num_pieces; piece ++) {
 
	    /* Find the last overlapping piece for this encoding group and retrieve its cumulative
	     * overlapping piece vector.  Not doing this was the bug in 1.759 exposed by attempting
	     * to build kqqk.
	     */

	    uint64_t overlapping_this_group = 0;
	    if (last_overlapping_group[piece] != -1) {
		overlapping_this_group = overlapping_pieces[last_overlapping_group[piece]];
	    }

	    /* Kings, en passant pawns, and pawngen pawns have their own encoding schemes and have
	     * already been decoded.
	     */
 
	    if ((piece != tb->white_king) && (piece != tb->black_king) && (piece != en_passant_pawn)
		&& (! tb->pawngen || (tb->pieces[piece].piece_type != PAWN))) {
 
		p->piece_position[piece] = piece_position[piece][vals[piece]];

		/* Form a bitvector of the piece on smaller squares than this one, that were earlier and
		 * are overlapped by this group.
		 *
		 * XXX smaller_pieces needs to take restricted locations into account
		 */

		uint64_t increments = (overlapping_this_group & smaller_pieces[p->piece_position[piece]]);
 
		/* Loop once for each bit set in "increments".  Brian Kernighan's way of counting
		 * bits.  Increment the encoding value and decode a new position, continuing to
		 * increment if the new position also overlaps an earlier piece.
		 */
 
		while (increments) {
		    increments &= increments - 1;
		    do {
			vals[piece] ++;
			p->piece_position[piece] = piece_position[piece][vals[piece]];
		    } while (overlapping_this_group & (1ULL << (p->piece_position[piece])));
		}
	    }
 
	    /* Build a board vector of this piece and all its overlapping pieces. */

	    if (last_overlapping_piece[piece] != -1) {
		overlapping_pieces[piece] = overlapping_pieces[last_overlapping_piece[piece]];
	    }
 
	    overlapping_pieces[piece] |= (1ULL << (p->piece_position[piece]));
	}

	/* En passant pawns always trail on a file, since they just moved from their starting
	 * positions.  So, white en passant pawns are still sorted, but black ones have to be moved
	 * to the end of their group.
	 *
	 * pawngen will never decode an en_passant_pawn here, so this code gets skipped.
	 */

	if (en_passant_pawn != -1) {

	    for (piece = next_piece_in_encoding_group[en_passant_pawn];
		 (piece != -1)
		     && (p->piece_position[prev_piece_in_encoding_group[piece]]
			 > p->piece_position[piece]);
		 piece = next_piece_in_encoding_group[piece]) {
		std::swap(p->piece_position[piece], p->piece_position[prev_piece_in_encoding_group[piece]]);
		en_passant_pawn = piece;
	    }

	    /* We've figured out which pawn is the en passant pawn, now make sure that it is the
	     * right color.  We earlier decided on en_passant_color based solely on side-to-move.
	     * If we're encoding a group of plus-pawns of mixed color, then this should always come
	     * out right.  Otherwise, our encoding group is of uniform color, and this check will
	     * reject half of our en passant positions, which might be a place for improvement.
	     */

	    if (tb->pieces[en_passant_pawn].color != en_passant_color) {
		return false;
	    }
	}

	/* We've got all the numbers right, but maybe not in the right order, since each encoding
	 * group is sorted in ascending order.
	 *
	 * Now we have to decide the actual ordering in the piece array.  Normalize_position() sorts
	 * semilegal groups of identical pieces into ascending order, then permutes until all the
	 * pieces are on legal squares.  Mimic this action here.
	 *
	 * XXX don't need to use permutations (at all?) for an encoding group of plus-pawns
	 */

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    if (tb->pieces[piece].permutations) {

		permute_semilegal_group_until_legal(tb, p, piece);

	    }
	}

	return true;
    }

    /* XXX This argument isn't 'const' because it might modify semilegal ranges. */

    combinadic_index(tablebase_t *tb)
    {
	/* Construct smaller_pieces */
	for (int i=0; i<64; i++) {
	    for (int j=0; j<=i; j++) {
		smaller_pieces[i] |= (1ULL << j);
	    }
	}

	if (tb->variant != VARIANT_SUICIDE) {
	    total_legal_king_positions = 0;
	    for (int white_king_square = 0; white_king_square < 64; white_king_square ++) {
		if (! (tb->pieces[tb->white_king].legal_squares & BITVECTOR(white_king_square))) continue;
		for (int black_king_square = 0; black_king_square < 64; black_king_square ++) {
		    if (! (tb->pieces[tb->black_king].legal_squares & BITVECTOR(black_king_square))) continue;
		    if ((tb->symmetry >= 2) && (COL(white_king_square) >= 4)) continue;
		    if ((tb->symmetry >= 4) && (ROW(white_king_square) >= 4)) continue;
		    if ((tb->symmetry == 8) && (ROW(white_king_square) > COL(white_king_square))) continue;
		    if ((tb->symmetry == 8) && (ROW(white_king_square) == COL(white_king_square))
			&& (ROW(black_king_square) > COL(black_king_square))) continue;

		    if (tb->positions_with_adjacent_kings_are_illegal
			&& ! check_king_legality(white_king_square, black_king_square)) continue;

		    white_king_position[total_legal_king_positions] = white_king_square;
		    black_king_position[total_legal_king_positions] = black_king_square;
		    king_index[white_king_square][black_king_square] = total_legal_king_positions;
		    total_legal_king_positions ++;
		}
	    }
	    size = total_legal_king_positions;

	    prev_piece_in_encoding_group[tb->white_king] = -1;
	    next_piece_in_encoding_group[tb->white_king] = -1;
	    prev_piece_in_encoding_group[tb->black_king] = -1;
	    next_piece_in_encoding_group[tb->black_king] = -1;
	} else {
	    size = 1;
	}

	/* Assign encoding groups, usually groups of identical pieces. */

	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    /* We don't really need to assign this for pawns in a PAWNGEN_INDEX, but we do it
	     * anyway to avoid bogus values in these arrays when we compute last_overlapping_group.
	     */

	    /* XXX revisit this when pawngen is refactored */

	    prev_piece_in_encoding_group[piece] = tb->pieces[piece].prev_piece_in_semilegal_group;
	    next_piece_in_encoding_group[piece] = tb->pieces[piece].next_piece_in_semilegal_group;

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    /* An important special case - handle two opposing plus-pawns by combining their
	     * encoding groups, reducing tablebase size.  This also requires extending the semilegal
	     * range of each group.  Note that we only set blocking_piece for plus-pawns, so if two
	     * pieces are mutually blocking, they must be opposing plus-pawns.
	     */

	    if ((tb->pieces[piece].blocking_piece != -1)
		&& (tb->pieces[tb->pieces[piece].blocking_piece].blocking_piece == piece)) {

		int piece2;

		if ((tb->pieces[piece].blocking_piece > piece) && (tb->pieces[piece].color != WHITE)) {
		    throw "Mutually blocking pawns must currently be specified white pawn first";
		}

		if (tb->pieces[piece].blocking_piece > piece) {
		    if (tb->pieces[piece].next_piece_in_semilegal_group != -1) {
			/* should never happen, we should be blocked by a pawn of opposite color */
			throw "BUG: not blocked right";
		    } else {
			next_piece_in_encoding_group[piece] = tb->pieces[piece].blocking_piece;
			for (piece2 = piece; piece2 != -1; piece2 = prev_piece_in_encoding_group[piece2]) {
			    tb->pieces[piece2].semilegal_squares
				|= tb->pieces[tb->pieces[piece].blocking_piece].semilegal_squares;
			}
		    }
		} else {
		    if (tb->pieces[piece].prev_piece_in_semilegal_group != -1) {
			/* should never happen, we should be blocked by a pawn of opposite color */
			throw "BUG: not blocked right";
		    } else {
			prev_piece_in_encoding_group[piece] = tb->pieces[piece].blocking_piece;
			for (piece2 = piece; piece2 != -1; piece2 = next_piece_in_encoding_group[piece2]) {
			    tb->pieces[piece2].semilegal_squares
				|= tb->pieces[tb->pieces[piece].blocking_piece].semilegal_squares;
			}
		    }
		}
	    }
	}

	for (int piece = 0; piece < tb->num_pieces; piece ++) {

	    /* If our semilegal range completely contains the semilegal range of a earlier piece,
	     * that's overlapping, and we'll be able to remove some of our positions since they must
	     * be occupied by the earlier piece.  Later pieces in a set of identical pieces record
	     * the last identical piece as the last overlapping piece.  We remove indices by backing
	     * out to the beginning of our identical set, then going backwards through the earlier
	     * overlapping pieces, decrementing if our piece position is greater than theirs.
	     *
	     * This is not (and can not be) a doubly linked list, since multiple later pieces can
	     * have the same last_overlapping_piece.  Consider an early piece restricted to d4, e4,
	     * d5, e5, a later piece restricted to de, and another later piece restricted to 45.
	     */

	    last_overlapping_piece[piece] = -1;

	    for (int piece2 = piece-1; piece2 >= 0; piece2 --) {
		if ((tb->pieces[piece].semilegal_squares & tb->pieces[piece2].semilegal_squares) == tb->pieces[piece2].semilegal_squares) {
		    last_overlapping_piece[piece] = piece2;
		    break;
		}
	    }

	    /* Back out to the first piece of this encoding group and record the last overlapping
	     * piece for this encoding group.  Not doing this was the bug in 1.759 exposed by
	     * attempting to build kqqk.
	     */

	    int piece2;
	    for (piece2=piece; prev_piece_in_encoding_group[piece2] != -1;
		 piece2 = prev_piece_in_encoding_group[piece2]);

	    last_overlapping_group[piece] = last_overlapping_piece[piece2];

	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;

	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;

	    int piece_in_set;

	    if (prev_piece_in_encoding_group[piece] == -1) {
		piece_in_set = 1;
	    } else if (prev_piece_in_encoding_group[piece] == piece-1) {
		piece_in_set ++;
	    } else {
		fatal("Combinadic3/4 index requires encoding groups to be adjacent in index\n");
	    }

	    /* Now number the squares in the piece's semilegal range, and construct tables to
	     * translate back and forth between this numbering and the board squares.  We count
	     * semilegal and not legal squares here because the pair encoding used for identical
	     * pieces assumes that both pieces occupy the same range of squares.  We also assign
	     * squares for en passant capturable pawns by using square numbers in the first row
	     * (i.e, less than 8), since pawns can never be there.
	     */

	    for (int square = 0; square < 64; square ++) {

		if ((tb->pieces[piece].semilegal_squares & BITVECTOR(square))
		    || ((tb->pieces[piece].piece_type == PAWN)
			&& (square < 8)
			&& (tb->pieces[piece].semilegal_squares
			    & BITVECTOR(rowcol2square(tb->pieces[piece].color == WHITE ? 3 : 4, square))))) {

		    value[piece][square] = total_legal_positions[piece];
		    piece_position[piece][total_legal_positions[piece]] = square;

		    piece_index[piece][total_legal_positions[piece]]
			= choose(total_legal_positions[piece], piece_in_set) * size;

		    total_legal_positions[piece] ++;
		} else {
		    /* This value should never get used. */
		    value[piece][square] = ILLEGAL_POSITION;
		}

	    }

	    /* Now back out any values that we saved because of any earlier overlapping pieces.  If
	     * we have a single earlier overlapping piece, for example, we'll never encode with the
	     * last value because the presence of the other piece would force that value to be
	     * decremented.
	     */

	    total_legal_piece_values[piece] = total_legal_positions[piece];

	    for (piece2 = piece; prev_piece_in_encoding_group[piece2] != -1; piece2 = prev_piece_in_encoding_group[piece2]);
	    for (piece2 = last_overlapping_piece[piece2]; piece2 != -1; piece2 = last_overlapping_piece[piece2]) {
		total_legal_piece_values[piece] --;
	    }

	    if ((prev_piece_in_encoding_group[piece] != -1)
		&& (total_legal_positions[piece]
		    != total_legal_positions[prev_piece_in_encoding_group[piece]])) {
		fatal("BUG: Identical pieces don't have the same number of total semilegal positions\n");
	    }

	    if ((prev_piece_in_encoding_group[piece] != -1)
		&& (total_legal_piece_values[piece]
		    != total_legal_piece_values[prev_piece_in_encoding_group[piece]])) {
		fatal("BUG: Identical pieces don't have the same number of encoding values\n");
	    }

	    if (next_piece_in_encoding_group[piece] == -1) {
		size *= choose(total_legal_piece_values[piece], piece_in_set);
	    }

	}

	/* Now we pad the tail end of the index arrays with 'size'.  This allows us to search the
	 * table using std::lower_bound without having to worry about where its actual end is, which
	 * will typically be before its physical end.
	 */

	for (int piece = 0; piece < tb->num_pieces; piece ++) {
	    if ((piece == tb->white_king) || (piece == tb->black_king)) continue;
	    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN)) continue;
	    for (int value = total_legal_piece_values[piece]; value < 64; value ++) {
		piece_index[piece][value] = size;
	    }
	}
    }
};

index_t normalized_position_to_index(const tablebase_t *tb, local_position_t *position)
{
    index_t index;
    int piece;

    /* This is a good place to make this check, since all of the position-to-index code passes
     * through here.
     */

    if (tb->positions_with_adjacent_kings_are_illegal
	&& ! check_king_legality(position->piece_position[tb->white_king], position->piece_position[tb->black_king]))
	return INVALID_INDEX;

    if ((tb->index_type == NO_EN_PASSANT_INDEX) && (position->en_passant_square != ILLEGAL_POSITION))
	return INVALID_INDEX;

    /* Recompute board_vector, and check for legality of piece positions */

    position->board_vector = 0;

    for (piece = 0; piece < tb->num_pieces; piece ++) {

	if ((position->piece_position[piece] < 0) || (position->piece_position[piece] > 63)
	    || !(tb->pieces[piece].legal_squares & BITVECTOR(position->piece_position[piece]))) {
	    /* This can happen if we're probing a restricted tablebase */
	    return INVALID_INDEX;
	}

	/* Blocking pawns.  Reject any position where a pawn has "hopped" over the enemy pawn
	 * blocking it.
	 */

	if ((tb->pieces[piece].piece_type == PAWN) && (tb->pieces[piece].blocking_piece != -1)) {
	    if (tb->pieces[piece].color == WHITE) {
		if (position->piece_position[piece] > position->piece_position[tb->pieces[piece].blocking_piece]) {
		    return INVALID_INDEX;
		}
	    } else {
		if (position->piece_position[piece] < position->piece_position[tb->pieces[piece].blocking_piece]) {
		    return INVALID_INDEX;
		}
	    }
	}

	if (position->board_vector & BITVECTOR(position->piece_position[piece])) return INVALID_INDEX;
	position->board_vector |= BITVECTOR(position->piece_position[piece]);
    }

    /* Check board_vector to make sure an en passant position is legal */

    if (position->en_passant_square != ILLEGAL_POSITION) {
	if (position->board_vector & BITVECTOR(position->en_passant_square)) return INVALID_INDEX;
	if (position->side_to_move == WHITE) {
	    if (position->board_vector & BITVECTOR(position->en_passant_square + 8)) return INVALID_INDEX;
	} else {
	    if (position->board_vector & BITVECTOR(position->en_passant_square - 8)) return INVALID_INDEX;
	}
    }

    /* Encode pieces and non-pawngen pawns using whatever index function was selected */

    index = tb->encoding->position_to_index(tb, position);

    /* Pawngen - the index encoding function skipped any pawngen pawns */

    if (tb->pawngen) {

	pawn_position pawns;

	for (int piece = 0; piece < tb->num_pieces; piece ++) {
	    if (tb->pieces[piece].piece_type == PAWN) {
		if (tb->pieces[piece].color == WHITE) {
		    pawns.add_white_pawn(position->piece_position[piece]);
		} else {
		    pawns.add_black_pawn(position->piece_position[piece]);
		}
	    }
	}
	pawns.en_passant_square = position->en_passant_square;

	auto it = std::lower_bound(tb->pawngen->pawn_positions_by_position.begin(),
				   tb->pawngen->pawn_positions_by_position.end(),
				   pawns, pawn_position_fast_compare);

	/* In the course of normal program operation, we should never generate invalid pawn
	 * positions, but it can happen during testing with check_1000_positions().  So invalid pawn
	 * positions just return INVALID_INDEX.
	 *
	 * XXX throw errors more aggressively here during actual program operation
	 */

	if (it == tb->pawngen->pawn_positions_by_position.end()) {
	    return INVALID_INDEX;
	} else if (*it != pawns) {
	    return INVALID_INDEX;
	} else {
	    index += tb->encoding->size * it->index;
	}

    }

    /* Now encode side-to-move (if needed).  Other code, like index_to_side_to_move(), assumes that
     * side-to-move is the index's LSB.
     */

    if (tb->encode_stm) {
	index <<= 1;
	index += position->side_to_move;  /* WHITE is 0; BLACK is 1 */
    }

    /* Multiplicity - number of non-identical positions that this index corresponds to.  We want to
     * update the original position structure that got passed in.
     */

    if ((tb->symmetry == 8)
	&& ((ROW(position->piece_position[tb->white_king]) != COL(position->piece_position[tb->white_king]))
	    || (ROW(position->piece_position[tb->black_king]) != COL(position->piece_position[tb->black_king])))) {
	position->multiplicity = 2;
    } else {
	position->multiplicity = 1;
    }

    /* position->reflection was set in normalize_position.  Maybe we should have a flag to specify
     * if position has been normalized?
     */

    position->index = index;
    position->valid = true;
    position->decoded = true;

    return index;
}

index_t local_position_to_index(const tablebase_t *tb, local_position_t *original)
{
    index_t index;

    if (original->decoded) return original->index;

    /* We don't want to change around the original position, during these next transformations, so
     * we use a copy of it.  We do, however, update the multiplicity in the original structure.
     */

    local_position_t copy = *original;

    normalize_position(tb, &copy);

    index = normalized_position_to_index(tb, &copy);

    original->multiplicity = copy.multiplicity;

    original->valid = copy.valid;
    original->index = copy.index;
    original->reflection = copy.reflection;
    original->decoded = copy.decoded;

    return index;
}

bool index_to_local_position(const tablebase_t *tb, index_t index, int reflection, local_position_t *position)
{
    int ret;
    int piece, piece2;

    bool decoded = position->decoded;

    if (index >= tb->num_indices) return false;

    /* The 'reflection' argument is either always REFLECTION_NONE, or changes faster than the index,
     * since we compute multiple reflections for every index.  Since 'reflection's behavior is
     * fairly predictable, I expect branch prediction to blow through this loop correctly every
     * time, though the appearance of an invalid index that is not 'unreflected_valid' might
     * upset that.
     */

    if (position->decoded && (index == position->index)) {
	if (reflection == position->reflection) return position->valid;
	if (! position->unreflected_valid) return false;
	goto do_reflection;
    }

    /* There are a bunch of 'return false' statements later in this routine.  We now set the values
     * we want if the routine returns false, and save the value of the 'decoded' flag.
     */

    position->index = index;
    position->reflection = reflection;
    position->valid = false;
    position->unreflected_valid = false;
    position->decoded = true;

    /* Side-to-move, if present, is always LSB.  Branch prediction can probably get this right
     * during initialization and futurebase back-prop, but this code is likely to trigger a pipeline
     * stall during intratable passes, when the LSB changes seemingly at random, unless the position
     * favors one player over another, in which case one value of side-to-move will dominate each
     * pass.
     */

    if (tb->encode_stm) {
	position->side_to_move = index % 2;
	index >>= 1;
    } else {
	position->side_to_move = WHITE;
    }

    /* Extract pawngen pawn encoding from the most significant bits */

    if (tb->pawngen) {

	/* Divisions are slow, plus we expect the pawngen field to vary slowly, because it's encoded
	 * in the MSBs.  Therefore, optimize this code to store the results of the division in the
	 * position structure, and move forward (but not backward) in the index by adding and
	 * incrementing.  We optimizing for the case where we've got lot of indices being processed,
	 * so the index changes slowly as we move through the tablebase, as opposed to only a few
	 * indices being processed (like at the end of a calculation), when we've moving quickly
	 * through the tablebase.  I expect branch prediction to turn this block of code into a nop
	 * when we're moving slowly through a tablebase.
	 */

	bool pawngen_update_needed = false;

	if ((! decoded) || (index < position->pawngen_base_index)) {
	    position->pawngen_index = index / tb->encoding->size;
	    position->pawngen_base_index = position->pawngen_index * tb->encoding->size;
	    pawngen_update_needed = true;
	} else {
	    while (index >= position->pawngen_base_index + tb->encoding->size) {
		    position->pawngen_base_index += tb->encoding->size;
		    position->pawngen_index ++;
		    pawngen_update_needed = true;
	    }
	}

	/* Do we actually need to copy the pawn positions into the piece_position array?
	 *
	 * Not if pawngen_index hasn't changed.
	 *
	 * SYMMETRY AND PAWNGEN
	 *
	 * We'd really like to copy into the unreflected_piece_position array, but then we'd like
	 * the method call to index_to_position to copy into that array as well.  Then we could be
	 * sure that the reflection code hasn't mucked around with the contents of piece_position[].
	 * So long as symmetry is not allowed with pawngen, we'll never use reflection and pawngen
	 * together, so it's not an issue.
	 *
	 */

	if (pawngen_update_needed) {

	    /* Conceptually, this code only runs for pawns, but we're going to fill in the rest of
	     * the piece_position array in the index_to_position() method call below, so maybe our
	     * compiler can optimize this a bit without the if condition on piece_type.
	     */

	    if ( false ) {
		for (piece = 0; piece < tb->num_pieces; piece ++) {
		    if (tb->pieces[piece].piece_type == PAWN) {
			position->piece_position[piece]
			    = tb->pawngen->pawn_positions_by_index[position->pawngen_index].position[piece];
		    }
		}
	    } else {
		for (piece = 0; piece < tb->num_pieces; piece ++) {
		    position->piece_position[piece]
			= tb->pawngen->pawn_positions_by_index[position->pawngen_index].position[piece];
		}
	    }

	    position->en_passant_square = tb->pawngen->pawn_positions_by_index[position->pawngen_index].en_passant_square;

	}

	index -= position->pawngen_base_index;

	/* If we've got an en passant pawn, make sure that it is the right color, i.e, the
	 * opposite color of the side to move.  This check will reject half of our en passant
	 * positions, which might be a place for improvement.
	 */

	if (position->en_passant_square != ILLEGAL_POSITION) {
	    if (tb->pieces[tb->pawngen->pawn_positions_by_index[position->pawngen_index].en_passant_pawn].color == position->side_to_move) {
		return false;
	    }
	}
    } else {
	position->en_passant_square = ILLEGAL_POSITION;
    }

    /* Encode pieces and non-pawngen pawns using selected index function.
     *
     * This function is expected to set the piece_position[] array and en_passant_square in
     * 'position'.  side_to_move is already set, and has been divided out of 'index', if it was
     * encoded at all.  If pawngen is in use, piece_position[] has been partially filled in (with
     * pawns) and en_passant_square is already set.
     */

    ret = tb->encoding->index_to_position(tb, index, position);

    if (!ret) return false;

    /* Blocking pawns.  Reject any position where a pawn has "hopped" over the enemy piece blocking
     * it.
     */

    for (piece = 0; piece < tb->num_pieces; piece++) {
	if ((tb->pieces[piece].piece_type == PAWN) && (tb->pieces[piece].blocking_piece != -1)) {
	    if (tb->pieces[piece].color == WHITE) {
		if (position->piece_position[piece] > position->piece_position[tb->pieces[piece].blocking_piece]) {
		    return false;
		}
	    } else {
		if (position->piece_position[piece] < position->piece_position[tb->pieces[piece].blocking_piece]) {
		    return false;
		}
	    }
	}
    }

    /* Suicide analysis allows adjacent kings.  Otherwise, we require this check. */

    /* XXX these two checks, and the one before it, might not be needed for a combinadic index */

    if (tb->positions_with_adjacent_kings_are_illegal
	&& ! check_king_legality(position->piece_position[tb->white_king], position->piece_position[tb->black_king]))
	return false;

    if ((tb->symmetry == 8)
	&& (ROW(position->piece_position[tb->white_king]) == COL(position->piece_position[tb->white_king]))
	&& (ROW(position->piece_position[tb->black_king]) > COL(position->piece_position[tb->black_king])))
	return false;

    /* Multiplicity - number of non-identical positions that this index corresponds to */

    if ((tb->symmetry == 8)
	&& ((ROW(position->piece_position[tb->white_king]) != COL(position->piece_position[tb->white_king]))
	    || (ROW(position->piece_position[tb->black_king]) != COL(position->piece_position[tb->black_king])))) {
	position->multiplicity = 2;
    } else {
	position->multiplicity = 1;
    }

    /* We've made it up to reflection.  Store a copy of the unreflected positions to speed up later
     * calls to this function that only change reflection, and set 'unreflected_valid' true.
     *
     * XXX if the tablebase has no reflection, we should be able to avoid this copy, but then have
     * to use piece_position[] below, instead of unreflected_piece_position[].
     */

    position->unreflected_valid = true;
    position->unreflected_piece_position = position->piece_position;
    position->unreflected_en_passant_square = position->en_passant_square;

 do_reflection:

    /* If a position in an 8-way symmetric tablebase has multiplicity 1, then we don't want to
     * diagonally reflect it, because there's another index that corresponds to the reflected
     * position.  Only 8-way tablebases would request diagonal reflection anyway.
     */

    if ((reflection & REFLECTION_DIAGONAL) && (position->multiplicity == 1)) return false;

    /* Apply reflection, check for an illegally positioned piece or two pieces on the same square,
     * set bits in the board vectors.
     */

    position->board_vector = 0;
    position->PTM_vector = 0;

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	position->piece_position[piece] = reverse_reflection[reflection & 7][position->unreflected_piece_position[piece]];

	/* An important check for restricted pieces, and one of most important, too, because
	 * this function is used during initialization to decide which indices are legal and
	 * which are not.
	 *
	 * For 'combinadic' and 'compact' index types, this test can fire because we counted
	 * semilegal positions to encode with, not legal positions.  It should never fire for the
	 * 'simple' index type, which only encodes legal positions.  'naive' and 'naive2'
	 * make no attempt to reject illegal positions, so of course it fires for them.
	 */

	if (!(tb->pieces[piece].legal_squares & BITVECTOR(position->piece_position[piece]))) {
	    return false;
	}

	/* Is there another piece already on this square? */
	if (position->board_vector & BITVECTOR(position->piece_position[piece])) {
	    position->unreflected_valid = false;
	    return false;
	}

	position->board_vector |= BITVECTOR(position->piece_position[piece]);
	if (tb->pieces[piece].color == position->side_to_move) {
	    position->PTM_vector |= BITVECTOR(position->piece_position[piece]);
	}
    }

    if (position->unreflected_en_passant_square != ILLEGAL_POSITION) {
	position->en_passant_square = reverse_reflection[reflection & 7][position->unreflected_en_passant_square];
    }

    if (reflection & REFLECTION_COLOR) {
	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if (tb->pieces[piece].color_symmetric_transpose > piece) {
		position->piece_position[piece] = 63 - position->piece_position[piece];
		std::swap(position->piece_position[piece],
			  position->piece_position[tb->pieces[piece].color_symmetric_transpose]);
		position->piece_position[piece] = 63 - position->piece_position[piece];
	    }
	}
	if (position->en_passant_square != ILLEGAL_POSITION) {
	    position->en_passant_square = 63 - position->en_passant_square;
	}
	position->side_to_move = BLACK;
    }

    /* If there is an en passant capturable pawn in this position, then there can't be anything on
     * the capture square or on the square right behind it (where the pawn just came from), or its
     * an illegal position.
     */

    if (position->en_passant_square != ILLEGAL_POSITION) {
	if (position->board_vector & BITVECTOR(position->en_passant_square)) return false;
	if (position->side_to_move == WHITE) {
	    if (position->board_vector & BITVECTOR(position->en_passant_square + 8)) return false;
	} else {
	    if (position->board_vector & BITVECTOR(position->en_passant_square - 8)) return false;
	}
    }

    /* permuted_piece is used to track the changes that happen after index-to-position and before
     * position-to-index.
     */

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	position->permuted_piece[piece] = piece;
    }

    position->valid = true;
    return true;
}

index_t num_indices(tablebase_t * tb)
{
    return tb->num_indices;
}

int index_to_side_to_move(tablebase_t *tb, index_t index)
{
    if (tb->encode_stm) {
	return index & 1;
    } else {
	return WHITE;
    }
}

/* check_1000_positions(); check_1000_indices() - used just to double check the code above. */

int check_1000_positions(tablebase_t *tb)
{
    local_position_t position1(tb);
    local_position_t position2(tb);
    index_t index;
    int positions;
    int piece;
    int ret = 1;

    for (positions=0; positions < 1000; positions ++) {

	memset(&position1, 0, sizeof(position1));

	position1.side_to_move = rand() % 2;
	position1.en_passant_square = ILLEGAL_POSITION;
	position1.decoded = false;

    retry:
	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    do {
		position1.piece_position[piece] = rand() % 64;
	    } while (! (BITVECTOR(position1.piece_position[piece]) & tb->pieces[piece].legal_squares));
	}

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if ((tb->pieces[piece].prev_piece_in_semilegal_group != -1) &&
		(position1.piece_position[piece] <=
		 position1.piece_position[tb->pieces[piece].prev_piece_in_semilegal_group])) goto retry;
	}

	normalize_position(tb, &position1);

	/* index_to_local_position is expected to initialize permuted_pieces to default */

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    position1.permuted_piece[piece] = piece;
	}

	index = local_position_to_index(tb, &position1);

	if (index != INVALID_INDEX) {

	    if (!index_to_local_position(tb, index, REFLECTION_NONE, &position2)) {
		fatal("Mismatch in check_1000_positions()\n");
		ret = 0;
	    } else {

		/* PTM_vector wasn't set in position1, so don't check it now */

		if ((position1.board_vector != position2.board_vector)
		    || (position1.side_to_move != position2.side_to_move)
		    || (position1.en_passant_square != position2.en_passant_square)
		    || (position1.multiplicity != position2.multiplicity)) {
		    fatal("Mismatch in check_1000_positions()\n");
		    ret = 0;
		}

		for (piece = 0; piece < tb->num_pieces; piece ++) {
		    if ((position1.piece_position[piece] != position2.piece_position[piece])
			|| (position1.permuted_piece[piece] != position2.permuted_piece[piece])) {
			fatal("Mismatch in check_1000_positions()\n");
			ret = 0;
		    }
		}
	    }
	}
    }

    return ret;
}

int check_1000_indices(tablebase_t *tb)
{
    local_position_t position(tb);
    index_t index;
    index_t index2;
    int positions;
    int ret = 1;

    for (positions=0; positions < 1000; positions ++) {

	index = rand() % (tb->num_indices);

	if (index_to_local_position(tb, index, REFLECTION_NONE, &position)) {
	    index2 = local_position_to_index(tb, &position);
	    if (index != index2) {
		fatal("Mismatch in check_1000_indices() %" PRIindex "\n", index);
		ret = 0;
	    }
	}
    }

    return ret;
}

/***** LOCAL POSITION MOVE PIECE *****/

void local_position_t::flip_side_to_move(void)
{
    if (side_to_move == WHITE) side_to_move = BLACK;
    else side_to_move = WHITE;

    if (decoded && valid && tb->encode_stm) {
	index ^= 1;
    } else {
	decoded = false;
    }

};

void local_position_t::move_piece(int piece, int destination_square) {

    if (!decoded || !valid) {
	/* XXX should never happen.  We should only call this routine on a valid position. */
	/* XXX does happen when we've done something like set_en_passant_square first */
	board_vector &= ~BITVECTOR(piece_position[piece]);
	piece_position[piece] = destination_square;
	board_vector |= BITVECTOR(piece_position[piece]);
	decoded = false;
	return;
    }

    if (tb->pawngen && (tb->pieces[piece].piece_type == PAWN) && (reflection == REFLECTION_NONE)) {
	/* Moving a pawngen pawn.  All we have to do is adjust the pawngen field in the index, which
	 * is always the most significant bits, and the position can remain 'decoded'.
	 */
	board_vector &= ~BITVECTOR(piece_position[piece]);
	piece_position[piece] = destination_square;
	if (board_vector & BITVECTOR(piece_position[piece])) {
	    /* If we're moving a piece to an occupied space, then the position is invalid since we have
	     * overlapping pieces.  We usually don't call this routine in this case, but it's best to
	     * check for it here.  Flag the position un-decoded and fix it up later.
	     */
	    decoded = false;
	    return;
	}
	board_vector |= BITVECTOR(piece_position[piece]);

	pawn_position& pp = tb->pawngen->pawn_positions_by_index[pawngen_index];

	if (pp.prev_position[piece] == destination_square) {
	    pawngen_index += pp.delta_pawngen_index[piece];
	    pawngen_base_index += pp.delta_pawngen_index[piece] * tb->encoding->size;
	    index += pp.delta_pawngen_index[piece] * tb->encoding->size * (tb->encode_stm ? 2 : 1);
	} else {
	    decoded = false;
	}
    } else {
	tb->encoding->move_piece(tb, this, piece, destination_square);
    }
}

/***** XML TABLEBASE INTERACTION *****/

/* xmlpp::Element's eval_to_number method has some serious drawbacks.  First, if the XPath
 * expression evaluates empty, the method returns nan, which converts to an enormous negative
 * integer number.  I always want empty XPaths to evaluate to zero instead.  Also, one place in
 * older hoffman tablebases (the <tablebase> 'offset' attribute) is specified in hexadecimal
 * notation, which doesn't convert right.  This function fixes both of these problems.
 */

int eval_to_number_or_zero(xmlpp::Node *node, std::string xpath)
{
    Glib::ustring str = node->eval_to_string(xpath);
    return (str != "") ? std::stoi(str, 0, 0) : 0;
}

/* parse_format()
 *
 * Parse an XML format specification (for a dynamic structure) into a format structure.  A simple
 * explicit XML format looks something like:
 *
 *   <format>
 *      <dtm bits="8"/>
 *   </format>
 *
 * An implicit format is just a <dtm/> tag without an enclosing format element.
 *
 * This function can be called on either a format element (the explicit case), or the tablebase
 * element itself (the implicit case).
 */

bool parse_format(xmlpp::Element * formatNode, struct format * format)
{
    auto children = formatNode->get_children();

    memset(format, 0, sizeof(struct format));

    format->dtm_offset = -1;
    format->flag_offset = -1;
    format->basic_offset = -1;

    for (auto child = children.begin(); child != children.end(); child ++) {
	xmlpp::Element * child_element = dynamic_cast<xmlpp::Element *>(*child);
	if (child_element != nullptr) {
	    int bits = eval_to_number_or_zero(child_element, "@bits");
	    try {
		// this might throw an exception - see below
		int format_field = format_fields.at(child_element->get_name());

		switch (format_field) {
		case FORMAT_FIELD_DTM:
		    format->dtm_offset = 0;
		    format->dtm_bits = bits;
		    break;
		case FORMAT_FIELD_FLAG:
		    format->flag_offset = 0;
		    bits = 1;
		    format->flag_type = format_flag_types.at(child_element->get_attribute_value("type"));
		    break;
		case FORMAT_FIELD_BASIC:
		    format->basic_offset = 0;
		    bits = 2;
		    break;
		default:
		    fatal("Unknown field in format\n");
		    return false;
		}

		format->bits = bits;
	    } catch (std::out_of_range ex) {
		/* ignore the exception, since we're scanning elements that might not be format fields */
	    }
	}
    }

    return (format->dtm_offset != -1) || (format->bits != 0);
}

int factorial(int n) {
    return (n <= 2) ? n : (n * factorial(n-1));
}

/* Determine whether the tablebase is color symmetric, meaning that we can flip the colors of all of
 * the pieces and get a position in the same tablebase.  kqkq is color symmetric (barring piece
 * restrictions), while kqqkq is not (it would flip into kqkqq).  Color symmetric tablebases do not
 * have to encode side-to-move, cutting their index space in half, a big win.  If the tablebase is
 * color symmetric, we also set up the color_symmetric_transpose array for later use in doing the
 * flips, using only transpositions.
 *
 * XXX we can enhance this function to handle piece restrictions.
 */

bool tablebase_t::is_color_symmetric()
{
    bool pieces_used[MAX_PIECES] = {false};

    for (int piece = 0; piece < num_pieces; piece ++) {

	int piece2;

	if (pieces_used[piece]) continue;

	if ((pieces[piece].legal_squares != ALL_ONES_BITVECTOR)
	    && (pieces[piece].legal_squares != LEGAL_PAWN_BITVECTOR))
	    return false;

	for (piece2 = 0; piece2 < num_pieces; piece2 ++) {

	    if (pieces_used[piece2]) continue;

	    if ((pieces[piece].color != pieces[piece2].color)
		&& (pieces[piece].piece_type == pieces[piece2].piece_type)
		&& (pieces[piece].legal_squares == pieces[piece2].legal_squares)) {

		pieces[piece].color_symmetric_transpose = piece2;
		pieces[piece2].color_symmetric_transpose = piece;
		pieces_used[piece] = true;
		pieces_used[piece2] = true;
		break;
	    }
	}

	if (piece2 == num_pieces) return false;
    }

    return true;
}

/* Parses XML, creates a tablebase structure corresponding to it, and returns it.
 *
 * I use a DTD and validate the XML input, so there's very little error checking here.  The idea is
 * that the validation provides most of the error checks.
 *
 * There are two types of XML files - control files, which are pure XML files controlling a program
 * run, and futurebases, which are computed tablebases with an XML prefix followed by data.  There's
 * very little difference between the two for XML parsing, but the second argument is a flag to
 * distinguish between them.
 */

piece::piece(xmlpp::Node * xml)
{
    color = colors.at(xml->eval_to_string("@color"));
    piece_type = piece_name.at(xml->eval_to_string("@type"));
    location = xml->eval_to_string("@location");

    if (xml->eval_to_string("@index-ordering") == "reverse") {
	fatal("reverse index ordering no longer supported\n");
    }

    if (location == "") {
	if (piece_type == PAWN) {
	    legal_squares = LEGAL_PAWN_BITVECTOR;
	} else {
	    legal_squares = ALL_ONES_BITVECTOR;
	}
    } else {
	int j = 0;
	legal_squares = 0;
	while ((location[j] >= 'a') && (location[j] <= 'h')
	       && (location[j+1] >= '1') && (location[j+1] <= '8')) {
	    legal_squares
		|= BITVECTOR(rowcol2square(location[j+1] - '1', location[j] - 'a'));
	    j += 2;
	    if ((piece_type == PAWN) && (j == 2) && (location[j] == '+')) j++;
	    while (location[j] == ' ') j ++;
	}
	if (location[j] != '\0') {
	    fatal("Illegal piece location (%s)\n", location.c_str());
	}
	if ((piece_type == PAWN) && (legal_squares & ~LEGAL_PAWN_BITVECTOR)) {
	    fatal("Illegal pawn location (%s)\n", location.c_str());
	}
    }
}

void tablebase_t::parse_XML(std::istream *instream)
{
    xmlpp::DtdValidator dtd;

    xmlpp::NodeSet result;
    xmlpp::Element * tablebase;

    Glib::ustring index;
    xmlpp::Element * index_node;

    Glib::ustring format_str;

    int piece, piece2, square, white_king_square, black_king_square;
    int pass;

    // XXX this might throw an exception

    parser->parse_stream(*instream);
    xml = parser->get_document();

    /* load the DTD from memory */

    dtd.parse_memory(tablebase_dtd);

    /* check if validation suceeded */
    // XXX add command line option to dump DTD

    if (! dtd.validate(xml)) {
	throw nested_exception("XML failed DTD validatation");
    }

    /* Fetch tablebase from XML */

    result = xml->get_root_node()->find("//tablebase");
    tablebase = (xmlpp::Element *) result[0];

    /* Figure out which version of chess we're playing... */

    variant = variant_names.at(tablebase->eval_to_string("//variant/@name"));

    switch (variant) {

    case VARIANT_NORMAL:
	positions_with_adjacent_kings_are_illegal = true;
	break;

    case VARIANT_SUICIDE:
	positions_with_adjacent_kings_are_illegal = false;
	promotion_possibilities = 5;	/* A global var, but all futurebases have to use the same variant */
	break;

    }

    if (! tablebase->find("//@pawngen-condition").empty()) {
	fatal("'pawngen-condition' attribute disallowed by Hoffman; preprocess with pawngen first\n");
    }

    /* Some statistics we'll use if this is a futurebase */

    max_dtm = eval_to_number_or_zero(tablebase, "//max-dtm");
    min_dtm = eval_to_number_or_zero(tablebase, "//min-dtm");

    /* If there's a stalemate prune, fetch it */

    result = tablebase->find("//prune[attribute::move='stalemate']");
    if (! result.empty()) {
	stalemate_prune_type = restriction_types.at(result[0]->eval_to_string("@type"));
	stalemate_prune_color = colors.at(result[0]->eval_to_string("@color"));
	if (stalemate_prune_type != RESTRICTION_CONCEDE) {
	    fatal("Stalemates can only be pruned to 'concede'\n");
	}
    } else {
	stalemate_prune_type = RESTRICTION_NONE;
    }

    /* Fetch the pieces from the XML */

    result = tablebase->find("//piece | //pawngen");

    white_king = -1;
    black_king = -1;

    num_pieces_by_color[WHITE] = 0;
    num_pieces_by_color[BLACK] = 0;
    num_pieces = 0;

    for (auto it = result.begin(); it != result.end(); it ++) {

	if ((*it)->get_name() == "piece") {

	    struct piece new_piece(*it);

	    if (variant != VARIANT_SUICIDE) {

		if ((new_piece.color == WHITE) && (new_piece.piece_type == KING)) {
		    if (white_king != -1) {
			fatal("Must have one white king and one black one!\n");
		    } else {
			white_king = pieces.size();
		    }
		}

		if ((new_piece.color == BLACK) && (new_piece.piece_type == KING)) {
		    if (black_king != -1) {
			fatal("Must have one white king and one black one!\n");
		    } else {
			black_king = pieces.size();
		    }
		}

	    }

	    num_pieces_by_color[new_piece.color] ++;

	    num_pieces ++;

	    pieces.push_back(new_piece);

	} else {

	    parse_pawngen_element(*it);

	}

    }

    if ((num_pieces_by_color[WHITE] == 0) || (num_pieces_by_color[BLACK] == 0)) {
	throw "Must have at least one white piece and one black piece!";
    }

    if (variant != VARIANT_SUICIDE) {
	if ((white_king == -1) || (black_king == -1)) {
	    throw "Must have one white king and one black one!";
	}
    }

    if (num_pieces > MAX_PIECES) {
	throw "Too many pieces (" + boost::lexical_cast<std::string>(MAX_PIECES) + "compiled-in maximum)!";
    }

    /* We quietly skipped over any plus signs after pawn locations, which mean that the pawn should
     * be advanced as far as possible along its file.  For example, if there is a white pawn at
     * "h2+" and a black pawn at "h7+", we want the white pawn's legal squares expanded all the way
     * to h6, and the black pawn's legal squares expanded all the way to h3.  We couldn't process
     * them immediately because without having parsed all the pieces we didn't know if anything was
     * blocking the file.
     *
     * Having now parsed all of the pieces, go back and expand the legal squares of any "plus pawns"
     * by first running through the pieces and looking for any blocking the plus pawn.  Then expand
     * the plus-pawn's restrictions up its file until it hits the blocking piece.
     *
     * To handle doubled pawns, we do this twice, figuring that we'll expand the leading pawn first,
     * then pick up the trailing pawn on the second pass.  To handle tripled pawns, we need three
     * passes.  To handled quadrupled (!) pawns, we need four.  Simplest is to just run the loop
     * once for however many pieces we've got.
     *
     * What if we specified a black pawn as "a7+ b4+" and a white pawn as "b2+"?  Then the black
     * pawn would be blocked by at b3 by the white pawn, even though the white pawn could move on
     * past (it wouldn't be blocked by the multiple-file black pawn).  I handle this complex case by
     * not allowing plus pawns to start on more than one square.
     *
     * Perhaps this seems like an absurd amount of complexity to introduce for a special case.  In
     * fact, pawns blocking each other are a not-so-special case and I don't see how they can be
     * handled as efficiently as we'd like without all of this.  In particular, we needn't regard
     * pawn moves onto blocked squares as futuremoves, and by pairing opposing pawns in indices we
     * can cut tablebase sizes by a factor of two for each pair.
     */

    /* First, compute which piece, if any, is blocking each plus-pawn.  We do this by stripping out
     * from the blocking piece's legal squares all possible positions of the plus-pawn as we move it
     * forward.  This ensures that a white pawn restricted to "g2 g3", say, will block a black
     * plus-pawn "g7+".  This is OK for non-pawns, too, since knights are the only pieces that can
     * jump and a knight could never be frozen purely along a single file.  Plus-pawns themselves,
     * since their legal_squares haven't been expanded yet, block other pawn-pawns at their origin
     * square.
     */

    for (piece = 0; piece < num_pieces; piece ++) {

	pieces[piece].blocking_piece = -1;

	if (pieces[piece].piece_type == PAWN) {

	    uint64_t pawn_positions = 0xffffffffffffffffLL;

	    if ((pieces[piece].location != "") && (pieces[piece].location[2] == '+')) {

		int square = rowcol2square(pieces[piece].location[1] - '1', pieces[piece].location[0] - 'a');
		int dir = (pieces[piece].color == WHITE) ? 8 : -8;

		pawn_positions &= ~BITVECTOR(square);
		square += dir;

		while ((square < 56) && (square > 7) && (pieces[piece].blocking_piece == -1)) {
		    for (piece2 = 0; piece2 < num_pieces; piece2 ++) {
			if ((pawn_positions & pieces[piece2].legal_squares) == BITVECTOR(square)) {
			    pieces[piece].blocking_piece = piece2;
			}
		    }
		    pawn_positions &= ~BITVECTOR(square);
		    square += dir;
		}

		/* This next batch of code is here because we (currently) sort 'identical' pieces
		 * into increasing order when we normalize a position.  Since doubled pawns are
		 * 'identical', the easiest way to handle them is to insure that they always appear
		 * in the correct order in the piece list.
		 */

		if ((pieces[piece].blocking_piece != -1) && (pieces[pieces[piece].blocking_piece].piece_type == PAWN)
		    && (pieces[pieces[piece].blocking_piece].color == pieces[piece].color)) {
		    if ((pieces[piece].color == WHITE) && (pieces[piece].blocking_piece < piece)) {
			fatal("Doubled pawns must (currently) appear in board order in piece list\n");
		    }
		    if ((pieces[piece].color == BLACK) && (pieces[piece].blocking_piece > piece)) {
			fatal("Doubled pawns must (currently) appear in board order in piece list\n");
		    }
		}

	    } else {
		/* XXX This is a pawn, but it isn't a plus-pawn.  It can be blocked if it is frozen.
		 * This matters because if a pawn is blocked, then we shouldn't complain if there is
		 * no futurebase or pruning statement for its forward move, but it isn't a big deal,
		 * since we can always just add an extra pruning statement for the non-move.
		 */
	    }
	}
    }

    /* Now advance plus-pawns as far as they can go without hitting the blocking piece. */

    for (pass = 0; pass < num_pieces; pass ++) {

	for (piece = 0; piece < num_pieces; piece ++) {

	    if (pieces[piece].piece_type == PAWN) {

		if ((pieces[piece].location != "") && (pieces[piece].location[2] == '+')) {

		    int square = rowcol2square(pieces[piece].location[1] - '1', pieces[piece].location[0] - 'a');
		    int dir = (pieces[piece].color == WHITE) ? 8 : -8;

		    square += dir;
		    while ((square < 56) && (square > 7)) {
			if ((pieces[piece].blocking_piece != -1)
			    && (BITVECTOR(square) & pieces[pieces[piece].blocking_piece].legal_squares)
			    && !(BITVECTOR(square + dir) & pieces[pieces[piece].blocking_piece].legal_squares))
			    break;
			pieces[piece].legal_squares |= BITVECTOR(square);
			square += dir;
		    }
		}
	    }
	}
    }

    /* Now we need to figure out if there are any other pieces identical to this one, because if so,
     * exchanging the two pieces would not change the position, and that has to be taken into
     * account in several places.  Move restrictions on the pieces complicate this, unless they are
     * completely non-overlapping, in which case we don't treat the pieces as identical because they
     * are then distinguishable (kinda like electrons).  The whole point of this code is to group
     * together identical pieces with overlapping move restrictions, and to compute for each group
     * the logical union of their move restrictions, which become the "semilegal" squares for all
     * the pieces in that group.  See the earlier discussion on semilegal squares.
     */

    for (piece = 0; piece < num_pieces; piece ++) {

	pieces[piece].prev_piece_in_semilegal_group = -1;
	pieces[piece].next_piece_in_semilegal_group = -1;

	pieces[piece].semilegal_squares = pieces[piece].legal_squares;

	for (piece2 = 0; piece2 < piece; piece2 ++) {
	    if ((pieces[piece2].color == pieces[piece].color)
		&& (pieces[piece2].piece_type == pieces[piece].piece_type)) {

		if (pieces[piece].semilegal_squares & pieces[piece2].semilegal_squares) {
		    pieces[piece].prev_piece_in_semilegal_group = piece2;
		    pieces[piece2].semilegal_squares |= pieces[piece].semilegal_squares;
		    pieces[piece].semilegal_squares |= pieces[piece2].semilegal_squares;
		}
	    }
	}

	if (pieces[piece].prev_piece_in_semilegal_group != -1) {
	    pieces[pieces[piece].prev_piece_in_semilegal_group].next_piece_in_semilegal_group = piece;
	}
    }

    /* Later, if we're trying to process a position with identical pieces that aren't on legal
     * squares, we permute them and see if we can get them onto legal squares that way.  Now,
     * construct the full set of possible permutations, using an algorithm that generates a series
     * of transpositions that walks the entire set of permutations, and store this as a list
     * attached to the first piece in the set.
     *
     * XXX probably don't need to do this during normalization at all if the semilegal and legal
     * squares are the same, because permuting wouldn't do anything for us then.
     */

    for (piece = 0; piece < num_pieces; piece ++) {

	pieces[piece].permutations = nullptr;

	if (pieces[piece].prev_piece_in_semilegal_group == -1 && pieces[piece].next_piece_in_semilegal_group != -1) {

	    int identical_pieces = 0;
	    int piece2;

	    int position[MAX_PIECES];
	    int directions[MAX_PIECES];
	    int i;
	    int j;

	    for (piece2 = piece; piece2 != -1; piece2 = pieces[piece2].next_piece_in_semilegal_group) {
		position[identical_pieces] = piece2;
		directions[identical_pieces] = -1;
		identical_pieces ++;
	    }
	    directions[0] = 0;

	    pieces[piece].permutations = (int *) calloc(factorial(identical_pieces), sizeof(int));
	    j = 0;

	    /* Use Johnson‚ÄìTrotter algorithm to generate all permutations as a series of
	     * transpositions.
	     *
	     * XXX looking at how these permutations get used, maybe we should add a final
	     * transposition to bring us back to the original configuration
	     */

	    while (1) {
		int largest_i_with_nonzero_direction;
		int direction;
		int saved_position;

		largest_i_with_nonzero_direction = -1;

		for (i=0; i<identical_pieces; i++) {
		    if ((directions[i] != 0)
			&& ((largest_i_with_nonzero_direction == -1) 
			    || position[i] > position[largest_i_with_nonzero_direction])) {
			largest_i_with_nonzero_direction = i;
		    }
		}

		if (largest_i_with_nonzero_direction == -1) break;

		pieces[piece].permutations[j++] = (position[largest_i_with_nonzero_direction] << 8)
		    | position[largest_i_with_nonzero_direction + directions[largest_i_with_nonzero_direction]];

		direction = directions[largest_i_with_nonzero_direction];

		saved_position = position[largest_i_with_nonzero_direction];
		position[largest_i_with_nonzero_direction] = position[largest_i_with_nonzero_direction + direction];
		position[largest_i_with_nonzero_direction + direction] = saved_position;

		directions[largest_i_with_nonzero_direction] = directions[largest_i_with_nonzero_direction + direction];
		directions[largest_i_with_nonzero_direction + direction] = direction;

		largest_i_with_nonzero_direction += direction;

		if ((largest_i_with_nonzero_direction == 0)
		    || (largest_i_with_nonzero_direction == identical_pieces-1)
		    || (position[largest_i_with_nonzero_direction + directions[largest_i_with_nonzero_direction]] > 
			position[largest_i_with_nonzero_direction])) {
		    directions[largest_i_with_nonzero_direction] = 0;
		}

		for (i=0; i<largest_i_with_nonzero_direction; i++) {
		    if (position[i] > position[largest_i_with_nonzero_direction]) directions[i] = +1;
		}
		for (i=largest_i_with_nonzero_direction; i<identical_pieces; i++) {
		    if (position[i] > position[largest_i_with_nonzero_direction]) directions[i] = -1;
		}
	    }

	    if (j != factorial(identical_pieces)-1) {
		fatal("BUG: did not generate factorial(identical_pieces) permutations\n");
	    }

	}
    }


#if DEBUG
    for (piece = 0; piece < num_pieces; piece ++) {
	info("Piece %d: type %s color %s legal_squares %0" PRIx64 " semilegal_squares %0" PRIx64 "\n",
	     piece, piece_name[pieces[piece].piece_type], colors[pieces[piece].color].c_str(),
	     pieces[piece].legal_squares, pieces[piece].semilegal_squares);
    }
#endif


    /* Fetch the index type.  First, for backwards compatibility, we check for an index property on
     * the tablebase element itself.  Next, check for the preferred syntax of an index element.
     * Finally, if there is no index element, add one with the default index type, to avoid having
     * to figure out the default index from the version of the program that generated a tablebase.
     */

    index = tablebase->get_attribute_value("index");
    index_node = tablebase;

    if (index == "") {
	result = tablebase->find("//index");
	if (!result.empty()) {
	    index_node = (xmlpp::Element *) result[0];
	    index = index_node->get_attribute_value("type");
	}
    }

    // XXX DEFAULT_INDEX should be able to handle pawngen

    if (index == "") {
	if (pawngen) {
	    index_type = PAWNGEN_INDEX;
	} else {
	    index_type = DEFAULT_INDEX;
	}

	tablebase->add_child_text("   ");
	index_node = tablebase->add_child("index");
	tablebase->add_child_text("\n");

	index_node->set_attribute("type", index_types[index_type]);
    } else {
	index_type = index_types.at(index);
    }

    if (pawngen) {
	if (! tablebase->find("//piece[@type='pawn']").empty()) {
	    throw nested_exception("Can't have normal pawn pieces with pawngen");
	}

	if ((index_type != PAWNGEN_INDEX)
	    && (index_type != COMBINADIC3_INDEX) && (index_type != COMBINADIC4_INDEX)
	    && (index_type != NAIVE_INDEX) && (index_type != NAIVE2_INDEX)) {
	    throw nested_exception("Illegal index type with pawngen");
	}
    }

    /* The other encoding schemes depend on a special encoding for the kings, which might not even
     * be present if we're doing a suicide analysis.
     *
     * XXX should be able to use pawngen, too, but it's untested
     */

    if ((variant == VARIANT_SUICIDE) && (index_type != NAIVE_INDEX)
	&& (index_type != SIMPLE_INDEX) && (index_type != COMBINADIC3_INDEX)
	&& (index_type != COMBINADIC4_INDEX)) {
	throw "Only 'naive', 'simple', and 'combinadic3/4' indices are compatible with 'suicide' variant";
    }

    /* Now, compute a bitvector for all the pieces that are frozen on single squares.  This
     * 'frozen_pieces_vector' differs from 'blocked_squares' because a square can be blocked by a
     * pawn that is at least partially mobile on a single file.  Frozen pieces, on the other hand,
     * are completely immobile on a single square.
     *
     * Now, I had this idea that I could completely discard those positions where the king was in
     * check from a frozen piece.  After all, how could a king ever move into check from a frozen
     * piece?  Well, the answer is that if we use this as a futurebase in a later analysis, the king
     * could possibly be in check as we transition between tablebases.  So first I put an option in
     * to turn off this feature.  I'm now convinced that it was such a bad idea that I've removed it
     * from the code (1.854).
     */

    frozen_pieces_vector = 0;

    for (piece = 0; piece < num_pieces; piece ++) {
	for (square = 0; square < 64; square ++) {
	    if (BITVECTOR(square) == pieces[piece].semilegal_squares) {
		if (frozen_pieces_vector & BITVECTOR(square)) {
		    throw "More than one piece frozen on " + ('a' + COL(square)) + ('1' + ROW(square));
		}
		frozen_pieces_vector |= BITVECTOR(square);

		break;
	    }
	}
    }

    /* Strip the locations of frozen pieces off the legal squares bitvectors of all the other
     * pieces.  Like stripping the capture squares off the enemy king's legal bitvector, this is a
     * convenience, so we don't have to list all the free squares for pieces that are not frozen.
     * But we do have to careful about changing this code around, because some index types (like
     * 'simple' and 'compact') implicitly use a piece's legal squares to encode its position, so
     * changing this code can change index encoding.
     */

    for (piece = 0; piece < num_pieces; piece ++) {
	if ((pieces[piece].semilegal_squares & frozen_pieces_vector) != pieces[piece].semilegal_squares) {
	    pieces[piece].legal_squares &= ~ frozen_pieces_vector;
	    pieces[piece].semilegal_squares &= ~ frozen_pieces_vector;
	}
    }

    /* Get the format.  Older method is to specify it as a property on the tablebase element.  Next
     * look to see if we've got an explicit format element.  Then check to see if any of the format
     * types were specified without a format element.  Finally, assume DTM format by default.
     *
     * XXX no reason to assume DTM format if the futurebases don't support it
     */

    format_str = tablebase->get_attribute_value("format");
    if (format_str != "") {
	switch (formats.at(format_str)) {
	case FORMAT_ONE_BYTE_DTM:
	    format = one_byte_dtm_format;
	    break;
	default:
	    throw "Unknown tablebase format " + format_str;
	}
    } else {
	result = tablebase->find("//format");
	if (! result.empty()) {
	    // XXX should parse_format throw the exception?
	    if (! parse_format((xmlpp::Element *) result[0], &format)) throw "Can't parse format";
	} else {
	    if (! parse_format(tablebase, &format)) {
		format = dtm_format;

		tablebase->add_child_text("   ");
		tablebase->add_child("dtm");
		tablebase->add_child_text("\n");

		warning("Format not expressly specified; assuming dtm\n");
	    }
	}
    }

    /* Extract index symmetry (if it was specified) */

    symmetry = eval_to_number_or_zero(index_node, "@symmetry");

    if (symmetry == 0) {
	/* If symmetry was not explicitly specified, compute it automatically */

	symmetry = 8;
	if ((index_type == NAIVE_INDEX) || (index_type == NAIVE2_INDEX)) {
	    symmetry = 4;
	}
	for (piece = 0; piece < num_pieces; piece ++) {
	    if (pieces[piece].piece_type == PAWN) {
		symmetry = 2;
	    }
	    if (((pieces[piece].piece_type != PAWN) && (pieces[piece].legal_squares != ALL_ONES_BITVECTOR))
		|| ((pieces[piece].piece_type == PAWN) && (pieces[piece].legal_squares != LEGAL_PAWN_BITVECTOR))) {
		symmetry = 1;
	    }
	}
	if (variant == VARIANT_SUICIDE) {
	    symmetry = 1;
	}

	index_node->set_attribute("symmetry", boost::lexical_cast<std::string>(symmetry));
    }

    if ((symmetry != 1) && (symmetry != 2) && (symmetry != 4) && (symmetry != 8)) {
	fatal("Bad index symmetry %d\n", symmetry);
    }

    /* Symmetry is based on the location of the white king, but in a suicide analysis we might not have
     * a white king.  Doesn't seem like a show stopper, but right now the code doesn't support it.
     *
     * XXX fix this and allow symmetry based on the first piece in the tablebase
     */

    if ((variant == VARIANT_SUICIDE) && (symmetry != 1)) {
	throw "Can't use symmetry with 'suicide' variant (yet)";
    }

    /* Check piece specification to make sure it matches symmetry
     *
     * XXX Some piece restrictions should be allowed for, so long as the restrictions themselves are
     * symmetric.  For example, a rook restricted to a single row is consistent with 2-way symmetry.
     */


    if ((symmetry == 8) && ((index_type == NAIVE_INDEX) || (index_type == NAIVE2_INDEX))) {
	throw "8-way symmetry incompatible with naive/naive2 index types";
    }

    if (symmetry >= 4) {
	for (piece = 0; piece < num_pieces; piece ++) {
	    if (pieces[piece].piece_type == PAWN) {
		throw "Pawns not allowed with 4/8-way symmetric indices";
	    }
	}
    }

    if (symmetry > 1) {
	if (pawngen) {
	    /* See SYMMETRY AND PAWNGEN above. */
	    throw "Pawngen not allowed with symmetric indices (yet)";
	}
	for (piece = 0; piece < num_pieces; piece ++) {
	    if (((pieces[piece].piece_type != PAWN) && (pieces[piece].legal_squares != ALL_ONES_BITVECTOR))
		|| ((pieces[piece].piece_type == PAWN) && (pieces[piece].legal_squares != LEGAL_PAWN_BITVECTOR))) {
		throw "Piece restrictions not allowed with symmetric indices (yet)";
	    }
	}
    }

    /* Compute reflections array
     *
     * 2-way symmetry: white king always on left side of board
     *
     * 4-way symmetry: white king always in lower left quarter of board
     *
     * 8-way symmetry: white king always in a1-a4-d4 triangle, and if white king is on a1-d4
     * diagonal, then black king is on or below a1-h8 diagonal
     */

    for (int white_king_square = 0; white_king_square < 64; white_king_square ++) {
	for (int black_king_square = 0; black_king_square < 64; black_king_square ++) {

	    reflections[white_king_square][black_king_square] = 0;

	    int reflected_white_king_square = white_king_square;
	    int reflected_black_king_square = black_king_square;

	    if (symmetry >= 2) {
		if (COL(reflected_white_king_square) >= 4) {
		    reflections[white_king_square][black_king_square] |= REFLECTION_HORIZONTAL;
		    reflected_white_king_square = horizontal_reflection(reflected_white_king_square);
		    reflected_black_king_square = horizontal_reflection(reflected_black_king_square);
		}
	    }

	    if (symmetry >= 4) {
		if (ROW(reflected_white_king_square) >= 4) {
		    reflections[white_king_square][black_king_square] |= REFLECTION_VERTICAL;
		    reflected_white_king_square = vertical_reflection(reflected_white_king_square);
		    reflected_black_king_square = vertical_reflection(reflected_black_king_square);
		}
	    }

	    if (symmetry == 8) {
		if (ROW(reflected_white_king_square) > COL(reflected_white_king_square)) {
		    reflections[white_king_square][black_king_square] |= REFLECTION_DIAGONAL;
		}
		if (ROW(reflected_white_king_square) == COL(reflected_white_king_square)) {
		    if (ROW(reflected_black_king_square) > COL(reflected_black_king_square)) {
			reflections[white_king_square][black_king_square] |= REFLECTION_DIAGONAL;
		    }
		}
	    }
	}
    }

    /* The naive, naive2 and simple index-to-position decoding routines make no attempt to permute
     * semilegal groups to get the pieces onto legal squares.  Therefore, we can't use them
     * if the semilegal and legal ranges of a piece differ.
     */

    if (index_type <= SIMPLE_INDEX) {
	for (piece = 0; piece < num_pieces; piece ++) {
	    if (pieces[piece].legal_squares != pieces[piece].semilegal_squares) {
		throw "Non-identical overlapping piece restrictions not allowed with this index type";
	    }
	}
    }

    if (index_type == NO_EN_PASSANT_INDEX) {
	for (piece = 0; piece < num_pieces; piece ++) {
	    int col;
	    int row1 = (pieces[piece].color == WHITE) ? 1 : 6;
	    int row3 = (pieces[piece].color == WHITE) ? 3 : 4;
	    int row4 = (pieces[piece].color == WHITE) ? 4 : 3;
	    if (pieces[piece].piece_type != PAWN) continue;
	    for (col = 0; col < 8; col ++) {
		if (pieces[piece].legal_squares
		    & (BITVECTOR(rowcol2square(row1, col)) | BITVECTOR(rowcol2square(row3, col)))) {
		    for (piece2 = 0; piece2 < num_pieces; piece2 ++) {
			if (pieces[piece2].piece_type != PAWN) continue;
			if (pieces[piece2].color == pieces[piece].color) continue;
			if ((col > 0)
			    && (pieces[piece2].legal_squares & BITVECTOR(rowcol2square(row4, col-1)))) {
			    throw "Can't use 'no-en-passant' index for a tablebase where en-passant captures are possible";
			}
			if ((col < 7)
			    && (pieces[piece2].legal_squares & BITVECTOR(rowcol2square(row4, col+1)))) {
			    throw "Can't use 'no-en-passant' index for a tablebase where en-passant captures are possible";
			}
		    }
		}
	    }
	}
    }

    /* Do we encode side-to-move? */

    if ((index_type == COMBINADIC4_INDEX) && is_color_symmetric()) {
	encode_stm = false;
    } else {
	encode_stm = true;
    }

    /* The constructor for the index encoding is expected to compute and assign num_indices in the
     * tablebase structure (but see next section of code where it might be modified).
     */

    switch (index_type) {
    case NAIVE_INDEX:
	encoding.reset(new naive_index(this));
	break;

    case NAIVE2_INDEX:
	encoding.reset(new naive2_index(this));
	break;

    case SIMPLE_INDEX:
	encoding.reset(new simple_index(this));
	break;

    case COMPACT_INDEX:
	encoding.reset(new compact_index(this));
	break;

    case COMBINADIC3_INDEX:
    case COMBINADIC4_INDEX:
    case PAWNGEN_INDEX:
	encoding.reset(new combinadic_index(this));
	break;

    case NO_EN_PASSANT_INDEX:
	fatal("no-en-passant index type deprecated\n");
	break;

    default:
	fatal("unknown index type\n");
	break;
    }

    /* Compute the actual size of the tablebase.  If we're encoding side-to-move, the tablebase is
     * bigger by a factor of two from what the index encoding calculated.  If we're using pawngen,
     * then the index constructor didn't take that into account, either.  The tablebase is actually
     * bigger by a factor of however many pawngen positions we've got.
     */

    num_indices = encoding->size;

    if (encode_stm) {
	num_indices *= 2;
    }

    if (pawngen) {
	num_indices *= pawngen->pawn_positions_by_index.size();
    }

    /* Fetch any prune enable elements */

    prune_enable[BLACK] = 0;
    prune_enable[WHITE] = 0;
    result = tablebase->find("//prune-enable | //move-restriction");
    if (! result.empty()) {
	for (auto i=0U; i < result.size(); i++) {
	    auto color_str = ((xmlpp::Element *) result[i])->get_attribute_value("color");
	    auto type_str = ((xmlpp::Element *) result[i])->get_attribute_value("type");
	    int color = colors.at(color_str);
	    int type = restriction_types.at(type_str);

	    if ((color == -1) || (type == -1)) {
		fatal("Illegal prune-enable\n");
	    } else {
		prune_enable[color] |= type;
	    }
	}
    }

    //return (fatal_errors == starting_fatal_errors) ? tb : nullptr;
}

tablebase_t::tablebase_t(std::istream *instream)
{
    parse_XML(instream);
}

xmlpp::Element * create_GenStats_node(std::string name)
{
    generation_statistics->add_child_text("   ");
    auto node = generation_statistics->add_child(name);
    generation_statistics->add_child_text("\n   ");

    return node;
}

/* Parses an XML control file.
 */

tablebase_t * parse_XML_control_file(char *filename)
{
    xmlpp::NodeSet result;
    tablebase_t *tb;

    char hostname[256];		/* XXX hardwired max */
    struct hostent *he;
    char strbuf[256];

    /* load the control file from the specified filename or URL */

    std::ifstream input_file;
    input_file.exceptions(std::ifstream::failbit | std::ifstream::badbit);
    input_file.open(filename, std::ifstream::in | std::ifstream::binary);

    io::filtering_istream instream;

    // XXX can we test for compression and then push?
    //instream.push(io::gzip_decompressor());
    instream.push(input_file);

    // XXX this might throw an exception
    tb = new tablebase_t(& instream);

    auto tablebase = tb->xml->get_root_node();

    tablebase->add_child_text("   ");
    generation_statistics = tablebase->add_child("generation-statistics");
    tablebase->add_child_text("\n   ");

    generation_statistics->add_child_text("\n   ");

    gethostname(hostname, sizeof(hostname));
    he = gethostbyname(hostname);

    create_GenStats_node("host")->add_child_text(he->h_name);
    create_GenStats_node("program")->add_child_text("Hoffman Version " + boost::lexical_cast<std::string>(Hoffman_program_version) + (Hoffman_program_modified ? " (modified)" : ""));
    create_GenStats_node("args")->add_child_text(options_string);
    strftime(strbuf, sizeof(strbuf), "%c %Z", localtime(&program_start_time.tv_sec));
    create_GenStats_node("start-time")->add_child_text(strbuf);

    completion_time = create_GenStats_node("completion-time");

    /* create global counter nodes */

    user_time = create_GenStats_node("user-time");
    system_time = create_GenStats_node("system-time");
    real_time = create_GenStats_node("real-time");
    page_faults = create_GenStats_node("page-faults");
    page_reclaims = create_GenStats_node("page-reclaims");

    return tb;
}

/* limiting_input_filter is a Boost iostreams filter that reads until it has read (and returned) a
 * particular string, then terminates reading and returns EOF.  I use it to terminate reading at the
 * string "</tablebase>", which prevents a libxml++ parser error "Extra content at the end of the
 * document".
 *
 * XXX it isn't quite right in the general case.  "</tab</tablebase>" won't match at all.
 */

class limiting_input_filter : public io::input_filter {
    std::string limitstr;
    size_t pos;

public:
    limiting_input_filter(std::string limitstr) : limitstr(limitstr), pos(0) { }

    template<typename Source>
    int get(Source& src)
    {
	if (pos == limitstr.length()) return EOF;

	int c = io::get(src);

	if (limitstr[pos] == c) pos++;
	else if (c != io::WOULD_BLOCK) pos = 0;

	return c;
    }
};

/* This next section of code was ripped out of the boost library, to create a gzip decompressor that
 * supports seeks.  Forward seeks are implemented by just burning data.  Backwards seeks reset to
 * the beginning of the stream and then burn data.  Backwards seeks in a compressed file are
 * obviously expensive, but occasionally unavoidable.
 */

const int default_device_buffer_size = 16384;

template<typename Alloc = std::allocator<char> >
class gzip_decompressor_impl : public z_stream {
public:
    typedef char char_type;
    void reset()
    {
	zalloc = nullptr;
	zfree = nullptr;
	next_in = nullptr;
	avail_in = 0;
	total_in = 0;
	total_out = 0;

	if (inflateInit2(this, 32 + MAX_WBITS) != Z_OK) throw new std::exception;
    }

    gzip_decompressor_impl() { reset(); }

    ~gzip_decompressor_impl() { }

    bool filter( const char*& begin_in, const char* end_in,
                 char*& begin_out, char* end_out, bool flush )
    {
	next_in = reinterpret_cast<Bytef*>(const_cast<char *>(begin_in));
	avail_in = end_in - begin_in;
	next_out = reinterpret_cast<Bytef*>(begin_out);
	avail_out = end_out - begin_out;

	int result = inflate(this, flush ? Z_SYNC_FLUSH : Z_NO_FLUSH);
	//if (result < 0) throw new std::exception;
	//if (result < 0) throw new io::detail::failure(msg);
	if (result < 0) {
	    throw new BOOST_IOSTREAMS_FAILURE(msg);
	}

	begin_in = reinterpret_cast<char*>(next_in);
	begin_out = reinterpret_cast<char*>(next_out);

	return (result != Z_STREAM_END);
    }
    //void close() { reset(); }
    void close() { }
};

template<typename Alloc = std::allocator<char> >
struct basic_gzip_decompressor 
    : io::symmetric_filter<gzip_decompressor_impl<Alloc>, Alloc> 
{
private:
    typedef gzip_decompressor_impl<Alloc>           impl_type;
    typedef io::symmetric_filter<impl_type, Alloc>  base_type;
public:
    typedef typename base_type::char_type               char_type;
    struct category : base_type::category, io::input_seekable { };
    basic_gzip_decompressor( int buffer_size = default_device_buffer_size )
	: base_type(buffer_size) { }
    ulong crc() { return this->filter().crc(); }
    ulong total_out() {  return this->filter().total_out; }
    bool eof() { return this->filter().eof(); }

    template <typename T>
    std::streampos seek(T& t, io::stream_offset off, BOOST_IOS::seekdir way)
    {
	// std::cout << typeid(t).name() << std::endl;
	// std::cerr << "seeking " << off << " " << way << " from " << total_out() << std::endl;

	if (way == BOOST_IOS::cur) {
	    if (off < 0) {
		off += total_out();
		//close_impl();
		this->close(t, BOOST_IOS::in);
		this->filter().reset();
		io::seek(t, 0, BOOST_IOS::beg);
	    }
	    if (off > 0) {
		// XXX check type
		char_type buffer[default_device_buffer_size];
		while (off > 0) {
		    if (off > default_device_buffer_size) {
			off -= this->read(t, buffer, default_device_buffer_size);
		    } else {
			off -= this->read(t, buffer, off);
		    }
		}
	    }
	}
	// std::cerr << "seek done\n";
	return total_out();
    }
};

typedef basic_gzip_decompressor<> gzip_decompressor;

tablebase_t::tablebase_t(Glib::ustring filename) : offset(0), invert_colors(false), num_pieces(0), filename(filename)
{
    std::ifstream * input_file = new std::ifstream;

    input_file->open(filename, std::ifstream::in | std::ifstream::binary);

    if (!input_file->good()) {
	// XXX better way to do this?
	throw "Can't open file";
    }

    input_file->exceptions(std::ifstream::failbit | std::ifstream::badbit);

    //io::filtering_istream * instream = new io::filtering_istream;
    instream.reset(new io::filtering_istream);

    instream->push(limiting_input_filter("</tablebase>"));
    if (input_file->peek() == '\037') {
	instream->push(io::gzip_decompressor());
    }
    instream->push(*input_file);

    parse_XML(instream.get());

    offset = eval_to_number_or_zero(xml->get_root_node(), "/tablebase/@offset");

    /* We don't just destroy instream, because that would close the file.  Instead, we disassemble
     * it and reassemble it for reading the data.
     */

    // XXX keep reading without reseting the file (might not work over network)

    instream->set_auto_close(false);
    while (! instream->empty()) instream->pop();
    input_file->seekg(0);

    // XXX test cases for exceptions

#if 0

    /* XXX This is what I'd like to do, but it doesn't work.  Boost 1.54 can't handle io::restrict
     * on gzip_decompressor (or its stock io::gzip_decompressor).  Instead, we need to construct a
     * new input stream, push the file and the decompressor into it, then io::restrict the stream.
     * Yuck.
     */

    if (input_file->peek() == '\037') {
	instream->push(io::restrict(gzip_decompressor(), offset));
	instream->push(*input_file);
    } else {
	instream->push(io::restrict(*input_file, offset));
    }
    instream->exceptions(std::ifstream::failbit | std::ifstream::badbit);

#else

    if (input_file->peek() == '\037') {
	// XXX delete instream2 when we're done with it
	io::filtering_stream<io::input_seekable> * instream2 = new io::filtering_stream<io::input_seekable>;

	instream2->push(gzip_decompressor());
	instream2->push(*input_file);

	instream->push(io::restrict(*instream2, offset));
    } else {
	instream->push(io::restrict(*input_file, offset));
    }

    instream->exceptions(std::ifstream::failbit | std::ifstream::badbit);

#endif

    next_read_index = 0;
}

/* compute_extra_and_missing_pieces()
 *
 * This function precomputes information that will later be used to translate positions between
 * tablebases in translate_foreign_position_to_local_position().  That function is used extensively
 * during futurebase back-propagation, so we try to figure out as much stuff as we can here,
 * specifically:
 *
 * - for each piece/square pair in the futurebase, we compute the corresponding semilegal group in
 *   the local tablebase, and store a pointer to the first piece in it
 *
 * - if there is a single extra piece in the futurebase, store its piece number
 *
 * - if there are one or two missing pieces that don't appear in the futurebase, store the piece
 *   number(s) along with an indication if it's a pawn or not
 *
 * If there is ambiguity because there are other pieces in the futurebase identical to the extra or
 * missings piece(s), the highest piece numbers will be returned.
 */

void compute_extra_and_missing_pieces(tablebase_t *tb, tablebase_t &futurebase)
    throw (const char *)
{
    int piece;
    int future_piece;
    int local_piece_vector = 0;
    int future_piece_vector = 0;
    int promotion;

    futurebase.extra_piece = -1;
    futurebase.missing_pawn = -1;
    futurebase.missing_non_pawn = -1;

    for (future_piece = 0; future_piece < futurebase.num_pieces; future_piece ++) {

	bool found_matching_piece = false;

	for (int square = 0; square < 64; square ++) {
	    futurebase.pieces[future_piece].matching_local_semilegal_group[square] = -1;
	}

	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if ((tb->pieces[piece].piece_type == futurebase.pieces[future_piece].piece_type)
		&& ((!futurebase.invert_colors &&
		     (tb->pieces[piece].color == futurebase.pieces[future_piece].color))
		    || (futurebase.invert_colors &&
			(tb->pieces[piece].color != futurebase.pieces[future_piece].color)))) {

		/* Have we found a unassigned matching pair of localbase/futurebase pieces? */
		if (!(local_piece_vector & (1 << piece))
		    && !(future_piece_vector & (1 << future_piece))) {

		    local_piece_vector |= (1 << piece);
		    future_piece_vector |= (1 << future_piece);

		    found_matching_piece = true;
		}

		for (int square = 0; square < 64; square ++) {

		    if (tb->pieces[piece].semilegal_squares & BITVECTOR(square)) {

			if (futurebase.pieces[future_piece].matching_local_semilegal_group[square] == -1) {
			    futurebase.pieces[future_piece].matching_local_semilegal_group[square] = piece;
			}

		    }
		}
	    }
	}

	if (! found_matching_piece) {
	    if ((futurebase.extra_piece == -1) && (futurebase.pieces[future_piece].piece_type != PAWN)) {
		futurebase.extra_piece = future_piece;
	    } else {
		throw "Couldn't find future piece in local tablebase";
	    }
	}
    }

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	if (!(local_piece_vector & (1 << piece))) {
	    if (tb->pieces[piece].piece_type == PAWN) {
		if (futurebase.missing_pawn == -1) {
		    futurebase.missing_pawn = piece;
		} else {
		    throw "Too many missing pieces in futurebase";
		}
	    } else {
		if (futurebase.missing_non_pawn == -1) {
		    futurebase.missing_non_pawn = piece;
		} else {
		    throw "Too many missing pieces in futurebase";
		}
	    }
	}
    }

    if (futurebase.extra_piece != -1) {

	for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
	    if (futurebase.pieces[futurebase.extra_piece].piece_type == promoted_pieces[promotion]) break;
	}

	if (promotion == promotion_possibilities) {
	    throw "Couldn't find futurebase's extra piece in promoted_pieces list";
	}

	futurebase.promotion = promotion;
    }
}

int autodetect_futurebase_type(tablebase_t & futurebase)
{
    if (futurebase.extra_piece == -1) {
	if ((futurebase.missing_pawn == -1) && (futurebase.missing_non_pawn == -1)) {
	    return FUTUREBASE_NORMAL;
	} else if ((futurebase.missing_pawn != -1) && (futurebase.missing_non_pawn != -1)) {
	    return -1;
	} else {
	    return FUTUREBASE_CAPTURE;
	}
    } else {
	if (futurebase.missing_pawn == -1) {
	    return -1;
	} else if (futurebase.missing_non_pawn == -1) {
	    return FUTUREBASE_PROMOTION;
	} else {
	    return FUTUREBASE_CAPTURE_PROMOTION;
	}
    }
}

/* preload_all_futurebases()
 *
 * In addition to preloading the futurebases, this function also updates the global variables
 * min_tracked_dtm and max_tracked_dtm.
 */

bool preload_all_futurebases(tablebase_t *tb)
{
    xmlpp::NodeSet result;
    int fbnum;

    result = tb->xml->get_root_node()->find("//futurebase");
    num_futurebases = result.size();

    for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {
	Glib::ustring filename = result[fbnum]->eval_to_string("@filename");

	// XXX put this back in
#if 0
	if (filename == nullptr) {
	    filename = xmlGetProp(result->nodesetval->nodeTab[fbnum], BAD_CAST "url");
	}
	if (filename == nullptr) {
	    fatal("No filename or URL specified in futurebase element\n");
	    continue;
	}
#endif

	try {
	    futurebases.push_back(tablebase_t(filename));
	} catch (const char * msg) {
	    fatal("%s: futurebase preload failed: %s\n", filename.c_str(), msg);
	    return false;
	}

	if (futurebases[fbnum].variant != tb->variant) {
	    fatal("Futurebases have to use same 'variant' as tablebase under construction!\n");
	    continue;
	}

	if (futurebases[fbnum].symmetry < tb->symmetry) {
	    fatal("Futurebases can't be less symmetric than the tablebase under construction\n");
	    continue;
	}

	/* Now update the range of locally tracked DTM values based on the futurebase DTM range.
	 *
	 * How do futurebase DTM values affect local DTM values?
	 *
	 * A futurebase max_dtm (ex: 5) will back propagate into -max_dtm (ex: -5) locally, and a
	 * futurebase min_dtm (ex: -5) will back propagate into 1-min_dtm (ex: 6).
	 */

	if (1-futurebases[fbnum].min_dtm > max_tracked_dtm) max_tracked_dtm = 1-futurebases[fbnum].min_dtm;
	if (-futurebases[fbnum].max_dtm < min_tracked_dtm) min_tracked_dtm = -futurebases[fbnum].max_dtm;

	futurebases[fbnum].invert_colors = (result[fbnum]->eval_to_string("@colors") == "invert");

	/* Check futurebase to make sure its prune enable(s) match our own */

	for (int color = 0; color < 2; color ++) {
	    if (futurebases[fbnum].prune_enable[color] & ~(tb->prune_enable[futurebases[fbnum].invert_colors ? 1 - color : color])) {
		fatal("'%s': Futurebase doesn't match prune-enables!\n", filename.c_str());
		return false;
	    }
	}

	/* Check futurebase to make sure its format is compatible with our own.
	 *
	 * 'dtm' futurebases can backprop into anything
	 *
	 * 'basic' futurebases can backprop into anything, even though the metric resulting from a
	 * basic-to-dtm backprop won't be DTM but rather DTC (distance to conversion)
	 *
	 * 'flag' futurebases can only backprop into a compatible 'flag' (compatible means either
	 * the same type of flag with no color inversion, or the opposite type of flag with color
	 * inversion)
	 *
	 * XXX distinguish between DTM and DTC tablebases
	 */

	if (futurebases[fbnum].format.flag_type != FORMAT_FLAG_NONE) {
	    if (tb->format.flag_type == FORMAT_FLAG_NONE) {
		fatal("'%s': bitbase unusable as futurebase for a non-bitbase format\n", filename.c_str());
	    } else if ((tb->format.flag_type != futurebases[fbnum].format.flag_type) && ! futurebases[fbnum].invert_colors) {
		fatal("'%s': bitbase unusable as futurebase due to flag type\n", filename.c_str());
	    } else if ((tb->format.flag_type == futurebases[fbnum].format.flag_type) && futurebases[fbnum].invert_colors) {
		fatal("'%s': bitbase unusable as futurebase due to color inversion\n", filename.c_str());
	    }
	}

	try {
	    compute_extra_and_missing_pieces(tb, futurebases[fbnum]);
	} catch (const char * reason) {
	    fatal("'%s': %s\n", filename.c_str(), reason);
	}

	/* We used to have to specify futurebase type in the XML, but now it is autodetected.  Check
	 * for correctness if the XML (optionally now) specified the type.
	 */

	futurebases[fbnum].futurebase_type = autodetect_futurebase_type(futurebases[fbnum]);

	if (futurebases[fbnum].futurebase_type == -1) {
	    fatal("'%s': Can't autodetect futurebase type\n", filename.c_str());
	}

	Glib::ustring type = exception_cast<xmlpp::Element *>(result[fbnum])->get_attribute_value("type");
	if (type != "") {
	    if (futurebases[fbnum].futurebase_type != futurebase_types.at(type)) {
		fatal("'%s': Specified futurebase type '%s' doesn't match autodetected type '%s'\n",
		      filename.c_str(), type.c_str(), futurebase_types[futurebases[fbnum].futurebase_type].c_str());
	    }
	}

	/* We can't xmlFree filename here, because it's stashed away in the tablebase structure */
	/* if (filename) xmlFree(filename); */
    }

    return (fatal_errors == 0);
}

/* finalize_pass_statistics() - this function also collects some of the per-pass statistics,
 * specifically the timings.
 */

void finalize_pass_statistics()
{
    xmlpp::Element * passNode;

    static struct timeval last_timeval;
    static struct rusage last_rusage;
    static int last_timings_valid = false;

    struct timeval timeval;
    struct rusage rusage;

    char strbuf[256];

    /* Update global statistics */

    gettimeofday(&timeval, nullptr);
    getrusage(RUSAGE_SELF, &rusage);

    strftime(strbuf, sizeof(strbuf), "%c %Z", localtime(&timeval.tv_sec));
    completion_time->set_child_text(strbuf);

    sprint_timeval(strbuf, &rusage.ru_utime);
    user_time->set_child_text(strbuf);

    sprint_timeval(strbuf, &rusage.ru_stime);
    system_time->set_child_text(strbuf);

    /* Note that we modified timeval here to compute the real time used by the program */
    subtract_timeval(&timeval, &program_start_time);
    sprint_timeval(strbuf, &timeval);
    real_time->set_child_text(strbuf);

    snprintf(strbuf, sizeof(strbuf), "%ld", rusage.ru_majflt);
    page_faults->set_child_text(strbuf);

    snprintf(strbuf, sizeof(strbuf), "%ld", rusage.ru_minflt);
    page_reclaims->set_child_text(strbuf);

    /* Now add a element with current pass statistics */

    gettimeofday(&timeval, nullptr);
    getrusage(RUSAGE_SELF, &rusage);

    generation_statistics->add_child_text("   ");
    passNode = generation_statistics->add_child("pass");
    generation_statistics->add_child_text("\n   ");

    passNode->set_attribute("type", boost::lexical_cast<std::string>(pass_type[total_passes]));

    if (last_timings_valid) {
	subtract_timeval(&timeval, &last_timeval);
	subtract_timeval(&rusage.ru_utime, &last_rusage.ru_utime);
    } else {
	subtract_timeval(&timeval, &program_start_time);
    }

    sprint_timeval(strbuf, &timeval);
    passNode->set_attribute("real-time", strbuf);

    sprint_timeval(strbuf, &rusage.ru_utime);
    passNode->set_attribute("user-time", strbuf);

    gettimeofday(&last_timeval, nullptr);
    getrusage(RUSAGE_SELF, &last_rusage);
    last_timings_valid = true;

    if (! strcmp(pass_type[total_passes], "intratable")) {
	if (tracking_dtm) {
	    passNode->set_attribute("dtm", boost::lexical_cast<std::string>(pass_target_dtms[total_passes]));
	}
	passNode->set_attribute("positions-finalized", boost::lexical_cast<std::string>(positions_finalized[total_passes]));
	passNode->set_attribute("moves-generated", boost::lexical_cast<std::string>(backproped_moves[total_passes]));
    }
}

/* Given a tablebase, change its XML structure to reflect the fact that the tablebase has now
 * actually been built.  Adds a dummy "offset" property to the root element which will be adjusted
 * later to reflect the actual byte offset of the tablebase entries, and a "generated-by" block
 * indicating the program, time, and host that generated the data.
 */

xmlpp::Document * finalize_XML_header(tablebase_t *tb)
{
    xmlpp::Element * tablebase = tb->xml->get_root_node();
    xmlpp::Element * node;
    xmlpp::NodeSet result;

    tablebase->set_attribute("offset", "0x1000");

    /* If no size field was specified for a DTM format, set it now */

    result = tablebase->find("//dtm");

    if (! result.empty()) {
	exception_cast<xmlpp::Element *>(result[0])->set_attribute("bits", boost::lexical_cast<std::string>(tb->format.dtm_bits));
    }

    /* Add a set of tablebase-statistics.  We prefer to add this before the generation-statistics,
     * because the generation-statistics are long and boring, and because this is how it's always
     * been done.
     */

    result = tablebase->find("//generation-statistics");

    if (result.empty()) {
	warning("Can't find /generation-statistics in XML\n");
	tablebase->add_child_text("   ");
	node = tablebase->add_child("tablebase-statistics");
    } else {
	node = tablebase->add_child_before(result[0], "tablebase-statistics");
	tablebase->add_child_text(node, "\n   ");
    }

    node->add_child_text("\n      ");
    node->add_child("indices")->set_child_text(boost::lexical_cast<std::string>(tb->num_indices));
    node->add_child_text("\n      ");
    node->add_child("PNTM-mated-positions")->set_child_text(boost::lexical_cast<std::string>(total_PNTM_mated_positions));
    node->add_child_text("\n      ");
    node->add_child("legal-positions")->set_child_text(boost::lexical_cast<std::string>(total_legal_positions));
    node->add_child_text("\n      ");
    node->add_child("stalemate-positions")->set_child_text(boost::lexical_cast<std::string>(total_stalemate_positions));

    /* If we generating a full tablebase, report both white-wins-positions and black-wins-positions.
     * If we generating a bitbase, report only one or the other of white-wins-positions or
     * white-wins-or-draws-positions.
     */

    if ((tb->format.dtm_bits > 0) || (tb->format.basic_offset != -1) || (tb->format.flag_type == FORMAT_FLAG_WHITE_WINS)) {
	node->add_child_text("\n      ");
	node->add_child("white-wins-positions")->set_child_text(boost::lexical_cast<std::string>(player_wins[WHITE]));
    }
    if ((tb->format.dtm_bits > 0) || (tb->format.basic_offset != -1)) {
	node->add_child_text("\n      ");
	node->add_child("black-wins-positions")->set_child_text(boost::lexical_cast<std::string>(player_wins[BLACK]));
    }
    if (tb->format.flag_type == FORMAT_FLAG_WHITE_DRAWS) {
	node->add_child_text("\n      ");
	node->add_child("white-wins-or-draws-positions")->set_child_text(boost::lexical_cast<std::string>(total_legal_positions - player_wins[BLACK]));
    }

    node->add_child_text("\n      ");
    node->add_child("forward-moves")->set_child_text(boost::lexical_cast<std::string>(total_moves));
    node->add_child_text("\n      ");
    node->add_child("futuremoves")->set_child_text(boost::lexical_cast<std::string>(total_futuremoves));

    if (tb->format.dtm_bits > 0) {
	node->add_child_text("\n      ");
	node->add_child("max-dtm")->set_child_text(boost::lexical_cast<std::string>(max_dtm));
	node->add_child_text("\n      ");
	node->add_child("min-dtm")->set_child_text(boost::lexical_cast<std::string>(min_dtm));
    }

    node->add_child_text("\n      ");

    return tb->xml;
}


/***** INDICES AND POSITIONS *****/

inline void flip_side_to_move_global(global_position_t *position)
{
    if (position->side_to_move == WHITE)
	position->side_to_move = BLACK;
    else
	position->side_to_move = WHITE;
}

/* invert_colors_of_global_position - just what its name implies
 *
 * We used to use this when propagating from a futurebase, but now it's only use is in the probe
 * code.  It translates a position for a tablebase built for the opposite colors, say a K+R vs K
 * endgame that we now want to probe where the rook is black, not white.  If there are pawns in the
 * game, this function has to reflect the board around a horizontal centerline.
 */

void invert_colors_of_global_position(global_position_t *global)
{
    int squareA;

    for (squareA=0; squareA < NUM_SQUARES/2; squareA++) {
	unsigned char pieceA;
	unsigned char pieceB;
	int squareB = rowcol2square(7-ROW(squareA),COL(squareA));

	pieceA = global->board[squareA];
	pieceB = global->board[squareB];

	if ((pieceA >= 'A') && (pieceA <= 'Z')) {
	    pieceA += 'a' - 'A';
	} else if ((pieceA >= 'a') && (pieceA <= 'z')) {
	    pieceA += 'A' - 'a';
	}

	if ((pieceB >= 'A') && (pieceB <= 'Z')) {
	    pieceB += 'a' - 'A';
	} else if ((pieceB >= 'a') && (pieceB <= 'z')) {
	    pieceB += 'A' - 'a';
	}
	
	global->board[squareA] = pieceB;
	global->board[squareB] = pieceA;
    }

    if (global->side_to_move == WHITE) {
	global->side_to_move = BLACK;
	if (global->en_passant_square != ILLEGAL_POSITION) global->en_passant_square -= 3*8;
    } else {
	global->side_to_move = WHITE;
	if (global->en_passant_square != ILLEGAL_POSITION) global->en_passant_square += 3*8;
    }
}

/* translate_foreign_position_to_local_position() - one of our key, key functions, used extensively
 * during futurebase back propagation.  It takes a position in a foreign tablebase and converts it
 * to a position in the local tablebase (the tablebase we're processing).  Of course, the pieces
 * might not match up between the two tablebases, but there are only a finite number of possible
 * differences:
 *
 * 1. There can be an "extra" piece in the foreign tablebase that doesn't appear in the
 * local tablebase (a pawn will promote into it).
 *
 * If there are multiple identical extra pieces, it'll be like QQ in the futurebase, while we've got
 * QP in the local tablebase.  If the futurebase position has multiple queens on the back rank, then
 * one queen might be "extra" back-proping into one position, while another queen might be "extra"
 * back-proping into a different position, but from the same futurebase position.  We can narrow it
 * down to a single semilegal group in the local tablebase with the extra piece in it.  If the
 * semilegal group is not empty, then we need to consider each piece in the semilegal group as the
 * extra piece.  This function will identify a single extra piece, the calling function is
 * responsible for swapping it with the other pieces in the semilegal group.
 *
 * Example: both Q7/7P/8/8/8/8/8/4k2K and 7Q/P7/8/8/8/8/8/4k2K promote into Q6Q/8/8/8/8/8/8/4k2K
 *
 * 2. There can be up to two "missing" pieces in the local tablebase that don't appear in the
 * foreign tablebase (one will either be a captured piece, or a pawn that promotes, and two will
 * indicate that a pawn captures and promotes).
 *
 * If there are multiple identical missing pieces due to capture, it'll be like QQ in the futurebase
 * and we've got QQQ in the local tb.  If only one queen can be captured in a given position, then
 * that's the missing piece.  But there are positions in which two different queen captures are both
 * possible, and then it's unclear which is the missing piece.  There are futurebase positions which
 * back-prop into multiple local positions with different missing pieces, depending on the piece
 * numbering.
 *
 * A missing piece will be the last piece in a semilegal group.
 *
 * 3. There can be one "restricted" piece that matches up, but is on a square flagged illegal for it
 * in the local tablebase (it moved from a legal square).  This function no longer checks for
 * legality, only semilegality, so a position can be returned with no restricted pieces indicated
 * even if the position can not be normalized.
 *
 * A restricted piece will be the last piece in a semilegal group.
 *
 * If there are additional differences not covered in this list (more than one extra piece, for
 * example), the function returns invalid_translation.  Otherwise, the return value is a struct with
 * four members:
 *
 * missing_piece1:   local tb piece number of missing piece #1
 * missing_piece2:   local tb piece number of missing piece #2
 * restricted_piece: local tb piece number of restricted piece
 * extra_piece:      foreign tb piece number of extra piece
 *
 * If any of the fields are unused (because there is no corresponding piece), it's value is NONE.
 * If there are two missing pieces and only one of them is a pawn, the pawn will always be returned
 * as missing piece #1.  If there are multiple identical missing pieces, the last one will always be
 * returned as the missing piece(s).
 *
 * To speed this function, we precomputed missing and extra pieces along with
 * piece-and-square-to-piece and piece-to-piece mapping tables.
 *
 * In addition to back-progagation, this function is also used while probing a set of tablebases to
 * see which one of them matches a given position.
 */

#define NONE 0x80

struct translation_result {
    uint8_t missing_piece1;
    uint8_t missing_piece2;
    uint8_t extra_piece;
    uint8_t restricted_piece;

    bool operator!=(const translation_result &other) const {
	return (missing_piece1 != other.missing_piece1) ||
	    (missing_piece2 != other.missing_piece2) ||
	    (extra_piece != other.extra_piece) ||
	    (restricted_piece != other.restricted_piece);
    }

    operator uint32_t() const {
	return missing_piece1 | (missing_piece2 << 8) | (extra_piece << 16) | (restricted_piece << 24);
    }
};

translation_result invalid_translation = {0xff, 0xff, 0xff, 0xff};
translation_result trivial_translation = {NONE, NONE, NONE, NONE};

translation_result translate_foreign_position_to_local_position(tablebase_t *foreign_tb, local_position_t *foreign_position,
								tablebase_t *local_tb, local_position_t *local_position,
								bool invert_colors)
{
    int foreign_piece;
    int local_piece;
    translation_result result = trivial_translation;
    int extra_sq = 0;

    memset(local_position, 0, sizeof(local_position_t));

    local_position->decoded = false;

    for (local_piece = 0; local_piece < local_tb->num_pieces; local_piece ++) {
	local_position->piece_position[local_piece] = ILLEGAL_POSITION;
	local_position->permuted_piece[local_piece] = local_piece;
    }

    local_position->en_passant_square = foreign_position->en_passant_square;
    if (invert_colors && (local_position->en_passant_square != ILLEGAL_POSITION))
	local_position->en_passant_square = vertical_reflection(local_position->en_passant_square);

    local_position->side_to_move = foreign_position->side_to_move;
    if (invert_colors) local_position->flip_side_to_move();

    /* First, see if we can slot foreign pieces into the local tablebase on semilegal squares. */

    for (foreign_piece = 0; foreign_piece < foreign_tb->num_pieces; foreign_piece ++) {

	int sq = foreign_position->piece_position[foreign_piece];

	if (invert_colors) sq = vertical_reflection(sq);

	for (local_piece = foreign_tb->pieces[foreign_piece].matching_local_semilegal_group[sq];
	     local_piece != -1; local_piece = local_tb->pieces[local_piece].next_piece_in_semilegal_group) {

	    if (local_position->piece_position[local_piece] == ILLEGAL_POSITION) {
		local_position->piece_position[local_piece] = sq;
		break;
	    }
	}

	/* If that didn't work for a foreign piece, see if we can assign it as a restricted piece
	 * (matching local piece) or an extra piece (no matching local piece).  Right now, we'll
	 * just flag it extra, then check below in this function to see if a local piece matches.
	 */

	if (local_piece == -1) {
	    if (result.extra_piece != NONE) {
		/* More than one extra/restricted piece in translation */
		return invalid_translation;
	    }
	    result.extra_piece = foreign_piece;
	    extra_sq = sq;
	}

    }

    /* Make sure all the local pieces but one or two have been accounted for, see if the extra piece
     * is actually a restricted piece, and set up our bitboard vectors.
     */

    for (local_piece = 0; local_piece < local_tb->num_pieces; local_piece ++) {
	if (local_position->piece_position[local_piece] != ILLEGAL_POSITION) {

	    local_position->board_vector |= BITVECTOR(local_position->piece_position[local_piece]);
	    if (local_tb->pieces[local_piece].color == local_position->side_to_move)
		local_position->PTM_vector |= BITVECTOR(local_position->piece_position[local_piece]);

	} else {

	    if ((result.extra_piece != NONE)
		&& (local_tb->pieces[local_piece].piece_type == foreign_tb->pieces[result.extra_piece].piece_type)
		&& ((!invert_colors
		     && (local_tb->pieces[local_piece].color == foreign_tb->pieces[result.extra_piece].color))
		    || (invert_colors
			&& (local_tb->pieces[local_piece].color != foreign_tb->pieces[result.extra_piece].color)))) {

		local_position->piece_position[local_piece] = extra_sq;
		result.restricted_piece = local_piece;
		result.extra_piece = NONE;

	    } else if (result.missing_piece1 == NONE) {
		result.missing_piece1 = local_piece;
	    } else if (result.missing_piece2 == NONE) {
		if (local_tb->pieces[local_piece].piece_type == PAWN) {
		    result.missing_piece2 = result.missing_piece1;
		    result.missing_piece1 = local_piece;
		} else {
		    result.missing_piece2 = local_piece;
		}
	    } else {
		/* More than two missing pieces in translation */
		return invalid_translation;
	    }

	}
    }

    return result;
}

translation_result translate_foreign_index_to_local_position(tablebase_t *foreign_tb, index_t index1, int reflection,
							     tablebase_t *local_tb, local_position_t *local_position, bool invert_colors)
{
    local_position_t foreign_position(foreign_tb);

    if (! index_to_local_position(foreign_tb, index1, reflection, &foreign_position)) {
#ifdef DEBUG_FUTUREMOVE
	if (index1 == DEBUG_FUTUREMOVE) {
	    info("translate_foreign_index_to_local_position: index_to_local_position failed\n");
	}
#endif
	return invalid_translation;
    }

    return translate_foreign_position_to_local_position(foreign_tb, &foreign_position, local_tb, local_position, invert_colors);
}

translation_result global_position_to_local_position(tablebase_t *tb, global_position_t *global, local_position_t *local)
{
    int square;
    tablebase_t fake_tb;
    local_position_t fake_position(&fake_tb);

    //memset(&fake_tb, 0, sizeof(fake_tb));
    memset(&fake_position, 0, sizeof(fake_position));

    fake_position.side_to_move = global->side_to_move;
    fake_position.en_passant_square = global->en_passant_square;
    fake_position.decoded = false;

    for (square = 0; square < NUM_SQUARES; square ++) {
	if ((global->board[square] != 0) && (global->board[square] != ' ')) {
	    int color;
	    int type;

	    for (color = WHITE; color <= BLACK; color ++) {
		for (type = KING; type <= PAWN; type ++) {

		    if (global->board[square] == global_pieces[color][type]) {
			fake_tb.pieces.push_back(piece(color, type));
			fake_position.piece_position[fake_tb.num_pieces] = square;
			fake_tb.num_pieces ++;
		    }
		}
	    }
	}
    }

    try {
	compute_extra_and_missing_pieces(tb, fake_tb);
    } catch (const char * reason) {
	return invalid_translation;
    }

    return translate_foreign_position_to_local_position(&fake_tb, &fake_position, tb, local, 0);
}

index_t global_position_to_index(tablebase_t *tb, global_position_t *global)
{
    local_position_t local(tb);

    if (global_position_to_local_position(tb, global, &local) != trivial_translation) return INVALID_INDEX;

    return local_position_to_index(tb, &local);
}

/* index_to_global_position()
 *
 * Used during Nalimov tablebase verification (by running through all indices in a tablebase), as
 * well as during probe code to consider possible captures and promotions because they may lead out
 * of the current tablebase.
 *
 * Massively simplified from an earlier implementation because I want to contain the details of
 * indexing to the local position routines.  Probably a little bit slower now, but not too much.
 *
 * Seems never to be used on a tablebase under construction; only on a finished one.
 */

void local_position_to_global_position(const tablebase_t *tb, const local_position_t& local, global_position_t *global)
{
    memset(global, 0, sizeof(global_position_t));

    global->side_to_move = local.side_to_move;
    global->en_passant_square = local.en_passant_square;
    global->variant = tb->variant;

    for (int piece = 0; piece < tb->num_pieces; piece++) {
	global->board[local.piece_position[piece]]
	    = global_pieces[tb->pieces[piece].color][tb->pieces[piece].piece_type];
    }
}


bool index_to_global_position(const tablebase_t *tb, index_t index, global_position_t *global)
{
    local_position_t local(tb);

    if (! index_to_local_position(tb, index, REFLECTION_NONE, &local)) return false;

    local_position_to_global_position(tb, local, global);

    return true;
}


/***** PARSING FEN TO/FROM POSITION STRUCTURES *****/

bool place_piece_in_local_position(tablebase_t *tb, local_position_t *pos, int square, int color, int type)
{
    int piece;

    if (pos->board_vector & BITVECTOR(square)) return false;

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	if ((tb->pieces[piece].piece_type == type) && (tb->pieces[piece].color == color)) {
	    pos->piece_position[piece] = square;
	    pos->board_vector |= BITVECTOR(square);
	    if (color == pos->side_to_move) pos->PTM_vector |= BITVECTOR(square);
	    return true;
	}
    }

    pos->decoded = false;

    return false;
}

bool place_piece_in_global_position(global_position_t *position, int square, int color, int type)
{
    position->board[square] = global_pieces[color][type];
    return true;
}

bool parse_FEN_to_local_position(char *FEN_string, tablebase_t *tb, local_position_t *pos)
{
    int row, col;
    int piece;

    memset(pos, 0, sizeof(local_position_t));
    pos->en_passant_square = ILLEGAL_POSITION;
    pos->decoded = false;

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	pos->piece_position[piece] = ILLEGAL_POSITION;
	pos->permuted_piece[piece] = piece;
    }

    while (*FEN_string == ' ') FEN_string ++;

    for (row=7; row>=0; row--) {
	for (col=0; col<=7; col++) {
	    switch (*FEN_string) {
	    case '1':
	    case '2':
	    case '3':
	    case '4':
	    case '5':
	    case '6':
	    case '7':
	    case '8':
		/* subtract one here since the 'for' loop will bump col by one */
		col += *FEN_string - '0' - 1;
		if (col > 7) return false;
		break;

	    case 'k':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), BLACK, KING)) return false;
		break;
	    case 'K':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), WHITE, KING)) return false;
		break;

	    case 'q':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), BLACK, QUEEN)) return false;
		break;
	    case 'Q':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), WHITE, QUEEN)) return false;
		break;

	    case 'r':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), BLACK, ROOK)) return false;
		break;
	    case 'R':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), WHITE, ROOK)) return false;
		break;

	    case 'b':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), BLACK, BISHOP)) return false;
		break;
	    case 'B':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), WHITE, BISHOP)) return false;
		break;

	    case 'n':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), BLACK, KNIGHT)) return false;
		break;
	    case 'N':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), WHITE, KNIGHT)) return false;
		break;

	    case 'p':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), BLACK, PAWN)) return false;
		break;
	    case 'P':
		if (!place_piece_in_local_position(tb, pos, rowcol2square(row, col), WHITE, PAWN)) return false;
		break;

	    default:
		return false;
	    }
	    FEN_string++;
	}
	if (row > 0) {
	  if (*FEN_string != '/') return false;
	  else FEN_string++;
	}
    }

    if (*FEN_string != ' ') return false;
    while (*FEN_string == ' ') FEN_string ++;

    if (*FEN_string == 'w') {
      pos->side_to_move = WHITE;
    } else if (*FEN_string == 'b') {
      pos->side_to_move = BLACK;
    } else {
      return false;
    }

    while (*FEN_string == ' ') FEN_string ++;

    /* skip castling rights (if they exist) */

    while ((*FEN_string == '-') || (*FEN_string == 'K') || (*FEN_string == 'Q')
	   || (*FEN_string == 'k') || (*FEN_string == 'q')) FEN_string ++;

    while (*FEN_string == ' ') FEN_string ++;

    /* If en passant square was specified, parse it */

    if ((FEN_string[0] >= 'a') && (FEN_string[0] <= 'h')
	&& (FEN_string[1] >= '1') && (FEN_string[1] <= '8')) {
	pos->en_passant_square = rowcol2square(FEN_string[1] - '1', FEN_string[0] - 'a');
    }

    return true;
}

bool parse_FEN_to_global_position(char *FEN_string, global_position_t *pos)
{
    int row, col;
    global_position_t localpos;

    memset(&localpos, 0, sizeof(global_position_t));
    localpos.en_passant_square = ILLEGAL_POSITION;

    while (*FEN_string == ' ') FEN_string ++;

    for (row=7; row>=0; row--) {
	for (col=0; col<=7; col++) {
	    switch (*FEN_string) {
	    case '1':
	    case '2':
	    case '3':
	    case '4':
	    case '5':
	    case '6':
	    case '7':
	    case '8':
		/* subtract one here since the 'for' loop will bump col by one */
		col += *FEN_string - '0' - 1;
		if (col > 7) return false;
		break;

	    case 'k':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), BLACK, KING)) return false;
		break;
	    case 'K':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), WHITE, KING)) return false;
		break;

	    case 'q':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), BLACK, QUEEN)) return false;
		break;
	    case 'Q':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), WHITE, QUEEN)) return false;
		break;

	    case 'r':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), BLACK, ROOK)) return false;
		break;
	    case 'R':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), WHITE, ROOK)) return false;
		break;

	    case 'b':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), BLACK, BISHOP)) return false;
		break;
	    case 'B':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), WHITE, BISHOP)) return false;
		break;

	    case 'n':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), BLACK, KNIGHT)) return false;
		break;
	    case 'N':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), WHITE, KNIGHT)) return false;
		break;

	    case 'p':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), BLACK, PAWN)) return false;
		break;
	    case 'P':
		if (!place_piece_in_global_position(&localpos, rowcol2square(row, col), WHITE, PAWN)) return false;
		break;

	    default:
		return false;
	    }
	    FEN_string++;
	}
	if (row > 0) {
	  if (*FEN_string != '/') return false;
	  else FEN_string++;
	}
    }

    if (*FEN_string != ' ') return false;
    while (*FEN_string == ' ') FEN_string ++;

    if (*FEN_string == 'w') {
      localpos.side_to_move = WHITE;
    } else if (*FEN_string == 'b') {
      localpos.side_to_move = BLACK;
    } else {
      return false;
    }

    FEN_string ++;

    while (*FEN_string == ' ') FEN_string ++;

    /* skip castling rights (if they exist) */

    while ((*FEN_string == '-') || (*FEN_string == 'K') || (*FEN_string == 'Q')
	   || (*FEN_string == 'k') || (*FEN_string == 'q')) FEN_string ++;

    while (*FEN_string == ' ') FEN_string ++;

    /* If en passant square was specified, parse it */

    if ((FEN_string[0] >= 'a') && (FEN_string[0] <= 'h')
	&& (FEN_string[1] >= '1') && (FEN_string[1] <= '8')) {
	localpos.en_passant_square = rowcol2square(FEN_string[1] - '1', FEN_string[0] - 'a');
    }

    /* the point of using 'localpos' was to only modify pos if the parse succeeded */

    memcpy(pos, &localpos, sizeof(global_position_t));
    return true;
}

/* Note that the two buffers in this function are static, but we alternate back and forth between them,
 * so we can use this function twice in a single debugging print statement.
 */

char * global_position_to_FEN(global_position_t *position)
{
    static char buffer[2][256];
    static int which_buffer = 0;
    char *ptr = buffer[which_buffer ^= 1];
    int empty_squares;
    int row, col;

    for (row=7; row>=0; row--) {
	empty_squares=0;
	for (col=0; col<=7; col++) {
	    if ((position->board[rowcol2square(row, col)] == ' ') || (position->board[rowcol2square(row,col)] == 0)) {
		empty_squares++;
	    } else {
		if (empty_squares > 0) {
		    *(ptr++) = '0' + empty_squares;
		    empty_squares = 0;
		}
		*(ptr++) = position->board[rowcol2square(row,col)];
	    }
	}
	if (empty_squares > 0) {
	    *(ptr++) = '0' + empty_squares;
	}
	if (row > 0) *(ptr++) = '/';
    }

    *(ptr++) = ' ';

    *(ptr++) = (position->side_to_move == WHITE) ? 'w' : 'b';

    /* no castling rights */

    *(ptr++) = ' ';
    *(ptr++) = '-';
    *(ptr++) = ' ';

    if (position->en_passant_square == ILLEGAL_POSITION) {
	*(ptr++) = '-';
    } else {
	*(ptr++) = 'a' + COL(position->en_passant_square);
	*(ptr++) = '1' + ROW(position->en_passant_square);
    }

    *(ptr++) = '\0';

    return buffer[which_buffer];
}

char * index_to_FEN(tablebase_t *tb, index_t index)
{
    global_position_t global;
    index_to_global_position(tb, index, &global);
    return global_position_to_FEN(&global);
}

/* This routine looks at "movestr" to try and figure out if it is a valid move from this global
 * position.  If so, it changes the global position to reflect the move and returns true.
 * Otherwise, it leaves the global position alone and returns false.
 */

bool parse_move_in_global_position(char *movestr, global_position_t *global)
{
    int origin_square, destination_square;
    bool is_capture = false;
    unsigned char promotion_piece = '\0';

    if (movestr[0] >= 'a' && movestr[0] <= 'h' && movestr[1] >= '1' && movestr[1] <= '8') {
	origin_square = movestr[0]-'a' + (movestr[1]-'1')*8;
	movestr += 2;
    } else {
	return false;
    }

    if (movestr[0] == 'x') {
	is_capture = true;
	movestr ++;
    }

    if (movestr[0] >= 'a' && movestr[0] <= 'h' && movestr[1] >= '1' && movestr[1] <= '8') {
	destination_square = movestr[0]-'a' + (movestr[1]-'1')*8;
	movestr += 2;
    } else {
	return false;
    }

    if (movestr[0] == '=') {
	movestr ++;
	promotion_piece = movestr[0];
    }

    if (!(global->board[origin_square] >= 'A' && global->board[origin_square] <= 'Z')
	&& global->side_to_move == WHITE)
	return false;

    if (!(global->board[origin_square] >= 'a' && global->board[origin_square] <= 'z')
	&& global->side_to_move == BLACK)
	return false;

    if (global->board[destination_square] >= 'A' && !is_capture) return false;

    if (((global->board[origin_square] == 'P') || (global->board[origin_square] == 'p'))
	&& is_capture && (destination_square == global->en_passant_square)) {

	if (global->side_to_move == WHITE) {
	    global->board[global->en_passant_square - 8] = 0;
	} else {
	    global->board[global->en_passant_square + 8] = 0;
	}

    } else {

	if (!(global->board[destination_square] >= 'A' && global->board[destination_square] <= 'Z')
	    && is_capture && global->side_to_move == BLACK)
	    return false;

	if (!(global->board[destination_square] >= 'a' && global->board[destination_square] <= 'z')
	    && is_capture && global->side_to_move == WHITE)
	    return false;
    }

    global->board[destination_square] = promotion_piece ? promotion_piece : global->board[origin_square];
    global->board[origin_square] = 0;

    if (global->side_to_move == WHITE)
	global->side_to_move = BLACK;
    else
	global->side_to_move = WHITE;

    global->en_passant_square = ILLEGAL_POSITION;

    if ((global->board[destination_square] == 'P') && (origin_square == destination_square - 16)) {
	if (((destination_square % 8 != 0) && (global->board[destination_square - 1] == 'p'))
	    || ((destination_square % 8 != 7) && (global->board[destination_square + 1] == 'p'))) {
	    global->en_passant_square = destination_square - 8;
	}
    }
    if ((global->board[destination_square] == 'p') && (origin_square == destination_square + 16)) {
	if (((destination_square % 8 != 0) && (global->board[destination_square - 1] == 'P'))
	    || ((destination_square % 8 != 7) && (global->board[destination_square + 1] == 'P'))) {
	    global->en_passant_square = destination_square + 8;
	}
    }

    return true;
}


/***** READING AN EXISTING TABLEBASE *****/

/* We're reading from a compressed tablebase, possibly over the network.  We want to make a single
 * sequential pass over the file, even though we may have multiple threads running concurrently.
 *
 * We read blocks of futurebase_stride entries at a time, and maintain as many blocks as we have
 * threads.
 *
 * fetch_entry() can be called with an index, which causes that index to be read into the current
 * thread's block, or it can be called with no arguments, which causes the next sequential block to
 * be read from disk.  In either case, the starting index in the block is returned.
 *
 * futurebase_stride is the number of index entries to read as a block.  It must be a power of two,
 * so that we can round down to the stride boundary by ANDing with ~(futurebase_stride - 1), and it
 * must be at least eight, so that futurebase_stride/8 is an exact division and blocks fit evenly on
 * byte boundaries, even if the entries themselves are not byte-aligned.
 */

const int futurebase_stride = 16384;

static_assert((futurebase_stride & (futurebase_stride - 1)) == 0,
	      "futurebase_stride must be a power of two");
static_assert(futurebase_stride >= 8,
	      "futurebase_stride must be at least eight");

thread_local tablebase_t * cached_tb = nullptr;
thread_local char * cached_entries = nullptr;
thread_local index_t cached_index;

index_t tablebase_t::fetch_entry(index_t index = INVALID_INDEX)
{
    /* If we're switching tablebases, discard old cache.  No locking required since we're working on
     * thread_local variables.
     */

    if (cached_tb && (cached_tb != this)) {
	delete [] cached_entries;
	cached_entries = nullptr;
	cached_tb = nullptr;
    }

    if (! cached_tb) {

	/* If cache is non existant, build it */

	if (instream == nullptr) {
	    fatal("fetch_entry() called on a non-preloaded tablebase\n");
	    terminate();
	}

	cached_tb = this;

	/* The calculation here is that format.bits bytes is enough space for 8 entries. */

	cached_entries = new char[format.bits * futurebase_stride / 8];

    } else if ((index & ~(futurebase_stride - 1)) == cached_index) {

	/* We've got the requested index in the cache */

	return cached_index;

    }

    /* Round down to stride boundary */

    if (index != INVALID_INDEX) index &= ~(futurebase_stride - 1);

    /* Mutex lock to protect the remainder of this function.  Only one thread should be accessing
     * tablebase variable next_read_index or calling zlib.
     */

    static std::mutex cache_lock;
    std::lock_guard<std::mutex> _(cache_lock);

    if (index == INVALID_INDEX) {
	index = next_read_index;
    }

    if (index != next_read_index) {
	instream->seekg(index * format.bits / 8);
	next_read_index = index;
    }

    if (next_read_index + futurebase_stride <= num_indices) {
	instream->read(cached_entries, format.bits * futurebase_stride / 8);
	next_read_index += futurebase_stride;
    } else {
	/* short read at end of file */
	int bytes_to_read = format.bits * (num_indices - next_read_index) / 8;
	if ((format.bits * (num_indices - next_read_index)) % 8 != 0) bytes_to_read ++;
	instream->read(cached_entries, bytes_to_read);
	next_read_index = num_indices;
    }

    // XXX put this error handling back in
#if 0
    if (zlib_read(file, cached_entries, format.bits * futurebase_stride / 8) != format.bits * futurebase_stride / 8) {
	/* Might get a short read at the end of a tablebase, otherwise complain */

	if (next_read_index + futurebase_stride <= num_indices) {
	    fatal("fetch_entry() hit EOF reading from disk\n");
	}
    }
#endif


    cached_index = index;

    return index;
}

/* To retrieve fields in the tablebase, we call fetch_entry() to both get the index into
 * cached_entries and return the starting index, which is subtracted to get an index offset into
 * cached_entries.
 */

int tablebase_t::get_DTM(index_t index)
{
    index -= fetch_entry(index);
    return get_int_field(cached_entries, format.dtm_offset + index * format.bits, format.dtm_bits);
}

bool tablebase_t::get_flag(index_t index)
{
    index -= fetch_entry(index);
    return get_bit_field(cached_entries, format.flag_offset + index * format.bits);
}

unsigned int tablebase_t::get_basic(index_t index)
{
    index -= fetch_entry(index);
    return get_unsigned_int_field(cached_entries, format.basic_offset + index * format.bits, 2);
}


/* THE ENTRIES TABLE - this is the tablebase under construction
 *
 * EntriesTable is a virtual class so that it can be implemented either in memory or on disk.
 *
 * PTM = Player to Move
 * PNTM = Player not to Move
 *
 */

/* The individual entries are formed from bit fields.  Here we specify their sizes and offsets. */

int dtm_offset;
uint8_t dtm_bits;
uint dtm_bitmask;

int movecnt_offset;
uint8_t movecnt_bits;
uint movecnt_bitmask;

int capture_possible_flag_offset;
const uint capture_possible_flag_bitmask = 1;

#define MOVECNT_MASK ((1U << movecnt_bits) - 1)

#define MOVECNT_PTM_WINS_PROPED (MOVECNT_MASK)
#define MOVECNT_PNTM_WINS_PROPED (MOVECNT_MASK - 1)
#define MOVECNT_PTM_WINS_UNPROPED (MOVECNT_MASK - 2)
#define MOVECNT_STALEMATE (MOVECNT_MASK - 3)
#define MOVECNT_MAX (MOVECNT_MASK - 4)
#define MOVECNT_PNTM_WINS_UNPROPED (0)

/* A templated class for tablebase entries.
 *
 * We want two slightly different versions, one for atomic entries in a big, shared array, and
 * another for non-atomic entries manipulated by a single thread.  They're almost the same except
 * that the atomic version provides an extra function, compare_exchange_weak(), and the logic to set
 * bitfields in an entry is more sophisticated.
 */

template <typename T, bool isAtomic> class entry;

typedef uint16_t entry_t;

typedef entry<std::atomic<entry_t>, true> atomic_entry;
typedef entry<entry_t, false> nonatomic_entry;

template <typename T, bool isAtomic> class entry {

private:
    T e;

    /* nonatomic_entry needs to expose 'e' to atomic_entry */
    friend atomic_entry;

public:

    entry(entry_t e = 0): e(e) {
    }

    entry(unsigned int movecnt, int dtm): entry(0) {
	set_movecnt(movecnt);
	set_raw_DTM(dtm);
    }

    /* atomic_entry can be implicitly converted to nonatomic_entry (when we read the array), and a
     * nonatomic_entry can be atomically assigned to an atomic_entry (when we write the array).  A
     * third possibility, for atomic_entry only, is compare_exchange_weak().
     */

    template <bool A=isAtomic, typename = typename std::enable_if<A>::type>
    operator nonatomic_entry () { return nonatomic_entry(e); }

    template <bool A=isAtomic, typename = typename std::enable_if<A>::type>
    atomic_entry & operator=(const nonatomic_entry &val) {
	e = val.e;
	return *this;
    }

    template <bool A=isAtomic, typename = typename std::enable_if<A>::type>
    bool compare_exchange_weak(nonatomic_entry & expected, nonatomic_entry desired) {
	return e.compare_exchange_weak(expected.e, desired.e);
    }

    /* Bitfields can be accessed for both types.  Atomic access requires a bit more work, though. */

    unsigned int get_unsigned_bitfield(int offset, int bitmask) {
	return (e >> offset) & bitmask;
    }

    template <bool A=isAtomic>
    typename std::enable_if<!A, void>::type set_unsigned_bitfield(int offset, int bitmask, unsigned int val) {
	e &= ~(bitmask << offset);
	e |= (val & bitmask) << offset;
    }

    template <bool A=isAtomic>
    typename std::enable_if<A, void>::type set_unsigned_bitfield(int offset, int bitmask, unsigned int val) {
	entry_t expected = e;
	entry_t desired;

	do {
	    desired = expected;
	    desired &= ~(bitmask << offset);
	    desired |= (val & bitmask) << offset;
	} while (! e.compare_exchange_weak(expected, desired));
    }

    /* Signed bitfields need to be sign-extended when we read from them. */

    int get_signed_bitfield(int offset, int bitmask) {
	int val = (e >> offset) & bitmask;
	if (val > (bitmask >> 1)) val |= (~ (bitmask >> 1));
	return val;
    }

    void set_signed_bitfield(int offset, int bitmask, int val) {
	set_unsigned_bitfield(offset, bitmask, val);
    }

    /* Now we have method functions that access specific bitfields. */

    void set_raw_DTM(int dtm) {
	set_signed_bitfield(dtm_offset, dtm_bitmask, dtm);
    }

    int get_raw_DTM(void) {
	return get_signed_bitfield(dtm_offset, dtm_bitmask);
    }

    void set_movecnt(unsigned int movecnt) {
	set_unsigned_bitfield(movecnt_offset, movecnt_bitmask, movecnt);
    }

    unsigned int get_movecnt(void) {
	return get_unsigned_bitfield(movecnt_offset, movecnt_bitmask);
    }

    bool get_capture_possible_flag(void) {
	if (capture_possible_flag_offset == -1) return false;
	return get_unsigned_bitfield(capture_possible_flag_offset, 1);
    }

    void set_capture_possible_flag(bool flag) {
	if (capture_possible_flag_offset == -1) return;
	set_unsigned_bitfield(capture_possible_flag_offset, 1, flag);
    }

    /* More complicated combinations of the movecnt field */

    bool does_PTM_win(void) {
	return (get_movecnt() == MOVECNT_PTM_WINS_PROPED) || (get_movecnt() == MOVECNT_PTM_WINS_UNPROPED);
    }

    bool does_PNTM_win(void) {
	return (get_movecnt() == MOVECNT_PNTM_WINS_PROPED) || (get_movecnt() == MOVECNT_PNTM_WINS_UNPROPED);
    }

    bool is_unpropagated(void) {
	return (get_movecnt() == MOVECNT_PTM_WINS_UNPROPED) || (get_movecnt() == MOVECNT_PNTM_WINS_UNPROPED);
    }

    bool is_normal_movecnt(void) {
	return (get_movecnt() > MOVECNT_PNTM_WINS_UNPROPED) && (get_movecnt() <= MOVECNT_MAX);
    }

    void set_PTM_wins_unpropagated(void) {
	set_movecnt(MOVECNT_PTM_WINS_UNPROPED);
    }

    void flag_as_propagated(void) {
	if (does_PTM_win()) {
	    set_movecnt(MOVECNT_PTM_WINS_PROPED);
	} else {
	    set_movecnt(MOVECNT_PNTM_WINS_PROPED);
	}
    }

    /* Get DTM in a more suitable format
     *
     * 0 = draw
     * 1 = PNTM in check (illegal position)
     * N = mate in N-1
     * -1 = PTM checkmated
     * -N = PNTM will have a mate in N-1 after this move
     *
     * The difference between get_DTM (here) and get_raw_DTM (above) is that if the DTM value is
     * less than zero (PNTM wins), but movecnt is still greater than zero, then there are still
     * moves that might let PTM slip off the hook, so in that case we indicate draw.
     *
     * There's also a tablebase member function called get_DTM() that retrieves this value from a
     * computed tablebase, while this function works on the tablebase under construction.
     */

    int get_DTM(void) {
	return (does_PTM_win() || does_PNTM_win()) ? get_raw_DTM() : 0;
    }
};



class EntriesTable {

 protected:

    atomic_entry zero;

    uint8_t bits;
    uint8_t threads;				/* number of threads accessing the table */

    /* Here we compute the sizes of the bit fields.
     *
     * capture possible flag - 1 bit, only if we're doing a suicide analysis
     * distance to mate - not sure, but our first pass only needs to copy dtm values
     *    from futurebases, and we know their dtm ranges
     * move count - the simple calculation here could be improved upon
     */

    void ComputeBitfields(void) {

	/* We've already preloaded our futurebases, so min_tracked_dtm and max_tracked_dtm tell us
	 * the minumum and maximum DTMs we'll need during futurebase backprop.  Make sure we've got
	 * enough room in our DTM field to handle anything from our futurebases, then we'll expand
	 * the field later if we need more space.
	 */

	if (tracking_dtm) {
	    for (dtm_bits = 1; (max_tracked_dtm > (1 << (dtm_bits - 1)) - 1)
		     || (min_tracked_dtm < -(1 << (dtm_bits - 1))); dtm_bits ++);
	} else {
	    dtm_bits = 0;
	}

	unsigned int max_white_moves = 0;
	unsigned int max_black_moves = 0;

	/* Compute the moves available to each side and use this to size the movecnt field */

	for (int piece = 0; piece < current_tb->num_pieces; piece ++) {
	    unsigned int *max_moves = (current_tb->pieces[piece].color == WHITE) ? &max_white_moves : &max_black_moves;
	    switch (current_tb->pieces[piece].piece_type) {
	    case KING:
	    case KNIGHT:
		*max_moves += 8; break;
	    case QUEEN:
		*max_moves += 28; break;
	    case ROOK:
	    case BISHOP:
		*max_moves += 14; break;
	    case PAWN:
		*max_moves += 12; break;
	    }
	}

	/* We double the calculated move counts if the tablebase has 8-way symmetry because then we
	 * have to deal with multiplicity - some of the positions double up into individual indices
	 * and some do not.  The doubled positions have twice as many moves as the others.  We don't
	 * worry about this for 4-way or 2-way symmetry because then all of the positions double (or
	 * quadruple).
	 */

	if (current_tb->symmetry == 8) {
	    max_white_moves *= 2;
	    max_black_moves *= 2;
	}

	info("%d maximum white moves; %d maximum black moves\n", max_white_moves, max_black_moves);

	for (movecnt_bits = 3; (max_white_moves > MOVECNT_MAX)
		 || (max_black_moves > MOVECNT_MAX); movecnt_bits ++);

	movecnt_bitmask = (1 << movecnt_bits) - 1;

	if (current_tb->variant == VARIANT_NORMAL) {
	    capture_possible_flag_offset = -1;
	    movecnt_offset = 0;
	} else {
	    capture_possible_flag_offset = 0;
	    movecnt_offset = 1;
	}

	/* The DTM field is deliberately last */

	dtm_offset = movecnt_offset + movecnt_bits;

	bits = 8 * sizeof(entry_t);
	dtm_bits = bits - dtm_offset;

	dtm_bitmask = (1 << dtm_bits) - 1;
    }

    void print_current_format(void) {
	info("%d bits movecnt", movecnt_bits);
	if (dtm_bits > 0) info("; %d bits dtm", dtm_bits);
	if (capture_possible_flag_offset != -1) info("; capture possible flag");
	info("\n");
    }

 public:
    EntriesTable(void) {

	ComputeBitfields();

	info("Entries format: ");
	print_current_format();

	threads = 1;
    }

    /* DiskEntriesTable will want to delete some files, so this destructor has to be virtual. */

    virtual ~EntriesTable() { }

    /* The main thing we want to do with an EntriesTable is to access the entries!  This function is
     * virtual because DiskEntriesTable may need to access the disk in order to produce an entry.
     */

    virtual atomic_entry & operator[](index_t index) {
	return zero;
    }

    /* Sets the number of threads accessing the table.
     *
     * Used by the disk-based version of this class to figure out how many threads it has to wait
     * for before it advances the buffer in the disk file.  If we have less than this number of
     * threads, the code will stall indefinately waiting for the remaining, non-existant threads.
     *
     * XXX the very existence of this function is a kludge
     */

    void set_threads(uint8_t threads) {
	this->threads = threads;
    }

    /* This function is virtual so that subclasses can do a better job of handling a DTM overflow.
     * We only use it at the beginning of a pass.
     */

    virtual void verify_DTM_field_size(int dtm) {
	if (! tracking_dtm) return;
	if (((dtm > 0) && (dtm > ((1 << (dtm_bits - 1)) - 1)))
	    || ((dtm < 0) && (dtm < -(1 << (dtm_bits - 1))))) {
	    fatal("DTM entry field size exceeded\n");
	    terminate();
	}
    }

    /* Seven possible ways we can initialize a tablebase entry for a position:
     *  - it's illegal
     *  - PNTM's mated
     *  - PTM's mated
     *  - stalemate
     *  - conceded as a win by a pruning statement
     *  - resigned as a loss by a pruing statement
     *  - any other position, with 'movecnt' possible moves out the position
     */

    void initialize_entry(index_t index, int movecnt, int dtm) {
#ifdef DEBUG_MOVE
	if (index == DEBUG_MOVE) {
	    info("initialize index %" PRIindex " %s movecnt %d; dtm %d\n",
		 index, index_to_FEN(current_tb, index), movecnt, dtm);
	}
#endif

	/* We always initialize with fairly small DTMs (never bigger than two), so we don't need to
	 * check these array bounds for overflow here.
	 */
	if (dtm > 0) positive_passes_needed[dtm] = true;
	if (dtm < 0) negative_passes_needed[-dtm] = true;

	(*this)[index] = nonatomic_entry(movecnt, dtm);
    }

    void initialize_entry_as_illegal(index_t index) {

	/* An "illegal" position is something like one with two pieces both on the same square.  An
	 * illegal position in the chess sense, of PNTM being in check, is handled below.  So this
	 * function needs to flag the position in such a way that nothing will ever get done with
	 * it; in particular, no attempt will ever be made to back propagate it.  Setting everything
	 * to zero does the trick.  The zero movecnt doesn't matter, since we'll never back
	 * propagate into this position, and the zero DTM ensures that it will always be treated
	 * like a draw during a back prop pass - i.e, no attempt will ever be made to finalize it.
	 */

	initialize_entry(index, 0, 0);
    }

    void initialize_entry_with_PTM_mated(index_t index) {

	/* This is a classic checkmate - PTM is in check and has no semi-legal moves, let along
	 * legal ones.  The case where PTM has semi-legal but no legal moves is handled below, in
	 * add_one_to_PNTM_wins().  DTM is -1 here - PNTM wins.
	 */

	initialize_entry(index, MOVECNT_PNTM_WINS_UNPROPED, -1);

	total_legal_positions ++;
    }

    void initialize_entry_with_PNTM_mated(index_t index) {

	/* In ordinary chess, this kind of position is illegal - PNTM's king can be captured.  We
	 * don't count moves into check as part of "movecnt", so we don't want to back propagate
	 * from this position.  So we just flag it as a propagated win, DTM 1.
	 *
	 * On the other hand, if we're doing a suicide analysis, a PNTM-mated position is a
	 * stalemate in ordinary terms (PTM can't move and therefore wins), so we do want to back
	 * propagate.
	 */

	if (current_tb->variant == VARIANT_NORMAL) {
	    initialize_entry(index, MOVECNT_PTM_WINS_PROPED, 1);
	} else {
	    initialize_entry(index, MOVECNT_PTM_WINS_UNPROPED, 1);
	}

	total_PNTM_mated_positions ++;
    }

    void initialize_entry_with_stalemate(index_t index) {

	/* The only way this function gets called is if the number of semi-legal moves out of the
	 * position is zero and we're not in check.  A "semi-legal" move is one that might not
	 * actually be legal (because it would move into check), but will be back-propagated in the
	 * tablebase.  A stalemate that arises from a position with semi-legal moves but no legal
	 * moves will get handled in add_one_to_PNTM_wins() once all of the semi-legal moves have
	 * been eliminated.  In short, because there are no semi-legal moves out of this position,
	 * we'll never back propagate into this position, so setting movecnt = 1 is an acceptable
	 * way of flagging this as a stalemate, since this position's movecnt should never get
	 * decremented.
	 */

	if (current_tb->stalemate_prune_type == RESTRICTION_CONCEDE) {
	    if (index_to_side_to_move(current_tb, index) == current_tb->stalemate_prune_color) {
		initialize_entry(index, MOVECNT_PTM_WINS_UNPROPED, 2);
	    } else {
		initialize_entry(index, MOVECNT_PNTM_WINS_UNPROPED, -2);
	    }
	} else {
	    initialize_entry(index, MOVECNT_STALEMATE, 0);
	    total_stalemate_positions ++;
	}

	total_legal_positions ++;
    }

    void initialize_entry_with_concede(index_t index) {

	initialize_entry(index, MOVECNT_PTM_WINS_UNPROPED, 2);

	total_legal_positions ++;
    }

    void initialize_entry_with_resign(index_t index) {

	initialize_entry(index, MOVECNT_PNTM_WINS_UNPROPED, -2);

	total_legal_positions ++;
    }

    void initialize_entry_with_movecnt(index_t index, unsigned int movecnt) {

	if (movecnt > MOVECNT_MAX) {
	    fatal("Attempting to initialize position with a movecnt (%d) that won't fit in field!\n", movecnt);
	}

	initialize_entry(index, movecnt, 0);

	total_legal_positions ++;
    }
};

class EntriesTablePtr {
    EntriesTable * entriesTable;

public:
    EntriesTablePtr(void) {
	entriesTable = nullptr;
    }

    EntriesTablePtr & operator=(EntriesTable * table) {
	entriesTable = table;
	return *this;
    }

    atomic_entry & operator[](index_t index) {
	return (*entriesTable)[index];
    }

    EntriesTable * operator->() {
	return entriesTable;
    }

    operator EntriesTable * () {
	return entriesTable;
    }
};

/* MemoryEntriesTable - an EntriesTable held completely in memory */

class MemoryEntriesTable: public EntriesTable {

 private:
    atomic_entry * entries;

 public:
    MemoryEntriesTable(void) {
	size_t bytes = current_tb->num_indices * sizeof(atomic_entry);
	try {
	    entries = new atomic_entry [current_tb->num_indices];
	    if (bytes < 1024*1024) {
		info("Malloced %zdKB for tablebase entries\n", bytes/1024);
	    } else {
		info("Malloced %zdMB for tablebase entries\n", bytes/(1024*1024));
	    }
	} catch (std::bad_alloc ex) {
	    fatal("Can't malloc %zdMB for tablebase entries: %s\n", bytes/(1024*1024), ex.what());
	}
    }

    atomic_entry & operator[](index_t index) {
	return entries[index];
    }
};

/* An EntriesTable held mostly on disk.
 *
 * If we're multi-threaded, we work on a entry buffer, then wait until all of the threads are ready
 * to move on.  At the end of a pass, wait until all of the threads are ready to reset back to the
 * beginning, then reset back to the beginning of the disk file.
 *
 * XXX Current implementation detects when a thread is 'ready' by waiting until it attempts to
 * access outside of the entry buffer, since we provide the thread no way to signal when it's done
 * with a particular table entry.  Among other things, this requires that we know exactly how many
 * threads are working on the entries table.  Otherwise we'll wait forever for a thread that isn't
 * accessing the table at all!
 */

/* atomic_entries_array is a simple wrapper class around an array of atomic_entry's that provides
 * methods for reading and writing it as a raw binary array.
 */

static const int entry_buffer_size = 4096;

class atomic_entries_array {

    atomic_entry entries[entry_buffer_size];

public:

    atomic_entry & operator[](index_t index) {
	return entries[index];
    }

    void zero(void) {
	std::fill(entries, entries + entry_buffer_size, nonatomic_entry());
    }

    void operator>> (std::ostream& os) {
	os.write(reinterpret_cast<char *>(entries), sizeof(entries));
    }

    void operator<< (std::istream& is) {
	is.read(reinterpret_cast<char *>(entries), sizeof(entries));
	/* It's a bug in boost iostreams that eof isn't set by the read, but let's do it now. */
	if (is.gcount() != sizeof(entries)) {
	    is.setstate(BOOST_IOS::eofbit);
	}
    }

};

/* temporary_file implements a temporary disk file that presents input and output streams, can be
 * optionally compressed, and will be deleted on disk when the object is destroyed.
 */

class temporary_file {

    char filename[16];
    int fd;
    bool compress;

    io::file_descriptor device(void)
    {
	lseek(fd, 0, SEEK_SET);
	return io::file_descriptor(fd, io::never_close_handle);
    }

public:
    temporary_file(std::string filename_template = "entriesXXXXXX", bool compress = true)
	: compress(compress)
    {
	strcpy(filename, filename_template.c_str());
	fd = mkostemp(filename, O_RDWR | O_CREAT | O_EXCL);

	if (fd == -1) {
	    fatal("Can't open '%s' for writing: %s\n", filename, strerror(errno));
	}
    }

    std::ostream * ostream(void)
    {
	io::filtering_ostream * os = new io::filtering_ostream;

	if (compress) os->push(io::gzip_compressor());
	os->push(device());
	os->exceptions(BOOST_IOS::failbit | BOOST_IOS::badbit);

	return os;
    }

    std::istream * istream(void)
    {
	io::filtering_istream * is = new io::filtering_istream;

	if (compress) is->push(io::gzip_decompressor());
	is->push(device());
	//is->exceptions(BOOST_IOS::failbit | BOOST_IOS::badbit);

	return is;
    }

    ~temporary_file(void)
    {
	close(fd);
	unlink(filename);
    }
};

class DiskEntriesTable: public EntriesTable {

 private:
    std::istream * entries_read_stream;
    std::ostream * entries_write_stream;

    temporary_file * entries_read_device;
    temporary_file * entries_write_device;

    std::mutex ready_to_advance_mutex;
    std::condition_variable ready_to_advance_cond;
    std::condition_variable ready_to_reset_cond;
    int threads_waiting_to_advance;
    int threads_waiting_to_reset;

    /* This is the in-memory portion of the table, and the index number of the first entry.  */

    atomic_entries_array entries;
    index_t entry_buffer_start;

    void open_new_entries_write_file(void)
    {
	entries_write_device = new temporary_file("entriesXXXXXX", compress_entries_table);
	entries_write_stream = entries_write_device->ostream();
    }

    void advance_entry_buffer(void)
    {
	entries >> *entries_write_stream;

	if (entries_read_device != nullptr) {
	    entries << *entries_read_stream;
	} else {
	    entries.zero();
	}

	entry_buffer_start += entry_buffer_size;
    }

    void wait_for_all_threads_ready_then_advance_entry_buffer(void) {
	std::unique_lock<std::mutex> lock(ready_to_advance_mutex);

	threads_waiting_to_advance ++;
	if (threads_waiting_to_advance + threads_waiting_to_reset < threads) {
	    ready_to_advance_cond.wait(lock);
	} else {
	    advance_entry_buffer();
	    threads_waiting_to_advance = 0;
	    ready_to_advance_cond.notify_all();
	}
    }

    void reset_files(void) {

	/* We're reseting for a new pass.  Write the current buffer out, write out everything left
	 * in the input file, switch the output file to become the next pass's input file, destroy
	 * the old input file, and create a new output file.
	 */

	entries >> *entries_write_stream;

	if (entries_read_device != nullptr) {
	    while (! entries_read_stream->eof()) {
		entries << *entries_read_stream;
		entries >> *entries_write_stream;
	    }
	    delete entries_read_stream;
	    delete entries_read_device;
	}

	entries_read_device = entries_write_device;

	/* Do this before creating the read stream, because it may need to flush output to
	 * the old write file, which is the new read file.
	 */

	if (entries_write_stream) delete entries_write_stream;
	open_new_entries_write_file();

	entries_read_stream = entries_read_device->istream();

	entry_buffer_start = 0;

	entries << *entries_read_stream;
    }

    void wait_for_all_threads_ready_then_reset(void) {
	std::unique_lock<std::mutex> lock(ready_to_advance_mutex);

	threads_waiting_to_reset ++;
	if (threads_waiting_to_reset < threads) {
	    ready_to_reset_cond.wait(lock);
	} else {
	    reset_files();
	    threads_waiting_to_reset = 0;
	    ready_to_reset_cond.notify_all();
	}
    }

    void advance_entry_buffer_to_index(index_t index)
    {
	if (entry_buffer_start > index) wait_for_all_threads_ready_then_reset();
	while (index >= entry_buffer_start + entry_buffer_size) {
	    wait_for_all_threads_ready_then_advance_entry_buffer();
	}
    }

 public:
    DiskEntriesTable(void) {

	threads_waiting_to_advance = 0;
	threads_waiting_to_reset = 0;

	entry_buffer_start = 0;

	entries_read_device = nullptr;
	open_new_entries_write_file();
    }

    ~DiskEntriesTable(void) {
	if (entries_read_device != nullptr) delete entries_read_device;
	if (entries_write_device != nullptr) delete entries_write_device;
    }

    atomic_entry & operator[](index_t index) {
	advance_entry_buffer_to_index(index);

	return entries[index - entry_buffer_start];
    }
};


/***** INTRA-TABLE BACK PROPAGATION *****/


EntriesTablePtr entriesTable;

/* finalize_update()
 *
 * starting with PTM_wins() and add_one_to_PNTM_wins()
 *
 * finalize_update() is called once we've labeled a position won for either one player or the other,
 * backed out its moves, figured out a position that leads to it in one move, and are ready to
 * update that other postion with the knowledge that either PTM can win, or that some of the moves
 * that lead out of it result in PNTM wins.
 *
 * Starting with 1.816, I've introduced a lockless update that uses C++11's atomic compare-exchange
 * primitive.  If another processor changes the entry while we're working on it, we go back and do
 * the calculation again.  The locks ran pretty quick, but burned a bit on each entry.
 */

inline void PTM_wins(index_t index, int dtm)
{
    nonatomic_entry expected = entriesTable[index];
    nonatomic_entry desired;

#ifdef DEBUG_MOVE
    if (index == DEBUG_MOVE)
	info("PTM_wins; index=%" PRIindex "; dtm=%d; table dtm=%d\n",
	     index, dtm, expected.get_raw_DTM());
#endif

    do {
	desired = expected;

	if (dtm < 0) {

	    fatal("Negative distance to mate in PTM_wins!?\n");

	} else if (desired.is_normal_movecnt()) {

	    /* In ordinary chess, we should never get here with MOVECNT_PNTM_WINS_UNPROPED (or
	     * PROPED) because we have to have decremented the movecnt already to zero to have
	     * gotten either of those flags.  However, if this is a suicide analysis, we can get a
	     * MOVECNT_PNTM_WINS from a forced capture, so we have to exclude this cases.  In any
	     * event, this code fragment only runs for a "normal" movecnt field - none of the five
	     * special cases.
	     */

	    desired.set_PTM_wins_unpropagated();
	    desired.set_raw_DTM(dtm);
	    if (dtm <= max_tracked_dtm) positive_passes_needed[dtm] = true;

	} else if ((dtm < desired.get_raw_DTM())
		   && (desired.does_PTM_win())
		   && (desired.is_unpropagated())) {

	    /* This can happen if we get a PTM mate during futurebase back prop, then, later during
	     * futurebase back prop or during intra-table back prop, improve upon the mate.
	     */

	    desired.set_raw_DTM(dtm);
	    if (dtm <= max_tracked_dtm) positive_passes_needed[dtm] = true;
	}
    } while (!entriesTable[index].compare_exchange_weak(expected, desired));
}

inline void add_one_to_PNTM_wins(index_t index, int dtm)
{
    nonatomic_entry expected = entriesTable[index];
    nonatomic_entry desired;

#ifdef DEBUG_MOVE
    if (index == DEBUG_MOVE)
	info("add_one_to_PNTM_wins; index=%" PRIindex "; dtm=%d; table dtm=%d\n",
	     index, dtm, expected.get_raw_DTM());
#endif

    do {
	desired = expected;

	if (dtm > 0) {
	    fatal("Positive distance to mate in PNTM_wins!?\n");
	} else if (desired.is_normal_movecnt()) {

	    /* Again, this is the code for a "normal" movecnt field. */

	    // XXX entriesTable[index].movecnt --;
	    desired.set_movecnt(desired.get_movecnt() - 1);

	    if ((dtm < desired.get_raw_DTM()) && (desired.get_raw_DTM() <= 0)) {
		/* Since this is PNTM wins, PTM will make the move leading to the slowest mate. */
		desired.set_raw_DTM(dtm);
	    }

	    if (desired.does_PNTM_win()) {
		/* This call pushed movecnt to zero, but the passed-in DTM might not be the best line,
		 * so that's why we fetch entry DTM here.
		 */
		dtm = desired.get_raw_DTM();
#ifdef DEBUG_PASS_DEPENDANCIES
		if ((dtm >= min_tracked_dtm) && (! negative_passes_needed[-dtm])) {
		    global_position_t global;
		    index_to_global_position(current_tb, index, &global);
		    printf("%d pass needed by %" PRIindex " %s\n",
			   dtm, index, global_position_to_FEN(&global));
		}
#endif
		if (dtm >= min_tracked_dtm) negative_passes_needed[-dtm] = true;
	    }
	}
    } while (!entriesTable[index].compare_exchange_weak(expected, desired));
}

void finalize_update(index_t index, short dtm, short movecnt, int futuremove)
{
    int i;

#if 0
    /* Skip everything if the position isn't valid.  In particular, we don't track futuremove
     * propagation for illegal positions.
     */

    if (get_entry_raw_DTM(index) == 1) return;
#endif

    /* If we're doing a suicide analysis, captures are forced, so we never want to back-propagate a
     * non-capture move into a position where a capture was possible.  For futurebase
     * back-propagation into such a position, the only futuremoves listed as possible correspond to
     * capture moves, so the code that called us should have already rejected non-capture
     * futuremoves into such a position.  Now we check the intra-tablebase case and return if the
     * capture-possible-flag is set.
     */

    if ((current_tb->variant == VARIANT_SUICIDE) && (futuremove == NO_FUTUREMOVE)
	&& entriesTable[index].get_capture_possible_flag()) {
	return;
    }

    /* The guts of committing an update into the entries table. */

    if (dtm > 0) {
	PTM_wins(index, dtm);
    } else if (dtm < 0) {
	for (i=0; i<movecnt; i++) {
	    add_one_to_PNTM_wins(index, dtm);
	}
    } else {
	/* dtm == 0; a discard; just decrement movecnt */
	nonatomic_entry expected = entriesTable[index];
	nonatomic_entry desired;
	if (expected.is_normal_movecnt()) {
	    do {
		desired = expected;
		desired.set_movecnt(desired.get_movecnt() - movecnt);
	    } while (!entriesTable[index].compare_exchange_weak(expected, desired));
	}
    }

}

/* back_propagate_index()
 *
 * As we make a single, normal, generation pass through the table, this is what we do to each entry.
 * Check to see if it's unpropagated and its DTM matches the target DTM for this pass.  If so, flag
 * it as propagated and hand it off to a routine, back_propagate_index_within_table(), defined later
 * in the code, that will back out every possible move from this position, do all sorts of subtle things,
 * and finally "adjust" the positions that lead here by calling finalize_update()!
 *
 * Note: if we're using proptables, the call to finalize_update() will be buffered until the next pass.
 */

void back_propagate_index_within_table(index_t index, int reflection);

void back_propagate_index(index_t index, int target_dtm)
{
    nonatomic_entry expected = entriesTable[index];

    if (((! tracking_dtm) && expected.is_unpropagated())
	|| (expected.get_DTM() == target_dtm)) {

	/* What could another processor change?  Well, it's not going to flip the propagated flag,
	 * because next_backprop_index (below) is atomic, so it's not going to attempt a back prop.
	 *
	 * XXX Could the DTM change (don't think so)
	 */

	nonatomic_entry desired;

	do {
	    desired = expected;
	    desired.flag_as_propagated();
	} while (!entriesTable[index].compare_exchange_weak(expected, desired));

	/* Symmetry.
	 *
	 * The only case we really have to worry about here is diagonal symmetry, because in both
	 * horizontal and vertical symmetry all of the positions neatly double up, so anytime we'd
	 * have a move backprop into our symmetry restriction from outside it, a matching move will
	 * backprop from inside out.
	 *
	 * For diagonal symmetry however, things aren't so neat, because squares along the diagonal
	 * map to themselves.  So positions where both kings are on the diagonal don't have a
	 * matching double, while the other positions do.  We deal with this here by backproping
	 * both the position itself and its matching pair (if one exists).  If one doesn't exist,
	 * then back_propagate_index_within_table() will quickly detect this case (when
	 * index_to_position returns false).  We also doubled the movecnt of "paired" positions
	 * during initialization, because moves will be backproped twice from doubled positions to
	 * doubled positions, not just assumed like the horizontal or vertical cases.
	 */

	back_propagate_index_within_table(index, REFLECTION_NONE);
	if (current_tb->symmetry == 8) {
	    back_propagate_index_within_table(index, REFLECTION_DIAGONAL);
	}

	/* Track statistics.  For the "player wins" statistics, we don't want to count illegal (PNTM
	 * mated) positions, so we don't increment anything if DTM is 1.
	 *
	 * XXX make these stats thread local
	 */

	positions_finalized_this_pass ++;

	if (expected.does_PTM_win()) {
	    if (target_dtm > 1) player_wins[index_to_side_to_move(current_tb, index)] ++;
	} else {
	    player_wins[1 - index_to_side_to_move(current_tb, index)] ++;
	}
    }
}

/* If we're not using proptables, then this section of code spawns off a number of threads to run
 * through the entries table, intra-table backpropagating to a single target DTM.  We could go
 * though the table sequentially, each thread picking the next available entry for processing, but
 * that would create a lot of contention between threads as they access adjacent entries that occupy
 * the same cache line.  Instead, we break the table into large blocks and assign a thread to each
 * one.
 *
 * XXX What happens if part of the table back props a lot faster than another part?  For, say, a ten
 * minute pass with two threads, a 1% difference in speed would result in six seconds of idle time
 * for the faster thread.  Maybe we should use smaller blocks, just big enough to avoid cache
 * conflicts.  On the other hand, Intel processors recognize sequential data access patterns and
 * prefetch data from memory, so there is a clear advantage to a simple sequential access pattern.
 */

void back_propagate_section(index_t start_index, index_t end_index, int target_dtm)
{
    index_t index;

    for (index = start_index; index <= end_index; index++) {
	print_progress_dot(current_tb);
	back_propagate_index(index, target_dtm);
    }
}

void non_proptable_pass(int target_dtm)
{
    std::thread t[num_threads];
    unsigned int thread;
    index_t block_size = current_tb->num_indices / num_threads;

    entriesTable->set_threads(num_threads);

    reset_progress_dots(current_tb);

    for (thread = 0; thread < num_threads; thread ++) {
	index_t start_index = thread*block_size;
	index_t end_index;

        if (thread != num_threads-1) {
            end_index = (thread+1)*block_size - 1;
        } else {
            end_index = current_tb->num_indices - 1;
        }

	t[thread] = std::thread(back_propagate_section, start_index, end_index, target_dtm);
    }

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread].join();
    }

    entriesTable->set_threads(1);
}


/***** PROPTABLES *****
 *
 * Proptables are used to optimize back propagation for large tablebases that can not fit into RAM.
 * A proptable is a priority queue that stores pending updates and then retrieves them in index
 * sorted order, allowing a batch of updates to be applied with a single linear pass through the
 * entries array.  We maintain two proptables, the input and the output, and as we make a single
 * pass through the tablebase, we're simultaneously committing changes from the input into the
 * current tablebase, and saving into the output any changes being generated.
 *
 * Or not.  We can disable proptables, which forces the program to use a random access pattern on
 * the entries array.  This is currently faster if the entries array can fit into RAM.  In code,
 * commit_update either calls finalize_update immediately (no proptable; random access) or enqueues
 * the update into the output proptable, so that it will later be retrieved and finalized in the
 * next call to proptable_pass, when the output proptable will have become the input proptable.
 *
 * XXX I used to have an option to store a PTM-wins-flag instead of DTM in the proptable entry to
 * make it smaller.  The only time it makes sense to use a PTM-wins-flag in the proptable is if
 * we're generating a bitbase (because otherwise we need a DTM field in the proptable).  Positive or
 * negative DTM values translate directly through to PTM wins or to its inverse, PNTM wins.  The
 * oddball is zero DTM, a draw, which only happens here if we're back propagating from a DTM
 * futurebase.  In that case, we need to look at the sense of the bitbase (white-wins or
 * white-draws), as well as which player is PTM to decide if we should set or clear the propentry's
 * flag.  I took this code out (for now).
 *
 * THE PRIORITY QUEUE
 *
 * I crafted my own priority_queue because I'm not happy with any of the existing options.
 *
 * The standard library's priority_queue holds everything in memory and thus can't deal effectively
 * with very large data sets.
 *
 * TPIE's priority_queue uses the disk, but isn't thread safe and can't compress its disk files.
 *
 * Mine is build from several pieces: an in-memory table; a templated class that dumps a container
 * to disk, then reads it back; a sorting network to read the files back in when we retreive.
 */

struct proptable_format {
    int index_offset;
    int index_bits;
    int dtm_offset;
    int dtm_bits;
    int movecnt_offset;
    int movecnt_bits;
    int futuremove_offset;
    int futuremove_bits;
    uint64_t index_mask;
    uint64_t dtm_mask;
    uint64_t movecnt_mask;
    uint64_t futuremove_mask;
    int bits;

    proptable_format(index_t num_indices, int min_dtm, int max_dtm, int movecnt_bits, int max_futuremoves)
	: movecnt_bits(movecnt_bits) {

	/* Tricky, tricky, tricky... 2^index_bits must be greater than or equal to num_indices.  dtm
	 * ranges in [min_dtm, max_dtm] inclusive, so 2^(dtm_bits-1) must be strictly greater than
	 * max_dtm and 2^(dtm_bits-1) must be greater than or equal to -min_dtm.  futuremove numbers
	 * range from 0 to max_futuremoves-1, so 2^futuremove_bits must be greater than or equal to
	 * max_futuremoves... and the senses of the comparisons are reversed for the loop!  Hope I
	 * got it all right!
	 */

	for (index_bits = 1; (1ULL << index_bits) < num_indices; index_bits ++);

	if ((max_dtm != 0) || (min_dtm != 0)) {
	    for (dtm_bits = 1; (1 << (dtm_bits - 1) <= max_dtm) || (1 << (dtm_bits - 1) < -min_dtm); dtm_bits ++);
	} else {
	    dtm_bits = 0;
	}

	for (futuremove_bits = 0; (1 << futuremove_bits) < max_futuremoves; futuremove_bits ++);

	/* Ordering is significant, since we may sort by directly comparing the marshaled values to
	 * each other.  Therefore, index has to be the most significant field.
	 */

	dtm_offset = 0;
	movecnt_offset = dtm_bits;
	futuremove_offset = movecnt_offset + movecnt_bits;
	index_offset = futuremove_offset + futuremove_bits;

	index_mask = (1ULL << index_bits) - 1;
	dtm_mask = (1ULL << dtm_bits) - 1;
	movecnt_mask = (1ULL << movecnt_bits) - 1;
	futuremove_mask = (1ULL << futuremove_bits) - 1;

	bits = index_offset + index_bits;
    }
};

/* A simple disk-backed que.
 *
 * Template argument Container is the in-memory container class we're backing up, and it has to be a
 * contiguous array.  It has to provide a value_type typedef and an iterator typedef.  Our
 * constructor takes a pair of iterators.  They have to provide a base() method that returns a
 * pointer.  Our semantics are to make a copy of the container and export a pop_front() method to
 * walk through our data.
 *
 * Caveat: Instances of this class can not be copied, because then both copies would have the same
 * file descriptor and the first one destroyed would close it.
 *
 * For bit-aligned proptables, we don't actually use this class, but specialize it later.
 */

template <typename Container>
struct disk_que {
    typedef typename Container::value_type value_type;

    temporary_file * file;
    std::istream * is;

    value_type last;

    int size;
    int next;

    disk_que(typename Container::iterator head, typename Container::iterator tail)
	: size(tail - head), next(0)
    {
	/* If we're compressing, convert the sorted array into a delta encoded list, which improves
	 * gzip's ability to compress proptables dramatically.
	 *
	 * XXX changes contents of the data passed into the function, but we can get away with this
	 * because we know it's about to be throw away
	 */

	if (compress_proptables) {
	    value_type last = *head;
	    for (auto it=head+1; it < tail; it++) {
		*it -= last;
		last += *it;
	    }
	}

	file = new temporary_file("proptableXXXXXX", compress_proptables);

	std::ostream * os = file->ostream();
	os->write(reinterpret_cast<char *>(head.base()), size * sizeof(value_type));
	delete os;

	is = file->istream();
    }

    ~disk_que() {
	delete is;
	delete file;
    }

    bool empty(void) {
	return (next == size);
    }

    value_type pop_front(void) {
	value_type val;
	if (empty()) throw "read past end of disk_que";
	is->read(reinterpret_cast<char *>(&val), sizeof(value_type));

	/* Back out delta encoding introduced above */
	if (compress_proptables) {
	    if (next > 0) {
		val += last;
	    }
	    last = val;
	}

	next ++;
	return val;
    }
};

/* A sorting network.
 *
 * We're reading from a container of pointers to subcontainers.  Each subcontainer is itself sorted,
 * but now we impose a total sort on all of them.  We do this by maintaining a binary tree (the
 * sorting network), with the subcontainers 'feeding' the leaves and each non-leaf being the
 * less-than comparison of the two nodes below it.  We also track which subcontainer each entry came
 * from originally.  Once initialized, we just read the root of the tree to get the next entry, then
 * refill whichever leaf we got the entry from (that's why we track subcontainers for each entry),
 * and run back up the tree from that leaf only, recomputing the comparisons.  It's laid out in
 * memory as an array, like this (in this example, highbit is 4):
 *
 *                    -4
 *                   /
 *                /-2--5
 *               1
 *                \-3--6
 *		     \
 *                    -7
 *
 * so that we can run that last step (backing up the tree, from right to left, in the diagram), just
 * by right shifting the index.  I got this idea from Knuth.
 */

template <class Container>
class sorting_network {

    typedef typename Container::value_type SubcontainerPtr;
    typedef typename dereference<SubcontainerPtr>::type Subcontainer;
    typedef typename Subcontainer::value_type T;

private:
    Container * containers;
    T * network;
    int * container_num;
    unsigned int highbit;

    /* We don't initialize until the first retrieval request, which allows 'containers' to be
     * modified, initially.  After we start retrieving, we expect 'containers' to be untouched.
     */

    void initialize_network(void) {

	for (highbit = 1; highbit < containers->size(); highbit <<= 1);

	network = new T[2 * highbit];
	container_num = new int[2 * highbit];

	/* Fill in the upper half of the network with either the first entry from a disk queue, or
	 * an "infinite" entry for slots with no proptables.
	 */

	for (unsigned int i=0; i<highbit; i++) {
	    if (i < containers->size()) {
		network[highbit + i] = (*containers)[i]->pop_front();
		container_num[highbit + i] = i;
	    } else {
		container_num[highbit + i] = -1;
	    }
	}

	/* Then, sort into the lower half of the network. */

	for (int network_node = highbit-1; network_node > 0; network_node --) {
	    if (container_num[2*network_node] == -1) {
		network[network_node] = network[2*network_node + 1];
		container_num[network_node] = container_num[2*network_node + 1];
	    } else if (container_num[2*network_node + 1] == -1) {
		network[network_node] = network[2*network_node];
		container_num[network_node] = container_num[2*network_node];
	    } else if (network[2*network_node] < network[2*network_node + 1]) {
		network[network_node] = network[2*network_node];
		container_num[network_node] = container_num[2*network_node];
	    } else {
		network[network_node] = network[2*network_node + 1];
		container_num[network_node] = container_num[2*network_node + 1];
	    }
	}
    }

public:

    sorting_network(Container * containers):
	containers(containers), network(nullptr), container_num(nullptr), highbit(0)
    { }

    ~sorting_network() {
	if (network) delete[] network;
	if (container_num) delete[] container_num;
    }

    bool empty(void) {
	return (highbit == 0) ? containers->empty() : (container_num[1] == -1);
    }

    const T& front(void) {
	if (highbit == 0) initialize_network();
	return network[1];
    }

    T pop_front(void) {
	if (highbit == 0) initialize_network();

	T retval = network[1];
	int network_node = highbit + container_num[1];

	if ((*containers)[container_num[1]]->empty()) {
	    container_num[network_node] = -1;
	} else {
	    network[network_node] = (*containers)[container_num[1]]->pop_front();
	}

	while (network_node > 1) {
	    network_node >>= 1;
	    if (container_num[2*network_node] == -1) {
		network[network_node] = network[2*network_node + 1];
		container_num[network_node] = container_num[2*network_node + 1];
	    } else if (container_num[2*network_node + 1] == -1) {
		network[network_node] = network[2*network_node];
		container_num[network_node] = container_num[2*network_node];
	    } else if (network[2*network_node] < network[2*network_node + 1]) {
		network[network_node] = network[2*network_node];
		container_num[network_node] = container_num[2*network_node];
	    } else {
		network[network_node] = network[2*network_node + 1];
		container_num[network_node] = container_num[2*network_node + 1];
	    }
	}

	return retval;
    }
};

/* The priority queue template.
 *
 * Initialize with the size of the in-memory portion in megabytes.  If we insert less than that
 * size, do everything in-memory.  If we insert more, then dump to disk and use a sorting network to
 * read it back.
 *
 * Our template takes three types.  The first (T) is the type to store in the priority queue, the
 * second (MemoryContainer) is a container to hold that type in memory, and the third
 * (DiskContainer) is a container to hold that type on disk.  Names notwithstanding, we don't impose
 * any memory or disk requirements in this class.  We expect MemoryContainer to export begin() and
 * end() methods that return random access iterators usable for insertion, retrieval, and sorting
 * (with std::sort).  We expect DiskContainer to take a begin/end pair of iterators as a constructor
 * and supply pop_front() for retrieval.  We just push into a MemoryContainer until it's full, sort
 * it and copy it to a DiskContainer, and keep going until we're done.  Then, if we used
 * DiskContainer at all, we sort and dump the final MemoryContainer into a DiskContainer and read
 * back from the DiskContainers using a sorting network.  Otherwise, we read back directly from a
 * single MemoryContainer, i.e, we don't use a DiskContainer at all unless we fill up a
 * MemoryContainer.
 *
 * We take advantage of multi-threading by breaking the in-memory table into equal size blocks, then
 * making each thread sort and write a single block.  This is done by detecting when we write into
 * the last num_threads elements in the table and using that as a trigger to sort and dump
 * 1/num_threads-th of it.  So long as the table is at least n^2 elements, we're fine.
 *
 * about inheriting std::mutex... we lock when we insert (though we shouldn't need this if tail can
 * be bumped atomically)... we expect the caller to already hold the lock when we retrieve... we do
 * this because we want to atomically retrieve the front element along with any elements equal to it
 */

template <typename T, typename MemoryContainer = std::vector<T>, typename DiskContainer = disk_que<MemoryContainer> >
class priority_queue : public std::mutex {

    typedef class synchronized<std::deque<std::shared_ptr<DiskContainer>>> DiskContainerQue;
    typedef typename MemoryContainer::iterator Iterator;

private:
    DiskContainerQue disk_ques;
    class sorting_network<DiskContainerQue> snetwork;

    MemoryContainer * in_memory_queue;
    Iterator head;
    Iterator tail;
    bool sorted;

    size_t remaining_space;
    size_t block_size;
    unsigned int blocks_dumped_to_disk;
    std::mutex blocks_dumped_to_disk_mutex;
    std::condition_variable blocks_dumped_to_disk_cond;

    void sort_and_dump_to_disk(Iterator begin, Iterator end) {
	/* The sort is time-consuming, so we don't lock disk_ques until it's done */
	std::sort(begin, end);
	std::lock_guard<std::mutex> _(disk_ques);
	std::shared_ptr<DiskContainer> ptr(new DiskContainer(begin, end));
	disk_ques.push_back(ptr);
    }

public:
    
    void prepare_to_retrieve(void) {

	/* XXX What I'd really like here is to detect when we get to the point where we can start
	 * retrieving, then alternate between filling the array from the front and from the back on
	 * alternate passes.  Right now, I just comment out this code and alloc a new array each
	 * time around.
	 */
#if 0
	/* If we never had to push anything to disk, just sort and retrieve in-memory.  The problem
	 * with this code is that we might not be able to free much memory, something that we can
	 * assure if we write everything out to disk.
	 */
	if (disk_ques.empty() && (remaining_space >= num_threads)) {
	    if (! sorted) {
		std::sort(head, tail);
		in_memory_queue->resize(tail-head);
		sorted = true;
	    }
	    return;
	}
#endif

	/* We assume that we're locked, so remaining_space remains constant and indicates whether
	 * other threads are dumping to disk.
	 */
	if (in_memory_queue) {
	    if (remaining_space >= num_threads) {
		if (head != tail) {
		    sort_and_dump_to_disk(head, tail);
		    tail = head;
		}
	    } else {
		unsigned int current = num_threads - remaining_space - 1;

		sort_and_dump_to_disk(in_memory_queue->begin() + current * block_size,
				      in_memory_queue->end());
	    }
	    delete in_memory_queue;
	    in_memory_queue = nullptr;
	}
    }

    /* Our constructor passes all of its arguments to MemoryContainer's constructor */

    template <typename... Args>
    priority_queue(Args... args):
	snetwork(&disk_ques),
	in_memory_queue(new MemoryContainer(args...)),
	head(in_memory_queue->begin()),
	tail(head),
	sorted(true)
    {
	block_size = (in_memory_queue->end() - in_memory_queue->begin()) / num_threads;

	/* Round down block_size to a multiple of eight to ensure that the blocks are byte aligned */
	while ((block_size % 8) != 0) block_size --;

	blocks_dumped_to_disk = 0;
	remaining_space = in_memory_queue->end() - in_memory_queue->begin();
    }

    ~priority_queue() {
	if (in_memory_queue) delete in_memory_queue;
    }

    void push(const T& x) {

	std::unique_lock<std::mutex> self_lock(*this);

	if (in_memory_queue == nullptr) throw "priority_queue: push attempted after retrieval started";

	*(tail ++) = x;
	remaining_space --;
	sorted = false;

	if (remaining_space < num_threads) {

	    unsigned int current = num_threads - remaining_space - 1;

	    if (current != num_threads - 1) {
		/* If there's still room to insert at the end, we unlock while we're sorting and
		 * dumping to disk, but the real reason to unlock is to let other threads into this
		 * code so they can also sort and dump to disk (it's a slow operation).
		 */
		self_lock.unlock();
		sort_and_dump_to_disk(in_memory_queue->begin() + current * block_size,
				      in_memory_queue->begin() + (current+1) * block_size);
	    } else {
		sort_and_dump_to_disk(in_memory_queue->begin() + current * block_size,
				      in_memory_queue->end());
	    }

	    /* Now we lock on a different mutex that protects a condition variable.  We never hold
	     * this lock doing anything that blocks on the primary lock - just increment
	     * blocks_dumped_to_disk and notify the thread waiting for it to reach num_threads,
	     * which is holding the primary lock.
	     */

	    std::unique_lock<std::mutex> lock(blocks_dumped_to_disk_mutex);

	    blocks_dumped_to_disk ++;
	    blocks_dumped_to_disk_cond.notify_all();

	    if (current == num_threads - 1) {
		/* There's no remaining space, we're locked, and dumps to disk have at least started
		 * for all blocks.  Make sure they're all done before we reset everything and get
		 * going again.
		 */

		while (blocks_dumped_to_disk < num_threads) {
		    blocks_dumped_to_disk_cond.wait(lock);
		}

		tail = head;
		remaining_space = in_memory_queue->end() - in_memory_queue->begin();
		blocks_dumped_to_disk = 0;
	    }
	}
    }

    bool empty(void) {
	return disk_ques.empty() ? (head == tail) : snetwork.empty();
    }

    const T front(void) {
	prepare_to_retrieve();
	if (disk_ques.empty()) {
	    return *head;
	} else {
	    return snetwork.front();
	}
    }

    T pop_front(void) {
	prepare_to_retrieve();
	if (disk_ques.empty()) {
	    return *(head++);
	} else {
	    return snetwork.pop_front();
	}
    }
};

/* The entries in the proptable
 *
 * Required field sizes for futurebase back-propagation:
 *
 *   index - figure out from num_indices
 *   dtm - figure out from futurebase preload, unless it isn't being tracked
 *   movecnt - 0 (XXX - discarded futuremove only), 1, or 2 for 8-way symmetry conversion
 *   futuremove - figure out from total_futuremoves
 *
 * Required field sizes for intra-tablebase propagation:
 *
 *   index - figure out from num_indices
 *   dtm - known from pass number, unless it isn't being tracked
 *   movecnt - always 1
 *   futuremove - unneeded
 *
 * The fields are stored as object variables, and functions are provided to marshal and demarshal an
 * entire proptable entry into whatever integer type is being used by the proptable.  encode<T> is a
 * method that takes a proptable_format and packs everything into a return value of type T.
 * proptable_entry<T> is a constructor that takes a proptable_format and a value of type T and
 * initializes the object fields appropriately.
 */

class proptable_entry {

private:
    template<typename T>
    static int value_to_dtm(proptable_format *format, T value) {
	int dtm = (value >> format->dtm_offset) & format->dtm_mask;
	if (dtm > (int) (format->dtm_mask >> 1)) dtm |= (~ (format->dtm_mask >> 1));
	return dtm;
    }

public:
    index_t index;
    int dtm;
    unsigned int movecnt;
    int futuremove;

    /* Can't initialize all our fields during construction since sorting_network creates an
     * uninitialized array of proptable_entry's.
     */
    proptable_entry() {}

    proptable_entry(index_t index, int dtm, unsigned int movecnt, int futuremove):
	index(index), dtm(dtm), movecnt(movecnt), futuremove(futuremove) {}

#if 0
    template<typename T>
    proptable_entry(proptable_format *format, T value):
	proptable_entry(value >> format->index_offset, value_to_dtm(format, value),
			((value >> format->movecnt_offset) & format->movecnt_mask) + 1,
			(value >> format->futuremove_offset) & format->futuremove_mask)
    {}
#else
    template<typename T>
    proptable_entry(proptable_format *format, T value):
	index(value >> format->index_offset), dtm(value_to_dtm(format, value)),
	movecnt(((value >> format->movecnt_offset) & format->movecnt_mask) + 1),
	futuremove((value >> format->futuremove_offset) & format->futuremove_mask)
    {}
#endif

    template<typename T>
    T encode(proptable_format *format) {
	return (index << format->index_offset)
	    | ((dtm & format->dtm_mask) << format->dtm_offset)
	    | (((movecnt - 1) & format->movecnt_mask) << format->movecnt_offset)
	    | ((futuremove & format->futuremove_mask) << format->futuremove_offset);
    }

    /* This is used when we build current_pt_entries */

    bool operator<(const proptable_entry &other) const {
	return index < other.index;
    }
};


/* Proptable - byte-aligned version
 *
 * Very simple - just construct a priority queue of a specified (integer) type and marshal/demarshal
 * proptable_entry's into that integer.
 */

template<typename T>
class typed_proptable : public priority_queue<T> {
private:
    proptable_format format;

public:

    /* priority_queue<T>'s constructor passes all of its arguments to its MemoryContainer's
     * constructor (remember?), and priority_queue<T>'s default MemoryContainer is std::vector<T>,
     * which will take a size_type and build a container with that many elements.
     */

    typed_proptable(proptable_format format, size_t size_in_bytes):
	priority_queue<T>(size_in_bytes / sizeof(T)), format(format)
    {
	if (format.bits > 8 * (int) sizeof(T)) throw "proptable format too large";
    }

    proptable_entry front() {
	return proptable_entry(&format, priority_queue<T>::front());
    }

    proptable_entry pop_front() {
	return proptable_entry(&format, priority_queue<T>::pop_front());
    }

    void push(proptable_entry &entry) {
	priority_queue<T>::push(entry.encode<T>(&format));
    }
};

/* Proptable - bit-aligned version
 *
 * proptable_iterator (defined below) dereferences into proptable_ptr, which is a pointer into the
 * in-memory table.  It's not a normal pointer because the in-memory table is bit-aligned, not
 * byte-aligned.  It contains a pointer to the table format structure, a pointer to the base of the
 * in-memory table, and an offset into the table, measured in entries, the exact size of which is
 * contained in the format structure.
 *
 * To support std::sort, proptable_iterator has to dereference into a type that is Swappable,
 * MoveConstructable and MoveAssignable (the C++11 standard's terminology).  That means that
 * proptable_ptr has to operate as an lvalue that both points into the proptable (Swappable) and
 * also can hold a temporary value (MoveConstructable and MoveAssignable).
 *
 * Both proptable_ptr and proptable_iterator contain pointers to the format, since both of them are
 * dependent on either a memory_proptable or a disk_que<memory_proptable>.  On the other hand, both
 * memory_proptable and disk_que<memory_proptable> contain actual format structures, not pointers.
 */

class proptable_iterator;
class memory_proptable;

class proptable_ptr {

    friend class proptable_iterator;
    friend class disk_que<memory_proptable>;
    friend void swap(proptable_ptr a, proptable_ptr b);

 private:
    proptable_format *format;
    uint64_t i;
    void *base;
    uint64_t value;

    /* Private constructor: friend proptable_iterator constructs proptable_ptr when dereferencing */

    proptable_ptr(proptable_format *format, void *base, uint64_t i):
	format(format), i(i), base(base) {
	    value = get_uint64_t_field(base, i * format->bits, format->bits);
	}

 public:

    operator proptable_entry() {
	int dtm = (value >> format->dtm_offset) & format->dtm_mask;
	if (dtm > (format->dtm_mask >> 1)) dtm |= (~ (format->dtm_mask >> 1));

	return proptable_entry(value >> format->index_offset, dtm,
			       ((value >> format->movecnt_offset) & format->movecnt_mask) + 1,
			       (value >> format->futuremove_offset) & format->futuremove_mask);
    }

    proptable_ptr & operator=(proptable_entry other) {
	/* Set both our local copy and the copy in the proptable */

	value = (other.index << format->index_offset)
	| ((other.dtm & format->dtm_mask) << format->dtm_offset)
	| (((other.movecnt - 1) & format->movecnt_mask) << format->movecnt_offset)
	| ((other.futuremove & format->futuremove_mask) << format->futuremove_offset);

	set_uint64_t_field(base, i * format->bits, format->bits, value);

	return *this;
    }

    /* We don't use the default copy operator, since that would change base and i. */

    proptable_ptr & operator=(proptable_ptr other) {
	value = other.value;
	set_uint64_t_field(base, i * format->bits, format->bits, value);
	return *this;
    }

    /* We want to compare index fields, but we don't want to have to extract all the fields, since
     * this function will be used a lot during sorting.  We make sure that index occupies the most
     * significant bits, making this comparision simple.
     */

    bool operator<(const proptable_ptr & other) const {
	return value < other.value;
    }

    /* This is here to allow disk_que's constructor to cast us to a (char *) and write us to disk */

    operator char *() {
	if (i % 8 != 0) throw "can't convert bit-aligned proptable_ptr to char *";
	return (char *)base + i * format->bits / 8;
    }

};

void swap(proptable_ptr a, proptable_ptr b) {
    uint64_t x = get_unsigned_int_field(a.base, a.i * a.format->bits, a.format->bits);
    set_uint64_t_field(a.base, a.i * a.format->bits, a.format->bits,
		       get_uint64_t_field(b.base, b.i * b.format->bits, b.format->bits));
    set_uint64_t_field(b.base, b.i * b.format->bits, b.format->bits, x);
}

class proptable_iterator : public std::iterator<std::random_access_iterator_tag, proptable_ptr, uint64_t> {

    friend class memory_proptable;
    friend class disk_que<memory_proptable>;

 private:
    proptable_format *format;
    uint64_t i;
    void *ptr;

    /* Private constructor ensures that only friends can create a proptable_iterator */

    proptable_iterator(proptable_format *format, void *ptr, uint64_t i) : format(format), i(i), ptr(ptr) {}

 public:

    proptable_ptr operator*() const {
	return proptable_ptr(format, ptr, i);
    }

    const proptable_iterator operator++(int zero) {
	proptable_iterator retval(*this);
	i ++;
	return retval;
    }

    const proptable_iterator & operator++() {
	i ++;
	return *this;
    }

    const proptable_iterator operator--(int zero) {
	proptable_iterator retval(*this);
	i --;
	return retval;
    }

    const proptable_iterator & operator--() {
	i --;
	return *this;
    }

    const proptable_iterator operator+(int val) {
	proptable_iterator retval(*this);
	retval.i += val;
	return retval;
    }

    const proptable_iterator operator-(int val) {
	proptable_iterator retval(*this);
	retval.i -= val;
	return retval;
    }

    uint64_t operator-(const proptable_iterator & other) {
	return i - other.i;
    }

    bool operator==(const class proptable_iterator & other) {
	return i == other.i;
    }

    bool operator!=(const class proptable_iterator & other) {
	return i != other.i;
    }

    bool operator<(const class proptable_iterator & other) {
	return i < other.i;
    }

    // this is for the loop comparision in disk_que
    bool operator<=(const class proptable_iterator & other) const {
	return i <= other.i;
    }
};

class memory_proptable {

 private:
    proptable_format format;
    size_t size_in_entries;
    char *data;

 public:
    typedef proptable_entry value_type;
    typedef proptable_iterator iterator;

 memory_proptable(proptable_format format, size_t size_in_bytes):
    format(format), size_in_entries(size_in_bytes / format.bits * 8), data(new char[size_in_bytes])
	{
	    /* We use a uint64_t to swap proptable entries */
	    if (format.bits > 64) throw "proptable format too large";
	}

    ~memory_proptable() {
	delete[] data;
    }

    class proptable_iterator begin() {
	return proptable_iterator(&format, data, 0);
    }

    class proptable_iterator end() {
	return proptable_iterator(&format, data, size_in_entries);
    }
};

/* We don't use the generic disk_que template defined above, because it can't handle bit-aligned
 * tables.  Instead, we specialize a disk_que that dumps a bit-aligned table.
 */

template <>
struct disk_que<memory_proptable> {

    typedef proptable_entry value_type;

    static const int queue_size = 256;	// size of in-memory queue; must be a multiple of 8

    int size;
    int next;

    temporary_file * file;
    std::istream * is;

    char *buffer;
    proptable_format format;

    disk_que(proptable_iterator head, proptable_iterator tail): size(tail - head), next(0), format(*(head.format)) {

	size_t bits = size * format.bits;
	size_t bytes = (bits + 7)/8;

	file = new temporary_file("proptableXXXXXX", compress_proptables);

	std::ostream * os = file->ostream();
	os->write(*head, bytes);
	delete os;

	is = file->istream();

	// this will create a buffer with room for queue_size values
	buffer = new char[queue_size * format.bits / 8];
    }

    ~disk_que() {
	delete is;
	delete file;
	delete[] buffer;
    }

    bool empty(void) {
	return (next == size);
    }

    proptable_entry pop_front(void) {
	if (empty()) throw "read past end of disk_que";
	if (next % queue_size == 0) {
	    is->read(buffer, queue_size * format.bits / 8);
	}
	proptable_ptr retval(&format, buffer, next % queue_size);
	next ++;

	return (proptable_entry) retval;
    }
};

/* Finally, the actual priority queue(s) */

// The bit-aligned version.  Significantly slower.
//typedef priority_queue<class proptable_entry, class memory_proptable> proptable;

// Byte-aligned versions.  No appreciable slowdown in using 64-bit version on a 32-bit problem.
//typedef typed_proptable<uint32_t> proptable;
typedef typed_proptable<uint64_t> proptable;

proptable * input_proptable;
proptable * output_proptable;

futurevector_t initialize_tablebase_entry(tablebase_t *tb, index_t index);
void finalize_futuremove(tablebase_t *tb, index_t index, futurevector_t futurevector);

/* proptable_pass()
 *
 * Commit an old set of proptables into the entries array while writing a new set.
 */

std::atomic<index_t> proptable_shared_index;

void proptable_pass_thread(int target_dtm)
{
    index_t index;
    std::deque<class proptable_entry> current_pt_entries;

    while (1) {

	futurevector_t futurevector = 0;

	current_pt_entries.clear();

	/* Lock the input proptable, advance the shared index, retrieve everything
	 * from the proptable that matches the new index, then unlock
	 */

	{
	    std::lock_guard<std::mutex> _(*input_proptable);

	    index = (proptable_shared_index ++);

	    if (index >= current_tb->num_indices) break;

	    if (! input_proptable->empty()) {

		if (input_proptable->front().index < index) {
		    fatal("Out-of-order entries in proptable\n");
		}

		while (! input_proptable->empty() && input_proptable->front().index == index) {
		    current_pt_entries.push_back(input_proptable->pop_front());
		}
	    }
	}

	if (target_dtm == 0) {
	    futurevector = initialize_tablebase_entry(current_tb, index);
	}

	for (auto pt_entry = current_pt_entries.begin(); pt_entry != current_pt_entries.end(); pt_entry ++) {

#ifdef DEBUG_MOVE
	    if (index == DEBUG_MOVE)
		info("Commiting proptable entry: index %" PRIindex ", dtm %d, movecnt %u, futuremove %d\n",
		     pt_entry->index, pt_entry->dtm, pt_entry->movecnt, pt_entry->futuremove);
#endif

	    if (target_dtm != 0) {

		/* Intra-table case: always update */

		finalize_update(pt_entry->index, target_dtm, 1, 0);

	    } else if (FUTUREVECTOR(pt_entry->futuremove) & futurevector) {

		/* Futurebase case: only update if move is possible and hasn't been handled yet
		 *
		 * Double consideration of a futuremove can happen for symmetric tablebases.  In
		 * this case, two different positions in the futurebase (or maybe just two different
		 * reflections of the same position) can indicate a result for this entry.  Of
		 * course, in this case the result should be the same.
		 *
		 * On the other hand, if we had two different tablebases indicating different
		 * results for the same futuremove, that should trigger a warning.  We could add
		 * that capability to the proptable code without too much trouble, but in the
		 * non-proptable case, we're just keeping a bit vector in memory to make sure all
		 * the futuremoves have been handled in some way and we don't have enough
		 * information to check all of that.  Right now, we quietly ignore it.
		 *
		 * The movecnt field is only a single bit, and it isn't stored correctly if DTM is
		 * zero, in which case movecnt is also zero.  Examine the code in
		 * propagate_index_from_futurebase(), which is where all of these entries are
		 * generated in the intra-table case, and notice that dtm=0 implies movecnt=0.
		 */

		if (pt_entry->dtm != 0) {
		    finalize_update(pt_entry->index, pt_entry->dtm, pt_entry->movecnt, pt_entry->futuremove);
		} else {
		    finalize_update(pt_entry->index, 0, 0, pt_entry->futuremove);
		}

		futurevector &= ~FUTUREVECTOR(pt_entry->futuremove);

	    }

	}

	/* We've committed everything for this index that was in the input proptable.  Now either
	 * check for back-propagation and maybe generate some updates for the output proptable
	 * (intra-table case) or check to make sure that we've handled all the futuremoves that we
	 * needed to, and check for conceded futuremoves, too, all in a subroutine.
	 */

	if (target_dtm != 0) {

	    back_propagate_index(index, target_dtm);

	} else {

	    /* Don't track futuremoves for illegal (DTM 1) positions */
	    if (entriesTable[index].get_DTM() != 1) {
		finalize_futuremove(current_tb, index, futurevector);
	    }

	    /* XXX why not back_propagate_index(index, -1) now and save a pass? */
	}

    }
}

void proptable_pass(int target_dtm)
{
    std::thread t[num_threads];
    unsigned int thread;

    /* Proptable for intra-tablebase propagation only needs to record the index, since the dtm is
     * known from the pass number, the movecnt is always one, and we're done tracking futuremoves.
     */

    proptable_format format(current_tb->num_indices, 0, 0, 0, 0);

    /* Swap proptables.  Our priority queue implementation is designed to do all the insertions
     * first, then all the retrievals, and prepare_to_retrieve() can free a lot of memory.
     */

    input_proptable = output_proptable;
    if (input_proptable) input_proptable->prepare_to_retrieve();

    /* XXX std::bad_alloc is a real possibility here.  Please do something better than dying.
     */

    try {
	output_proptable = new proptable(format, proptable_MBs << 20);
    } catch (std::exception &ex) {
	throw nested_exception("Constructing output proptable", ex);
    }

    proptable_shared_index = 0;

    entriesTable->set_threads(num_threads);

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread] = std::thread(proptable_pass_thread, target_dtm);
    }

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread].join();
    }

    entriesTable->set_threads(1);

    delete input_proptable;
}

/* reconstruct_proptable() is hardly ever used.  I put it in here because I had a kqqkqq calculation
 * that died due to a memory leak and I wanted to restart it.
 */

void reconstruct_proptable_thread(int target_dtm)
{
    while (1) {

	index_t index = (proptable_shared_index ++);

	if (index >= current_tb->num_indices) break;

	back_propagate_index(index, target_dtm);
    }
}

void reconstruct_proptable(int target_dtm)
{
    std::thread t[num_threads];
    unsigned int thread;

    proptable_format format(current_tb->num_indices, 0, 0, 0, 0);

    output_proptable = new proptable(format, proptable_MBs << 20);

    proptable_shared_index = 0;

    entriesTable->set_threads(num_threads);

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread] = std::thread(proptable_pass_thread, target_dtm);
    }

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread].join();
    }

    entriesTable->set_threads(1);
}

void insert_new_propentry(index_t index, int dtm, unsigned int movecnt, int futuremove)
{
    class proptable_entry pt_entry;

    pt_entry.index = index;
    pt_entry.dtm = dtm;
    pt_entry.movecnt = movecnt;
    pt_entry.futuremove = futuremove;

    output_proptable->push(pt_entry);

    /* fprintf(stderr, "Size of proptable: %llu\n", output_proptable->size()); */
}


/* If we're running multi-threaded, then there is a possibility that 1) two different positions will
 * try to backprop into the same position (if we're not using proptables), or that 2) two different
 * threads will try to retrieve from the proptable at the same time (if we're using proptables).
 *
 * The first case is handled by a locking sequence on individual entries in finalize_update(); the
 * second case is handled by a locking sequence on the priority_queue in proptable_pass_thread().
 */

void commit_update(index_t index, short dtm, short movecnt, int futuremove)
{

#ifdef DEBUG_MOVE
    if (index == DEBUG_MOVE)
	info("commit_update; index=%" PRIindex "; dtm=%d; movecnt=%d; futuremove=%d\n",
	     index, dtm, movecnt, futuremove);
#endif

    backproped_moves_this_pass ++;

    if (!using_proptables) {

	if (futuremove != NO_FUTUREMOVE) {

	    /* Futuremove - check off bits in an array that got filled in when we initialized
	     *
	     * Do nothing if the bit is clear, either because we were never to process this
	     * futuremove at all (this is how a suicide analysis rejects non-capture futuremoves
	     * from a position where captures are possible), or because a previous pass through this
	     * code has already processed it.  We can't tell the difference at this point, and
	     * probably need to use proptables for more accurate checking.
	     *
	     * This has to be atomically, because there will be other indices in this bit vector.
	     */

	    long long bit_offset = ((long long)index * current_tb->futurevector_bits);

	    if (! test_and_set_bit_field(current_tb->futurevectors, bit_offset + futuremove, 0)) {
		info("commit_update; futuremove processed; index=%" PRIindex "; dtm=%d; movecnt=%d; futuremove=%d\n",
		     index, dtm, movecnt, futuremove);
		return;
	    }

	}

	finalize_update(index, dtm, movecnt, futuremove);

    } else {

	insert_new_propentry(index, dtm, movecnt, futuremove);

    }

}


/* target_dtm 0 is the initialization / futurebase back prop pass */

int propagation_pass(int target_dtm)
{
    positions_finalized_this_pass = 0;
    backproped_moves_this_pass = 0;

    if (tracking_dtm) {
	if (target_dtm > 0) {
	    entriesTable->verify_DTM_field_size(target_dtm+1);
	} else {
	    entriesTable->verify_DTM_field_size(target_dtm-1);
	}
    }

    if (pass_type[total_passes] == nullptr) pass_type[total_passes] = "intratable";
    pass_target_dtms[total_passes] = target_dtm;

    if (using_proptables) {
	proptable_pass(target_dtm);
    } else {
	non_proptable_pass(target_dtm);
    }

    positions_finalized[total_passes] = positions_finalized_this_pass;
    backproped_moves[total_passes] = backproped_moves_this_pass;

    total_backproped_moves += backproped_moves[total_passes];

    if (positions_finalized_this_pass > 0) {
	if (target_dtm > max_dtm) max_dtm = target_dtm;
	if (target_dtm < min_dtm) min_dtm = target_dtm;
    }

    finalize_pass_statistics();
    if (target_dtm != 0) {
	info("Pass %3d complete; %d positions finalized\n", target_dtm, (int) positions_finalized_this_pass);
    }

    total_passes ++;
    if (total_passes == max_passes) expand_per_pass_statistics();

    return positions_finalized_this_pass;
}

/***** FUTUREBASES *****/

/* Subroutines to backpropagate an individual index, or an individual local position (these are the
 * "mini" routines), or a set of local positions that differ only in the en passant square.
 *
 * The idea behind the en passant handling is this.  If we back propagate a position with the en
 * passant square set, then that's the only position we process.  If we back prop a position without
 * the en passant square set, then we process not only that position, but also any positions just
 * like it that have en passant set.  The idea being that we set en passant if we actually need it,
 * and we clear it if we don't need it, so if it's clear we need to process positions where it was
 * set, but we didn't use it.
 */

void propagate_index_from_futurebase(tablebase_t *tb, tablebase_t *futurebase, index_t future_index,
				     short movecnt, int futuremove, index_t current_index)
{
    if (futuremove == -1) {
	global_position_t global;

	index_to_global_position(tb, current_index, &global);
	fatal("Futuremove never assigned: %s\n", global_position_to_FEN(&global));

	return;
    }

#ifdef DEBUG_FUTUREMOVE
    if (future_index == DEBUG_FUTUREMOVE) {
	global_position_t global1, global2;

	index_to_global_position(tb, current_index, &global1);
	index_to_global_position(futurebase, future_index, &global2);
	info("propagate_index_from_futurebase; %" PRIindex " %s from %s %" PRIindex " %s\n",
	     current_index, global_position_to_FEN(&global1), futurebase->filename.c_str(), future_index, global_position_to_FEN(&global2));
    }
#endif

#ifdef DEBUG_MOVE
    if (current_index == DEBUG_MOVE) {
	global_position_t global1, global2;

	index_to_global_position(tb, current_index, &global1);
	index_to_global_position(futurebase, future_index, &global1);
	info("propagate_index_from_futurebase; %" PRIindex " %s from %s %" PRIindex " %s\n",
	     current_index, global_position_to_FEN(&global1), futurebase->filename.c_str(), future_index, global_position_to_FEN(&global2));
    }
#endif

    if (futurebase->format.dtm_bits > 0) {

	int dtm = futurebase->get_DTM(future_index);

	if (dtm > 0) {
	    commit_update(current_index, -dtm, movecnt, futuremove);
	} else if (dtm < 0) {
	    commit_update(current_index, -dtm+1, movecnt, futuremove);
	} else {
	    /* We insert even if dtm is zero because we have to track futuremoves,
	     * but we use movecnt=0 since this is a draw, which is different
	     * from a discard.
	     */
	    commit_update(current_index, 0, 0, futuremove);
	}

    } else if (futurebase->format.basic_offset != -1) {

	int basic = futurebase->get_basic(future_index);

	if (basic == 1) {
	    commit_update(current_index, -2, movecnt, futuremove);
	} else if (basic == 2) {
	    commit_update(current_index, 2, movecnt, futuremove);
	} else {
	    commit_update(current_index, 0, 0, futuremove);
	}

    } else {

	bool flag = futurebase->get_flag(future_index);
	int stm = index_to_side_to_move(futurebase, future_index);

	/* What happens if we're back propagating a flag from a color-inverted futurebase?
	 *
	 * Well, first of all, a "white-wins" flag in an inverted futurebase becomes a "black-wins"
	 * flag here, which is basically a "NOT white-draws" flag, so we have to be careful to
	 * backprop from draw flags to win flags and from win flags to draw flags if the colors have
	 * been inverted.  Other than that, since the side to move we just fetched is in the
	 * futurebase, the white/black sense of the flag matches with it, so we don't need to invert
	 * anything to figure out if this is a PTM win or a PNTM win.
	 */

	/* I use twos here because there's a lot of stuff that gets cut out for the special case of 1 */

	if ((flag && (stm == WHITE)) || (!flag && (stm == BLACK))) {
	    commit_update(current_index, -2, movecnt, futuremove);
	} else {
	    commit_update(current_index, 2, movecnt, futuremove);
	}

    }
}

void propagate_minilocal_position_from_futurebase(tablebase_t *tb, tablebase_t *futurebase, index_t future_index,
						  int futuremove, local_position_t *current_position)
{
    index_t current_index;

    /* Look up the position in the current tablebase... */

    current_index = local_position_to_index(tb, current_position);

    if (current_index == INVALID_INDEX) {
	return;
    }

    /* local_position_to_index() updated the position structure's multiplicity, so we know it's
     * correct.  It actually should be a little more complex than this, but since we're only dealing
     * with 8-way symmetry where multiplicity is either 1 or 2, this should do.  If we're
     * backproping from a single multiplicity position into one with double multiplicity, then this
     * function will get called twice on the same index, because that index will get generated
     * twice during back prop from the single future position, but since we're using the futuremove
     * number to toss out additional function calls, we can safely just use the multiplicity here
     * without worrying about it getting called again.
     */

    propagate_index_from_futurebase(tb, futurebase, future_index, current_position->multiplicity,
				    futuremove, current_index);
}

void propagate_local_position_from_futurebase(tablebase_t *tb, tablebase_t *futurebase, index_t future_index,
					      int futuremove, local_position_t *position)
{
    int piece;

    /* We may need to consider a bunch of additional positions here that are identical to the base
     * position except that a single one of the pawns on the fourth or fifth ranks was capturable en
     * passant.
     * 
     * We key off the en_passant flag in the position that was passed in.  If it's set, then we're
     * back propagating a position that requires en passant, so we just do it.  Otherwise, we're
     * back propagating a position that doesn't require en passant, so we check for additional
     * en passant positions.
     */

    propagate_minilocal_position_from_futurebase(tb, futurebase, future_index, futuremove, position);

    if (position->en_passant_square == ILLEGAL_POSITION) {

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if (tb->pieces[piece].color == position->side_to_move) continue;
	    if (tb->pieces[piece].piece_type != PAWN) continue;

	    /* I took care in the calling routines to update board_vector specifically so we can
	     * check for en passant legality here.
	     */

	    if ((tb->pieces[piece].color == WHITE)
		&& (ROW(position->piece_position[piece]) == 3)
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] - 8))
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] - 16))) {
		position->set_en_passant_square(position->piece_position[piece] - 8);
		propagate_minilocal_position_from_futurebase(tb, futurebase, future_index, futuremove, position);
	    }

	    if ((tb->pieces[piece].color == BLACK)
		&& (ROW(position->piece_position[piece]) == 4)
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] + 8))
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] + 16))) {
		position->set_en_passant_square(position->piece_position[piece] + 8);
		propagate_minilocal_position_from_futurebase(tb, futurebase, future_index, futuremove, position);
	    }

	    position->clear_en_passant_square();
	}
    }
}

void propagate_mini_normalized_position_from_futurebase(tablebase_t *tb, tablebase_t *futurebase, index_t future_index,
						  int futuremove, local_position_t *current_position)
{
    index_t current_index;

    /* Look up the position in the current tablebase... */

    current_index = normalized_position_to_index(tb, current_position);

    if (current_index == INVALID_INDEX) {
	return;
    }

    /* local_position_to_index() updated the position structure's multiplicity, so we know it's
     * correct.  It actually should be a little more complex than this, but since we're only dealing
     * with 8-way symmetry where multiplicity is either 1 or 2, this should do.  If we're
     * backproping from a single multiplicity position into one with double multiplicity, then this
     * function will get called twice on the same index, because that index will get generated
     * twice during back prop from the single future position, but since we're using the futuremove
     * number to toss out additional function calls, we can safely just use the multiplicity here
     * without worrying about it getting called again.
     */

    propagate_index_from_futurebase(tb, futurebase, future_index, current_position->multiplicity,
				    futuremove, current_index);
}

void propagate_normalized_position_from_futurebase(tablebase_t *tb, tablebase_t *futurebase, index_t future_index,
					      int futuremove, local_position_t *position)
{
    int piece;

    /* We may need to consider a bunch of additional positions here that are identical to the base
     * position except that a single one of the pawns on the fourth or fifth ranks was capturable en
     * passant.
     * 
     * We key off the en_passant flag in the position that was passed in.  If it's set, then we're
     * back propagating a position that requires en passant, so we just do it.  Otherwise, we're
     * back propagating a position that doesn't require en passant, so we check for additional
     * en passant positions.
     */

    propagate_mini_normalized_position_from_futurebase(tb, futurebase, future_index, futuremove, position);

    if (position->en_passant_square == ILLEGAL_POSITION) {

	for (piece = 0; piece < tb->num_pieces; piece ++) {

	    if (tb->pieces[piece].color == position->side_to_move) continue;
	    if (tb->pieces[piece].piece_type != PAWN) continue;

	    /* I took care in normalize_position() to update board_vector specifically so we can
	     * check for en passant legality here.
	     */

	    if ((tb->pieces[piece].color == WHITE)
		&& (ROW(position->piece_position[piece]) == 3)
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] - 8))
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] - 16))) {
		position->set_en_passant_square(position->piece_position[piece] - 8);
		propagate_mini_normalized_position_from_futurebase(tb, futurebase, future_index, futuremove, position);
	    }

	    if ((tb->pieces[piece].color == BLACK)
		&& (ROW(position->piece_position[piece]) == 4)
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] + 8))
		&& !(position->board_vector & BITVECTOR(position->piece_position[piece] + 16))) {
		position->set_en_passant_square(position->piece_position[piece] + 8);
		propagate_mini_normalized_position_from_futurebase(tb, futurebase, future_index, futuremove, position);
	    }

	    position->clear_en_passant_square();
	}
    }
}

/* Reflections.
 *
 * If the futurebase has greater symmetry than the tablebase under construction, then we have to
 * apply a series of reflections to each futurebase position in order to get all the corresponding
 * positions in the current tablebase.  This utility function computes them.
 *
 * If we're back propagating from a futurebase with greater symmetry, then a single futurebase index
 * will correspond to several positions in the current tablebase.  We'll need to apply some
 * reflections to get those additional positions, so compute here how many of them we'll need.  It's
 * a fairly easy calculation, since our symmetry options are currently limited to 1/2/4/8, so a
 * simple ratio suffices, except if both tablebases have symmetry 8, in which case the more complex
 * effects of diagonal symmetry require a double conversion no matter what.
 */


int compute_reflections(tablebase_t *tb, tablebase_t *futurebase, int *reflections)
{
    int max_reflection;

    max_reflection = futurebase->symmetry / tb->symmetry;
    if ((futurebase->symmetry == 8) && (tb->symmetry == 8)) max_reflection = 2;

    reflections[0] = REFLECTION_NONE;
    if (futurebase->symmetry == 8) reflections[1] = REFLECTION_DIAGONAL;
    if (futurebase->symmetry == 4) reflections[1] = REFLECTION_VERTICAL;
    if (futurebase->symmetry == 2) reflections[1] = REFLECTION_HORIZONTAL;
    if (max_reflection >= 4) {
	if (futurebase->symmetry == 8) {
	    /* This is either the 8 -> 2 or 8 -> 1 cases */
	    reflections[2] = reflections[0] | REFLECTION_VERTICAL;
	    reflections[3] = reflections[1] | REFLECTION_VERTICAL;
	} else {
	    /* This is the 4 -> 1 case */
	    reflections[2] = reflections[0] | REFLECTION_HORIZONTAL;
	    reflections[3] = reflections[1] | REFLECTION_HORIZONTAL;
	}
    }
    if (max_reflection == 8) {
	/* The 8 -> 1 case */
	reflections[4] = reflections[0] | REFLECTION_HORIZONTAL;
	reflections[5] = reflections[1] | REFLECTION_HORIZONTAL;
	reflections[6] = reflections[2] | REFLECTION_HORIZONTAL;
	reflections[7] = reflections[3] | REFLECTION_HORIZONTAL;
    }

    if (! futurebase->encode_stm) {
	for (int r = 0; r < max_reflection; r ++) {
	    reflections[max_reflection + r] = reflections[r] | REFLECTION_COLOR;
	}
	max_reflection *= 2;
    }

    return max_reflection;
}


/* Some variables common to many or all of the futurebase backprop routines */

int max_reflection;
int reflections[16];

int promotion_color;
int first_back_rank_square;
int last_back_rank_square;
int promotion_move;

tablebase_t * futurebase;

std::atomic<index_t> next_future_index;

/* The four futurebase back-propagation functions
 *
 * These functions handle threading differently from the intra-table case, where we split the
 * tablebase up into N sections for the N threads and let each thread tear into its own section.
 * This time, we're reading the futurebase from disk, and it might be biiiig, so we want to proceed
 * through it sequentially.  Each thread reads a portion of the futurebase, calls the appropriate
 * one of these functions for every index in that portion, and loops until everything is done.
 *
 * reflections[] is a global variable that gets computed for every futurebase.  See comments on
 * compute_reflections().
 *
 * For each possible reflection of each possible futuremove, we attempt to translate the futurebase
 * pieces into corresponding local tablebase pieces.  Actually, we did this for the entire
 * futurebase when we loaded it, and those piece assignments should never change within a single
 * futurebase, so all we really do is blunder check.
 */

/* NORMAL PAWN PROMOTION
 *
 * We can easily identify what we're promoting into, since there's a single type and color of piece
 * in the futurebase of which there are one more than in the current tablebase.  Assume, without
 * loss of generality, that it's a queen.  There are also pawns in the current tablebase.  To a
 * first approximation, we have to consider all pairs of local pawns and foreign queens.
 *
 * Actually, we can limit things further.  Let's just consider each foreign queen in turn.  The only
 * possible local pawn that could promote into it is located one square directly behind it.  So in a
 * given futurebase position, we only need to consider all foreign queens, with the local position
 * that leads to it uniquely determined.
 *
 * Furthermore, in a given position, each foreign piece will map into a local semilegal group.  One
 * of those local semilegal groups will have one more piece (the extra piece) map into it; all of
 * the others must have the same number of pieces map into them as they contain.  Once a local
 * position has been setup for back propagation, that special semilegal group will be fully
 * populated and will contain the promotion square, too.  We just cycle the promotion square among
 * all of the n pieces in this group, creating n+1 total positions.  None of pieces that map into
 * other semilegal groups could be the promotion piece, because that would create an imbalance among
 * the semilegal groups - one would have one piece too many, another would have one piece too few.
 *
 * Prior to 1.779, we cycled among semilegal groups in the FUTUREBASE, but that was a bug.
 * Futurebase semilegal groups don't matter, only the local semilegal group matters.
 */

void propagate_moves_from_promotion_futurebase(index_t future_index, int reflection)
{
    local_position_t foreign_position(futurebase);
    local_position_t position(current_tb);
    translation_result translation;
    int true_pawn;

    /* Take the position from the futurebase and translate it into a local position for the current
     * tablebase.  If the futurebase index was illegal, the function will return -1.  Otherwise,
     * there should be one piece missing from the local position (the pawn that promoted) and one
     * piece extra (what it promoted into).  There can be no pieces on restricted squares.
     */

    if (! index_to_local_position(futurebase, future_index, reflections[reflection],
				  &foreign_position)) return;

    translation = translate_foreign_position_to_local_position(futurebase, &foreign_position,
								     current_tb, &position,
								     futurebase->invert_colors);

    if (translation != invalid_translation) {

	if ((translation.extra_piece == NONE) || (translation.missing_piece1 == NONE)
	    || (translation.missing_piece2 != NONE) || (translation.restricted_piece != NONE)) return;

	uint8_t pawn = translation.missing_piece1;

	/* Since the last move had to have been a promotion move, there is absolutely no way we
	 * could have en passant capturable pawns in the futurebase position.
	 */

	if (position.en_passant_square != ILLEGAL_POSITION) return;

	/* Whatever color the promoted piece is, after the promotion it must be the other side to
	 * move.
	 */

	if (position.side_to_move == promotion_color) return;

	/* We're going to back step a half move now */

	position.flip_side_to_move();

	/* We need an extra loop in here to handle futurebases with multiple identical pieces.
	 * Let's say we're back propagating from a Q+Q endgame into a Q+P endgame.  If we've got a
	 * futurebase position with both queens on the back rank, then we have to consider the
	 * possibility that the pawn could promote into either of them.
	 */

	int promotion_sq = foreign_position.piece_position[translation.extra_piece];

	if (futurebase->invert_colors)
	    promotion_sq = rowcol2square(7 - ROW(promotion_sq), COL(promotion_sq));

	int local_piece = futurebase->pieces[translation.extra_piece].matching_local_semilegal_group[promotion_sq];

	while (true) {

	    /* The extra piece has to be on the back rank.
	     *
	     * I used to (pre 1.547) 'break' here if it wasn't, figuring that since identical pieces
	     * are sorted into ascending square numbers, if we'd backed up to an extra piece that
	     * wasn't on the back rank, then there couldn't be any more identical pieces on the back
	     * rank.
	     *
	     * But Laurent Bartholdi exposed that as a bug.  If black is promoting, then we start
	     * with the piece with the highest square number - that isn't on the back rank - and
	     * have to back up to find one that is.
	     *
	     * We could invert the whole piece processing order to make the original optimization
	     * work, but then when you consider what can happen if there are movement restrictions
	     * in the futurebase, maybe the pieces aren't even going to show up in the right order.
	     * Better to ditch that whole idea, I think.
	     */

	    if ((promotion_sq >= first_back_rank_square) && (promotion_sq <= last_back_rank_square)) {

		/* There has to be an empty square right behind where the pawn came from, and it has
		 * to be at least semilegal for the pawn.
		 */

		if (!(position.board_vector & BITVECTOR(promotion_sq - promotion_move))
		    && (current_tb->pieces[pawn].semilegal_squares & BITVECTOR(promotion_sq - promotion_move))) {

		    local_position_t new_position = position;

		    /* Put the missing pawn on the seventh (or second). */

		    new_position.place_piece(pawn, promotion_sq - promotion_move);

		    /* Normalize the position, and back prop it. */

		    normalize_position(current_tb, &new_position);

		    true_pawn = new_position.permuted_piece[pawn];

		    propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
								  promotions[true_pawn][futurebase->promotion],
								  &new_position);
		}

	    }

	    /* If the extra piece mapped into a non-empty semilegal group, then swap it with
	     * the next piece in the group and try again.
	     */

	    if (local_piece == -1) return;

	    int new_promotion_sq = position.piece_position[local_piece];

	    position.move_piece(local_piece, promotion_sq);
	    promotion_sq = new_promotion_sq;

	    local_piece = current_tb->pieces[local_piece].next_piece_in_semilegal_group;
	}
    }
}

void propagate_moves_from_promotion_capture_futurebase(index_t future_index, int reflection)
{
    local_position_t foreign_position(futurebase);
    local_position_t position(current_tb);
    translation_result translation;
    int true_captured_piece;
    int true_pawn;

    /* Take the position from the futurebase and translate it into a local position for the current
     * tablebase.  If the futurebase index was illegal, the function will return -1.  Otherwise,
     * there should be two pieces missing from the local position (the pawn that promoted and the
     * piece it captured) and one piece extra (what it promoted into).  There can be no pieces on
     * restricted squares.
     */

    if (! index_to_local_position(futurebase, future_index, reflections[reflection],
				  &foreign_position)) return;

    translation = translate_foreign_position_to_local_position(futurebase, &foreign_position,
							       current_tb, &position,
							       futurebase->invert_colors);

    if (translation != invalid_translation) {

	if ((translation.extra_piece == NONE) || (translation.missing_piece1 == NONE)
	    || (translation.missing_piece2 == NONE) || (translation.restricted_piece != NONE)) return;

	/* Since the last move had to have been a promotion move, there is absolutely no way
	 * we could have en passant capturable pawns in the futurebase position.
	 */

	if (position.en_passant_square != ILLEGAL_POSITION) return;

	/* Whatever color the promoted piece is, after the promotion it must be the other
	 * side to move.
	 */

	if (position.side_to_move == promotion_color) return;

	/* We're going to back step a half move now */

	position.flip_side_to_move();

	/* We need an extra loop in here to handle futurebases with multiple identical pieces.
	 * Let's say we're back propagating from a Q+Q endgame into a Q+P endgame.  If we've got a
	 * futurebase position with both queens on the back rank, then we have to consider the
	 * possibility that the pawn could promote into either of them.
	 */

	int promotion_sq = foreign_position.piece_position[translation.extra_piece];

	if (futurebase->invert_colors)
	    promotion_sq = rowcol2square(7 - ROW(promotion_sq), COL(promotion_sq));

	int local_piece = futurebase->pieces[translation.extra_piece].matching_local_semilegal_group[promotion_sq];

	while (true) {

	    /* The extra piece has to be on the back rank.
	     *
	     * I used to (pre 1.547) 'break' here if it wasn't, figuring that since identical pieces
	     * are sorted into ascending square numbers, if we'd backed up to an extra piece that
	     * wasn't on the back rank, then there couldn't be any more identical pieces on the back
	     * rank.
	     *
	     * But Laurent Bartholdi exposed that as a bug.  If black is promoting, then we start
	     * with the piece with the highest square number - that isn't on the back rank - and
	     * have to back up to find one that is.
	     *
	     * We could invert the whole piece processing order to make the original optimization
	     * work, but then when you consider what can happen if there are movement restrictions
	     * in the futurebase, maybe the pieces aren't even going to show up in the right order.
	     * Better to ditch that whole idea, I think.
	     */

	    if ((promotion_sq >= first_back_rank_square) && (promotion_sq <= last_back_rank_square)) {

		/* Consider first a capture to the left (white's left).  There has to be an empty
		 * square where the pawn came from, and it has to be at least semilegal.
		 */

		if ((COL(promotion_sq) != 0)
		    && !(position.board_vector & BITVECTOR(promotion_sq - promotion_move - 1))
		    && (current_tb->pieces[translation.missing_piece1].semilegal_squares & BITVECTOR(promotion_sq - promotion_move - 1))) {

		    local_position_t new_position = position;

		    /* Put the piece that was captured onto the board on the promotion square. */

		    new_position.place_piece(translation.missing_piece2, promotion_sq);

		    /* Put the missing pawn on the seventh (or second). */

		    new_position.place_piece(translation.missing_piece1, promotion_sq - promotion_move - 1);

		    /* Back propagate the resulting position */

		    normalize_position(current_tb, &new_position);

		    true_captured_piece = new_position.permuted_piece[translation.missing_piece2];
		    true_pawn = new_position.permuted_piece[translation.missing_piece1];

		    /* This function also back props any similar positions with one of the pawns
		     * from the side that didn't promote in an en passant state.
		     */

		    propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
								  promotion_captures[true_pawn][true_captured_piece][futurebase->promotion],
								  &new_position);

		}

		/* Now consider a capture to the right (white's right).  Again, there has to be an
		 * empty square where the pawn came from, and it has to be semilegal.
		 */

		if ((COL(promotion_sq) != 7)
		    && !(position.board_vector & BITVECTOR(promotion_sq - promotion_move + 1))
		    && (current_tb->pieces[translation.missing_piece1].semilegal_squares & BITVECTOR(promotion_sq - promotion_move + 1))) {

		    local_position_t new_position = position;

		    /* Put the piece that was captured onto the board on the promotion square. */

		    new_position.place_piece(translation.missing_piece2, promotion_sq);

		    /* Put the missing pawn on the seventh (or second). */

		    new_position.place_piece(translation.missing_piece1, promotion_sq - promotion_move + 1);

		    normalize_position(current_tb, &new_position);

		    true_captured_piece = new_position.permuted_piece[translation.missing_piece2];
		    true_pawn = new_position.permuted_piece[translation.missing_piece1];

		    propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
								  promotion_captures[true_pawn][true_captured_piece][futurebase->promotion],
								  &new_position);

		}

	    }

	    /* If the extra piece mapped into a non-empty semilegal group, then swap it with the
	     * next piece in the group and try again.
	     */

	    if (local_piece == -1) return;

	    int new_promotion_sq = position.piece_position[local_piece];

	    position.move_piece(local_piece, promotion_sq);
	    promotion_sq = new_promotion_sq;

	    local_piece = current_tb->pieces[local_piece].next_piece_in_semilegal_group;

	}
    }
}

/* Propagate moves from a futurebase that resulted from capturing one of the pieces in the current
 * tablebase.
 *
 * I'm thinking of changing that "invert_colors_of_futurebase" flag to be a subroutine that gets
 * passed in.  It could be a pointer to invert_colors_of_global_position to do what it does now.  Or
 * it could be a "reflect board around vertical axis" to move a d4 pawn to e4.  Also see my comments
 * on invert_colors_of_global position.
 */

void consider_possible_captures(const index_t future_index, const local_position_t *position,
				const int capturing_piece, const int captured_piece)
{
    int dir;
    struct movement *movementptr;
    int true_captured_piece;
    int true_capturing_piece;

    /* We only want to consider pieces of the side which captured... */

    if (current_tb->pieces[capturing_piece].color == current_tb->pieces[captured_piece].color) return;

    /* When we finally convert the position to an index (in local_position_to_index()), we'll make a
     * copy of the position and normalize it by sorting the identical pieces so that they are in
     * ascending order.  But we have to at least be aware of this here, in order to figure out which
     * piece "actually" got captured (we're always called with captured_piece set to the last piece
     * number of any identical pieces), so we can figure out which futuremove number to use.
     */

    /* Now consider all possible backwards movements of the capturing piece. */

    if (current_tb->pieces[capturing_piece].piece_type != PAWN) {

	/* If the square we're about to put the captured piece on isn't semilegal for it, then don't
	 * consider this capturing piece in this future position any more.  This is after the "if"
	 * instead of before it because an en passant pawn capture is special, since then the
	 * capturing piece ends up on a different square from the captured piece.
	 */

	if (!(current_tb->pieces[captured_piece].semilegal_squares
	      & BITVECTOR(position->piece_position[capturing_piece]))) {
	    return;
	}

	for (dir = 0; dir < number_of_movement_directions[current_tb->pieces[capturing_piece].piece_type]; dir++) {

	    for (movementptr = movements[current_tb->pieces[capturing_piece].piece_type][position->piece_position[capturing_piece]][dir];
		 (movementptr->vector & position->board_vector) == 0;
		 movementptr++) {

		/* We already checked that the captured piece was on a semilegal square for it.  Now
		 * check the capturing piece.
		 */

		if (! (current_tb->pieces[capturing_piece].semilegal_squares & movementptr->vector)) continue;

		/* Move the capturing piece, normalize the position, and back prop it.
		 *
		 * We have to figure out the "true" capturing and captured pieces, which might not
		 * be the pieces we started with (see comments on normalization).
		 */

		local_position_t new_position = *position;

		new_position.uncapture_piece(capturing_piece, captured_piece, movementptr->square);

		normalize_position(current_tb, &new_position);

		true_capturing_piece = new_position.permuted_piece[capturing_piece];
		true_captured_piece = new_position.permuted_piece[captured_piece];

		propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
							      futurecaptures[true_capturing_piece][true_captured_piece],
							      &new_position);
	    }
	}

    } else {

	/* Yes, pawn captures are special */

	for (movementptr = capture_pawn_movements_bkwd[position->piece_position[capturing_piece]][current_tb->pieces[capturing_piece].color];
	     movementptr->square != -1;
	     movementptr++) {

	    /* Is there anything on the square the pawn had to capture from? */

	    if ((movementptr->vector & position->board_vector) != 0) continue;

	    /* See if it came from a semilegal square for it. */

	    if (! (current_tb->pieces[capturing_piece].semilegal_squares & movementptr->vector)) continue;

	    /* And if the captured piece will end up on a semilegal square for it... */

	    if ((current_tb->pieces[captured_piece].semilegal_squares
		 & BITVECTOR(position->piece_position[capturing_piece]))) {

		local_position_t new_position = *position;

		new_position.uncapture_piece(capturing_piece, captured_piece, movementptr->square);

		normalize_position(current_tb, &new_position);

		true_capturing_piece = new_position.permuted_piece[capturing_piece];
		true_captured_piece = new_position.permuted_piece[captured_piece];

		propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
							      futurecaptures[true_capturing_piece][true_captured_piece],
							      &new_position);

	    }

	    /* The en passant special case: if both the piece that captured and the piece that was
	     * captured are both pawns, and either a white pawn captured from the fifth rank, or a
	     * black pawn captured from the fourth, then there are two possible back prop positions
	     * - the obvious one we just handled, and the one where the captured pawn was in an en
	     * passant state.  We also make sure right away that the rank is clear where the pawn
	     * had to come from, and the rank is clear where the pawn had to go to, ensuring that an
	     * en passant move was even possible.
	     */

	    if ((current_tb->pieces[captured_piece].piece_type == PAWN)
		&& !(position->board_vector & BITVECTOR(position->piece_position[capturing_piece]-8))
		&& !(position->board_vector & BITVECTOR(position->piece_position[capturing_piece]+8))) {

		if ((current_tb->pieces[capturing_piece].color == BLACK) && (ROW(movementptr->square) == 3)) {

		    /* A black pawn capturing a white one (en passant)
		     *
		     * The white pawn is actually a rank higher than usual.
		     */

		    if ((current_tb->pieces[captured_piece].semilegal_squares
			 & BITVECTOR(position->piece_position[capturing_piece] + 8))) {

			local_position_t new_position = *position;

			new_position.uncapture_piece(capturing_piece, captured_piece, movementptr->square);

			new_position.set_en_passant_square(new_position.piece_position[captured_piece]);

			new_position.move_piece(captured_piece, new_position.piece_position[captured_piece] + 8);

			normalize_position(current_tb, &new_position);

			true_capturing_piece = new_position.permuted_piece[capturing_piece];
			true_captured_piece = new_position.permuted_piece[captured_piece];

			propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
								      futurecaptures[true_capturing_piece][true_captured_piece],
								      &new_position);

		    }

		}

		if ((current_tb->pieces[capturing_piece].color == WHITE) && (ROW(movementptr->square) == 4)) {

		    /* A white pawn capturing a black one (en passant)
		     *
		     * The black pawn is actually a rank lower than usual.
		     */

		    if ((current_tb->pieces[captured_piece].semilegal_squares
			 & BITVECTOR(position->piece_position[capturing_piece] - 8))) {

			local_position_t new_position = *position;

			new_position.uncapture_piece(capturing_piece, captured_piece, movementptr->square);

			new_position.set_en_passant_square(new_position.piece_position[captured_piece]);

			new_position.move_piece(captured_piece, new_position.piece_position[captured_piece] - 8);

			normalize_position(current_tb, &new_position);

			true_capturing_piece = new_position.permuted_piece[capturing_piece];
			true_captured_piece = new_position.permuted_piece[captured_piece];

			propagate_normalized_position_from_futurebase(current_tb, futurebase, future_index,
								      futurecaptures[true_capturing_piece][true_captured_piece],
								      &new_position);

		    }
		}
	    }
	}
    }
}

void propagate_moves_from_capture_futurebase(index_t future_index, int reflection)
{
    local_position_t position(current_tb);
    int piece;
    translation_result translation;

    /* Take the position from the futurebase and translate it into a local position for the current
     * tablebase.  If the futurebase index was illegal, the function will return -1.  Otherwise,
     * there should be one piece missing from the local position: the piece that was captured.
     * There could possibly be one piece on a restricted square, as well.  If so, then it must be
     * the piece that moved in order to capture.
     */

    /* XXX If the futurebase is more liberal than the tablebase, then there will be
     * positions with multiple restricted pieces that should be quietly ignored.
     */

    translation = translate_foreign_index_to_local_position(futurebase, future_index,
							    reflections[reflection],
							    current_tb, &position,
							    futurebase->invert_colors);

#ifdef DEBUG_FUTUREMOVE
    if (future_index == DEBUG_FUTUREMOVE) {
	info("capture backprop; reflection=%d; translation=%x\n",
	     reflections[reflection], translation);
    }
#endif

    if (translation != invalid_translation) {

	if ((translation.extra_piece != NONE) || (translation.missing_piece1 == NONE)
	    || (translation.missing_piece2 != NONE)) {
	    return;
	}

	uint8_t captured_piece = translation.missing_piece1;

	/* Since the last move had to have been a capture move, there is absolutely no way
	 * we could have en passant capturable pawns in the futurebase position.
	 */

	if (position.en_passant_square != ILLEGAL_POSITION) return;

	/* Since the position resulted from a capture, we only want to consider future
	 * positions where the side to move is not the side that captured.
	 */

	if (position.side_to_move != current_tb->pieces[captured_piece].color) return;

	/* We're going to back step a half move now */

	position.flip_side_to_move();

	if (translation.restricted_piece == NONE) {

	    /* No pieces were on restricted squares.  Consider them all as the possible
	     * capturing piece.
	     */

	    for (piece = 0; piece < current_tb->num_pieces; piece++) {

		consider_possible_captures(future_index, &position, piece, captured_piece);
	    }

	} else {

	    /* One piece was on a restricted square.  It's the obvious capturing piece, but it's not
	     * the only possible one.  A restricted piece is on a square whose semilegal group is
	     * either empty or already full.  If the square's semilegal group is in fact empty, then
	     * there's only one restricted piece we need to consider.  Otherwise, we need to
	     * consider each piece in the semilegal group as the possible restricted piece.
	     */

	    int restricted_square = position.piece_position[translation.restricted_piece];

	    consider_possible_captures(future_index, &position, translation.restricted_piece, captured_piece);

	    for (piece = 0; piece < current_tb->num_pieces; piece++) {

		if ((current_tb->pieces[piece].color == current_tb->pieces[translation.restricted_piece].color)
		    && (current_tb->pieces[piece].piece_type == current_tb->pieces[translation.restricted_piece].piece_type)
		    && (current_tb->pieces[piece].semilegal_squares & BITVECTOR(restricted_square))) {

		    position.swap_pieces(translation.restricted_piece, piece);

		    consider_possible_captures(future_index, &position, translation.restricted_piece, captured_piece);

		    position.swap_pieces(translation.restricted_piece, piece);
		}
	    }
	}
    }
}

/* A "normal" futurebase is one that's identical to our own in terms of the number and types
 * of pieces.  It differs only in the frozen positions of the pieces.
 *
 * XXX not sure how to handle symmetry changes here.  At the moment it's not an issue, since we
 * don't allow frozen pieces in symmetric tablebases.
 */

void propagate_moves_from_normal_futurebase(index_t future_index, int reflection)
{
    local_position_t parent_position(current_tb);
    local_position_t current_position(current_tb); /* i.e, last position that moved to parent_position */
    translation_result translation;
    int piece;
    int dir;
    struct movement *movementptr;
    int origin_square;

    /* Translate the futurebase index into a local position.  We have exactly the same number and
     * type of pieces here, but exactly one of them is on a restricted square (according to the
     * current tablebase).  If more than one of them was on a restricted square, then there'd be no
     * way we could get to this futurebase with a single move.  On the other hand, if none of them
     * were on restricted squares, then this would be a position in the current tablebase.
     */

    /* XXX we need to permute the restricted piece around in its semilegal set */

    /* XXX If the futurebase is more liberal than the tablebase, then there will be positions with
     * multiple restricted pieces that should be quietly ignored.
     */

    translation = translate_foreign_index_to_local_position(futurebase, future_index, reflection,
							    current_tb, &current_position,
							    futurebase->invert_colors);

    if (translation != invalid_translation) {

	if ((translation.missing_piece1 != NONE) || (translation.missing_piece2 != NONE)
	    || (translation.extra_piece != NONE) || (translation.restricted_piece == NONE)) {
	    return;
	}

	piece = translation.restricted_piece;

	origin_square = current_position.piece_position[piece];

	/* We've moving BACKWARDS in the game, so this has to be a piece of the player who is NOT TO
	 * PLAY here - this is the LAST move we're considering, not the next move.
	 */

	if (current_tb->pieces[piece].color == current_position.side_to_move) return;

	/* If there are any en passant capturable pawns in the position, then the last move had to
	 * have been a pawn move.  In fact, in this case, we already know exactly what the last move
	 * had to have been.
	 */

	if (current_position.en_passant_square != ILLEGAL_POSITION) {

	    if (current_tb->pieces[piece].piece_type != PAWN) return;

	    if (((current_tb->pieces[piece].color == WHITE)
		 && (current_position.piece_position[piece] != current_position.en_passant_square + 8))
		|| ((current_tb->pieces[piece].color == BLACK)
		    && (current_position.piece_position[piece] != current_position.en_passant_square - 8))) {

		/* No reason to complain here.  Maybe some other pawn was the en passant pawn. */
		return;
	    }

	    current_position.flip_side_to_move();
	    current_position.clear_en_passant_square();

	    int square;
	    if (current_tb->pieces[piece].color == WHITE)
		square = current_position.piece_position[piece] - 16;
	    else
		square = current_position.piece_position[piece] + 16;

	    current_position.move_piece(piece, square);

	    /* We never back out into a restricted position.  Since we've already decided that this
	     * is the only possible back-move from this point, well...
	     */

	    if (! (current_tb->pieces[piece].semilegal_squares
		   & BITVECTOR(current_position.piece_position[piece]))) {
		return;
	    }

	    propagate_local_position_from_futurebase(current_tb, futurebase, future_index,
						     futuremoves[piece][origin_square],
						     &current_position);

	    return;
	}

	/* Abuse of notation here.  We just want to keep a copy of current_position because we
	 * change it around a lot during the loops below.
	 */

	parent_position = current_position;

	if (current_tb->pieces[piece].piece_type != PAWN) {

	    for (dir = 0; dir < number_of_movement_directions[current_tb->pieces[piece].piece_type]; dir++) {

		/* What about captures?  Well, first of all, there are no captures here!  We're
		 * moving BACKWARDS in the game... and pieces don't appear out of thin air.
		 * Captures are handled by back-propagation from futurebases, not here in the
		 * movement code.  The piece moving had to come from somewhere, and that somewhere
		 * will now be an empty square, so once we've hit another piece along a movement
		 * vector, there's absolutely no need to consider anything further.
		 */

		for (movementptr
			 = movements[current_tb->pieces[piece].piece_type][parent_position.piece_position[piece]][dir];
		     (movementptr->vector & parent_position.board_vector) == 0;
		     movementptr++) {

		    /* We never back out into a restricted position (obviously) */

		    if (! (current_tb->pieces[piece].semilegal_squares & movementptr->vector)) continue;

		    /* Back stepping a half move here involves several things: flipping the
		     * side-to-move flag, clearing any en passant pawns into regular pawns, moving
		     * the piece (backwards), and considering a bunch of additional positions
		     * identical to the base position except that a single one of the pawns on the
		     * fourth or fifth ranks was capturable en passant.
		     *
		     * Of course, the only way we could have gotten an en passant pawn is if THIS
		     * MOVE created it.  Since this isn't a pawn move, that can't happen.  Checking
		     * additional en passant positions is taken care of in
		     * propagate_one_move_within_table()
		     */

		    current_position.flip_side_to_move();

		    current_position.move_piece(piece, movementptr->square);

		    propagate_local_position_from_futurebase(current_tb, futurebase, future_index,
							     futuremoves[piece][origin_square],
							     &current_position);
		}
	    }

	} else {

	    /* Usual special case for pawns */

	    for (movementptr = normal_pawn_movements_bkwd[parent_position.piece_position[piece]][current_tb->pieces[piece].color];
		 (movementptr->vector & parent_position.board_vector) == 0;
		 movementptr++) {

		/* We never back out into a restricted position (obviously) */

		if (! (current_tb->pieces[piece].semilegal_squares & movementptr->vector)) continue;

		/* Do we have a backwards pawn move here?
		 *
		 * Back stepping a half move here involves several things: flipping the side-to-move
		 * flag, clearing any en passant pawns into regular pawns, moving the piece
		 * (backwards), and considering a bunch of additional positions identical to the
		 * base position except that a single one of the pawns on the fourth or fifth ranks
		 * was capturable en passant.
		 *
		 * Of course, the only way we could have gotten an en passant pawn is if THIS MOVE
		 * created it.  We handle that as a special case above, so we shouldn't have to
		 * worry about clearing en passant pawns here - there should be none.  Checking
		 * additional en passant positions is taken care of in
		 * propagate_one_move_within_table()
		 *
		 * But we start with an extra check to make sure this isn't a double pawn move, it
		 * which case it would result in an en passant position, not the non-en passant
		 * position we are in now (en passant got taken care of in the special case above).
		 */

		if (((movementptr->square - parent_position.piece_position[piece]) == 16)
		    || ((movementptr->square - parent_position.piece_position[piece]) == -16)) {
		    continue;
		}

		current_position = parent_position;

		current_position.flip_side_to_move();

		current_position.move_piece(piece, movementptr->square);

		propagate_local_position_from_futurebase(current_tb, futurebase, future_index,
							 futuremoves[piece][origin_square],
							 &current_position);
	    }
	}
    }
}

/* Back propagates from all the futurebases.
 *
 * Should be called after the tablebase has been initialized, but before intra-table propagation.
 *
 * Runs through the parsed XML control file, pulls out all the futurebases, and back-propagates each
 * one.
 *
 * Returns true, or false if something went wrong
 */

void back_propagate_futurebase_thread(void (* backprop_function)(index_t, int))
{
    index_t future_index;
    int reflection;
    int i;

    /* XXX We could limit the range of future_index here to only those positions where the promoted
     * piece appears on the back rank, but watch out for reflection.
     */

    while ((future_index = futurebase->fetch_entry()) < futurebase->num_indices) {

	for (i=0; i<futurebase_stride; i++) {

	    if (future_index + i < futurebase->num_indices) {

		/* It's tempting to break out the loop here if the position isn't a win, but we want
		 * to track futuremoves in order to make sure we don't miss one, so the simplest way
		 * to do that is to run this loop even for draws.
		 */

		print_progress_dot(futurebase);

		for (reflection = 0; reflection < max_reflection; reflection ++) {
		    (*backprop_function)(future_index + i, reflection);
		}
	    }
	}
    }
}

bool back_propagate_all_futurebases(tablebase_t *tb) {

    int fbnum;
    void (* backprop_function)(index_t, int);

    for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {

	futurebase = & futurebases[fbnum];

	max_reflection = compute_reflections(tb, futurebase, reflections);

	next_future_index = 0;
	backprop_function = nullptr;

	switch (futurebase->futurebase_type) {

	case FUTUREBASE_CAPTURE:

	    if (fatal_errors == 0) {
		info("Back propagating from '%s'\n", (char *) futurebase->filename.c_str());
		backprop_function = &propagate_moves_from_capture_futurebase;
	    }

	    break;

	case FUTUREBASE_PROMOTION:

	    if (fatal_errors == 0) {
		info("Back propagating from '%s'\n", (char *) futurebase->filename.c_str());

		promotion_color = tb->pieces[futurebase->missing_pawn].color;
		first_back_rank_square = ((promotion_color == WHITE) ? 56 : 0);
		last_back_rank_square = ((promotion_color == WHITE) ? 63 : 7);
		promotion_move = ((promotion_color == WHITE) ? 8 : -8);

		backprop_function = &propagate_moves_from_promotion_futurebase;
	    }

	    break;

	case FUTUREBASE_CAPTURE_PROMOTION:

	    if (fatal_errors == 0) {
		info("Back propagating from '%s'\n", (char *) futurebase->filename.c_str());

		promotion_color = tb->pieces[futurebase->missing_pawn].color;
		first_back_rank_square = ((promotion_color == WHITE) ? 56 : 0);
		last_back_rank_square = ((promotion_color == WHITE) ? 63 : 7);
		promotion_move = ((promotion_color == WHITE) ? 8 : -8);

		backprop_function = &propagate_moves_from_promotion_capture_futurebase;
	    }

	    break;

	case FUTUREBASE_NORMAL:

	    if (fatal_errors == 0) {
		info("Back propagating from '%s'\n", (char *) futurebase->filename.c_str());
		backprop_function = propagate_moves_from_normal_futurebase;
	    }

	    break;

	default:

	    fatal("Unknown back propagation type for futurebase '%s'\n", futurebase->filename.c_str());
	    break;

	}

	if (backprop_function) {

	    std::thread t[num_threads];
	    unsigned int thread;

	    reset_progress_dots(futurebase);

	    for (thread = 0; thread < num_threads; thread ++) {
		t[thread] = std::thread(back_propagate_futurebase_thread, backprop_function);
	    }

	    for (thread = 0; thread < num_threads; thread ++) {
		t[thread].join();
	    }
	}
    }

    return (fatal_errors == 0);
}

/***** PRUNING *****/

/* If we don't want to fully analyze out the tree past the table we're now building, we prune some
 * possible futuremoves.  Of course, this will affect the accuracy of the table; the table is a
 * result of BOTH the position it was set up for AND the pruning decisions (and any pruning
 * decisions made on the futurebases used to calculate this one).
 *
 * We specify pruning in a simple way - by omitting future tables for moves we don't want to
 * consider.  This can be dangerous, so we require this feature to be specifically enabled.  There
 * are two possibilities: moves can be DISCARDED, or victory can be CONCEDED to the side that makes
 * the move.
 *
 * So, if we are white, and assuming that this is a table with a frozen white pawn on e3, we can
 * prune by simply ignoring Pe4 as a possible move.  If there is a black pawn on the g-file, and we
 * don't want to compute out what happens after it queens, we can prune by conceding Pg1=X as a win
 * for black.
 *
 * For example, let's say we're looking at a Q-and-P vs. Q-and-P endgame.  There are four completely
 * mobile pieces (2 Ks and 2 Qs), and this is easy.  But if one of the pawns queens, then we've got
 * a more complex game with five mobile pieces.  But we don't want to completely discard all
 * possible enemy promotions, if we can immediately capture the new queen.  So we construct a
 * special tablebase with a queen frozen on the queening square, concede any move by that queen as a
 * win, then use it as a futurebase.
 *
 * And finally, we want to label in the file header that this pruning was done.  In particular, if
 * we use a pruned tablebase to compute another (earlier) pruned tablebase, we want to make sure the
 * pruning is consistent, i.e. "our" side has to stay the same.  This is guaranteed by explicitly
 * flagging in the XML header which sides can be pruned in which way (concede or discard).
 */

bool all_futuremoves_handled = true;

/* finalize_futuremove()
 *
 * After all futurebase backpropagation is done, this function is called on each legal position to
 * check if there are any futuremoves that weren't handled by the futurebases.  If so, we either
 * complain or prune, depending on how we're configured.  We don't use commit_update(), and instead
 * call finalize_update() directly, because we're making a pass through the entries array to call
 * finalize_futuremove(), and can thus update the entry directly, without going through a proptable.
 */

void finalize_futuremove(tablebase_t *tb, index_t index, futurevector_t futurevector) {

    unsigned int futuremove;
    int stm = index_to_side_to_move(tb, index);

    if (futurevector & unpruned_futuremoves[stm]) {
	global_position_t global;
	index_to_global_position(tb, index, &global);
	fatal("Futuremoves not handled: %" PRIindex " %s", index, global_position_to_FEN(&global));
	for (futuremove = 0; futuremove < num_futuremoves[stm]; futuremove ++) {
	    if (futurevector & FUTUREVECTOR(futuremove)	& unpruned_futuremoves[stm]) {
		fatal(" %s", movestr[stm][futuremove]);
	    }
	}
	fatal("\n");
	all_futuremoves_handled = false;
    }

    /* concede - we treat these unhandled futuremoves as forced wins for PTM.  We update the entry
     * with DTM=2 (mate in one) and movecnt=1 (doesn't matter for a PTM win).
     */

    if (futurevector & conceded_futuremoves[stm]) {
	finalize_update(index, 2, 1, NO_FUTUREMOVE);
    }

    /* discard - we ignore these unhandled futuremoves by updating with DTM=0, which decrements
     * movecnt by position.multiplicity, because we multiplied movecnt by position.multiplicity when
     * we initialized the entry.
     *
     * XXX Can't test the use of position.multiplicity because we currently can't have piece
     * restrictions with symmetric tablebases, we need 8-way symmetry to get multiplicity, and we
     * need piece restrictions to get a futurebase where only some futuremoves are handled.
     */

    if (futurevector & discarded_futuremoves[stm]) {
	for (futuremove = 0; futuremove < num_futuremoves[stm]; futuremove ++) {
	    if (futurevector & FUTUREVECTOR(futuremove) & discarded_futuremoves[stm]) {

		local_position_t position(tb);

		index_to_local_position(tb, index, REFLECTION_NONE, &position);

		finalize_update(index, 0, position.multiplicity, NO_FUTUREMOVE);
	    }
	}
    }
}

/* have_all_futuremoves_been_handled() - this is the non-proptable case to run through the entries
 * table and call finalize_futuremove()
 */

bool have_all_futuremoves_been_handled(tablebase_t *tb) {

    index_t index;

    /* XXX this code is probably inefficient, and though it appears to assume a little-endian
     * architecture, I've tried to do it the same way everywhere, so I think it should work no
     * matter the endianness.  Might have alignment problems, though.
     */

    for (index = 0; index < tb->num_indices; index ++) {
	if (entriesTable[index].get_DTM() != 1) {
	    long long bit_offset = ((long long)index * current_tb->futurevector_bits);
	    futurevector_t futurevector = *((futurevector_t *)(current_tb->futurevectors + (bit_offset >> 3)));

	    futurevector >>= bit_offset & 7;
	    futurevector &= (1 << current_tb->futurevector_bits) - 1;
	    finalize_futuremove(tb, index, futurevector);
	}
    }

    return all_futuremoves_handled;
}

/* assign_pruning_statement() - a helper function for compute_pruned_futuremoves()
 *
 * searches the tablebase's XML pruning statements for one matching (more or less identically) the
 * specified color and string.  If there is a match, set the corresponding bit in the
 * pruned_futuremoves bit vector.  The function can be called more than once for a given bit, but
 * probably shouldn't be.  For example, the function might be called on the same bit for "PxQ=Q" if
 * there are two pawns that can promote into a queen.  UNIX-style wildcards are allowed, so "Kd4"
 * would match against "Kd4", "Kd?", "K?4", "K[a-d]4", or "K*".  The function also allows a trailing
 * "any" in the prune statement to act as a "*" wildcard for backwards compatibility.
 *
 * If there are multiple prune statements that match a given futuremove, it's a warning if they are
 * of the same type; a fatal error if their types are different.
 */

int match_pruning_statement(tablebase_t *tb, int color, char *pruning_statement)
{
    xmlpp::NodeSet result;
    int type = RESTRICTION_NONE;

    result = tb->xml->get_root_node()->find("//prune");

    for (auto prune = result.begin(); prune != result.end(); prune ++) {

	Glib::ustring prune_color = (*prune)->eval_to_string("@color");
	Glib::ustring prune_move = (*prune)->eval_to_string("@move");
	Glib::ustring prune_type = (*prune)->eval_to_string("@type");

	/* Trailing 'any' is an older syntax that means '*' */

	auto pos = prune_move.find("any");
	if (pos != std::string::npos) {
	    prune_move.replace(pos, std::string::npos, "*");
	}

	if ((colors.at(prune_color) == color)
	    && (fnmatch(prune_move.c_str(), pruning_statement, FNM_CASEFOLD) == 0)) {

	    if (type == RESTRICTION_NONE) {
		type = restriction_types.at(prune_type);
	    } else if (type != restriction_types.at(prune_type)) {
		fatal("Conflicting %s pruning statements match futuremove %s\n",
		      colors[color].c_str(), pruning_statement);
	    } else {
		warning("Multiple %s pruning statements match futuremove %s\n",
			colors[color].c_str(), pruning_statement);
	    }
	}
    }

    return type;
}

void assign_pruning_statement(tablebase_t *tb, int color, int futuremove)
{
    int type;
    char * pruning_statement = movestr[color][futuremove];

    if (futuremove == -1) return;

    pruning_statement = movestr[color][futuremove];

    type = match_pruning_statement(tb, color, pruning_statement);

    if (type != RESTRICTION_NONE) {

	if (pruned_futuremoves[color] & FUTUREVECTOR(futuremove)) {
	    warning("Multiple pruning statements ('%s') match a futuremove\n", pruning_statement);
	}

	pruned_futuremoves[color] |= FUTUREVECTOR(futuremove);

	if (type == RESTRICTION_CONCEDE) {
	    conceded_futuremoves[color] |= FUTUREVECTOR(futuremove);
	    if (discarded_futuremoves[color] & FUTUREVECTOR(futuremove)) {
		fatal("Conflicting pruning statements ('%s') match a futuremove\n",
		      pruning_statement);
	    }
	}
	if (type == RESTRICTION_DISCARD) {
	    discarded_futuremoves[color] |= FUTUREVECTOR(futuremove);
	    if (conceded_futuremoves[color] & FUTUREVECTOR(futuremove)) {
		fatal("Conflicting pruning statements ('%s') match a futuremove\n",
		      pruning_statement);
	    }
	}
    }
}

/* assign_numbers_to_futuremoves()
 *
 * We could just dismiss any moves that aren't handled by our futurebases, but I've found this to be
 * a source of error, since moves tend to get overlooked this way.  We're also concerned with the
 * more sobering possibility of a single move getting processed twice by two different futurebases.
 *
 * So we assign numbers, bit positions in a bit vector, actually, to each futuremove.  When we
 * initialize the tablebase, we set bits in the vector (each position has its own vector) for each
 * futuremove possible from that position.  As we back propagate futuremoves, we check the bit to
 * make sure it's still set, then clear it.  After we've back propagated all the futurebases, we run
 * through the entire tablebase, making sure that the only bits that remain set correspond to prune
 * statements.
 *
 * This function not only assigns the numbers, but also prints an identifying string, such as "KxP"
 * or "Re4", into the movestr array for each number assigned.  This string will then be matched
 * against the pruning statements specified in the configuration file.  Sometimes the strings will
 * repeat.  For example, if we have two pawns and an enemy queen, we'll probably end up with two
 * different bit positions, both assigned as "QxP".  The reason is that there are probably positions
 * where the queen could take either pawn, so both possibilities have to be tracked.
 *
 * Because we need a "futurevector" for each position in the tablebase, we want to keep it as small
 * as possible, so we try to use as few bit positions as possible.  In particular, we track white
 * and black futuremoves seperately (since from a given position only one or the other will be
 * possible) and we try to reuse bit positions for pawn capture-promotions if the pawns are
 * sufficiently restricted so that only one or the other could capture the enemy piece in a given
 * position.
 */

void assign_numbers_to_futuremoves(tablebase_t *tb) {

    int piece;
    int captured_piece;
    int capturing_piece;
    int sq;
    int dir;
    int promotion;
    struct movement *movementptr;
    uint64_t possible_captures[MAX_PIECES];
    char local_movestr[MOVESTR_CHARS];
    int futurebase_cnt;
    int fbnum;

    /* Start by computing a board vector (possible_captures) showing all possible squares where each
     * piece can capture onto.
     */

    for (piece = 0; piece < tb->num_pieces; piece ++) {

	possible_captures[piece] = 0;

	for (sq = 0; sq < 64; sq ++) {

	    /* We make the checks here using legal_squares and not semilegal_squares because
	     * we're assigning futuremove numbers to individual pieces that can capture.  The
	     * movements we consider here, being captures, would take us to a futurebase anyway,
	     * so there's no question of whether the resulting position is fully legal or not.
	     */

	    if (tb->pieces[piece].legal_squares & BITVECTOR(sq)) {
		if (tb->pieces[piece].piece_type != PAWN) {
		    for (dir = 0; dir < number_of_movement_directions[tb->pieces[piece].piece_type]; dir++) {
			for (movementptr = movements[tb->pieces[piece].piece_type][sq][dir];
			     movementptr->square != -1; movementptr++) {

			    possible_captures[piece] |= movementptr->vector;

			    /* If we hit a frozen piece, then this movement direction ends here */
			    if (movementptr->vector & tb->frozen_pieces_vector) break;
			}
		    }
		} else {
		    for (movementptr = capture_pawn_movements[sq][tb->pieces[piece].color];
			 movementptr->square != -1; movementptr++) {

			possible_captures[piece] |= movementptr->vector;
		    }
		}
	    }
	}
    }

    /* Now, consider all possible pairs of pieces that might capture, and assign a number (in the
     * futurecaptures array) to each pair.  We'll ultimately use this number as an index into a bit
     * vector to determine if this capture has been handled in any particular position.  However,
     * there's a common enough "special" case: the two pieces are frozen (or at least sufficiently
     * restricted) so that the capture can never occur.  Go to the trouble of checking for this.
     */

    for (captured_piece = 0; captured_piece < tb->num_pieces; captured_piece ++) {

	if ((captured_piece == tb->white_king) || (captured_piece == tb->black_king)) continue;

	for (capturing_piece = 0; capturing_piece < tb->num_pieces; capturing_piece ++) {

	    /* If this is a suicide analysis and we can capture a player's only (i.e, last) piece,
	     * we lose.  Treat this just like a 'resign' prune, except that we don't need prune or
	     * prune-enable statements, since these are the rules of the game!
	     */

	    if ((tb->variant == VARIANT_SUICIDE) && (tb->num_pieces_by_color[tb->pieces[captured_piece].color] == 1)) {

		futurecaptures[capturing_piece][captured_piece] = RESIGN_FUTUREMOVE;

		for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
		    promotion_captures[capturing_piece][captured_piece][promotion] = RESIGN_FUTUREMOVE;
		}

		continue;
	    }

	    futurecaptures[capturing_piece][captured_piece] = NO_FUTUREMOVE;

	    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
		promotion_captures[capturing_piece][captured_piece][promotion] = NO_FUTUREMOVE;
	    }

	    if (tb->pieces[capturing_piece].color == tb->pieces[captured_piece].color) continue;

	    if (tb->pieces[capturing_piece].piece_type != PAWN) {

		if (possible_captures[capturing_piece] & tb->pieces[captured_piece].legal_squares) {

		    char * my_movestr
			= movestr[tb->pieces[capturing_piece].color]
			[num_futuremoves[tb->pieces[capturing_piece].color]];

		    sprintf(my_movestr, "%cx%c",
			    piece_char[tb->pieces[capturing_piece].piece_type],
			    piece_char[tb->pieces[captured_piece].piece_type]);

		    futurecaptures[capturing_piece][captured_piece]
			= num_futuremoves[tb->pieces[capturing_piece].color] ++;
		}

	    } else {

		/* if it's a pawn-takes-pawn situation, check for en passant as well */

		if ((possible_captures[capturing_piece] & tb->pieces[captured_piece].legal_squares)
		    | ((tb->pieces[captured_piece].piece_type == PAWN)
		       && (((tb->pieces[capturing_piece].color == WHITE)
			    ? ((possible_captures[capturing_piece] & 0x0000ff0000000000LL) >> 8)
			    : ((possible_captures[capturing_piece] & 0x0000000000ff0000LL) << 8))
			   & tb->pieces[captured_piece].legal_squares))) {

		    int candidate_futuremove = NO_FUTUREMOVE;
		    char candidate_movestr[MOVESTR_CHARS];

		    /* start by dishing out a non-promotion futurecapture */

		    char * my_movestr
			= movestr[tb->pieces[capturing_piece].color]
			[num_futuremoves[tb->pieces[capturing_piece].color]];

		    sprintf(my_movestr, "%cx%c",
			    piece_char[tb->pieces[capturing_piece].piece_type],
			    piece_char[tb->pieces[captured_piece].piece_type]);

		    futurecaptures[capturing_piece][captured_piece]
			= num_futuremoves[tb->pieces[capturing_piece].color] ++;

		    /* Keep going only if it's a pawn capture that results in promotion */

		    if (! (possible_captures[capturing_piece] & tb->pieces[captured_piece].legal_squares
			   & ((tb->pieces[capturing_piece].color == WHITE)
			      ? 0xff00000000000000LL : 0x00000000000000ffLL))) {
			continue;
		    }

		    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {

			candidate_futuremove = NO_FUTUREMOVE;

			sprintf(candidate_movestr, "Px%c=%c",
				piece_char[tb->pieces[captured_piece].piece_type],
				piece_char[promoted_pieces[promotion]]);

			/* Be conservative about handing out bit positions in the futurevector.
			 * Look through the other pieces that have been assigned bit positions and
			 * see if we can find one with an identical movestr that can never capture
			 * onto the squares that our piece can capture onto and reuse its bit
			 * positions.
			 *
			 * This code could be a lot more aggressively conservative, but for now I
			 * settle for handling the common simple case of pawns more than two files
			 * apart never being able to capture the same piece.  I only look at
			 * futuremoves for the current captured_piece, and only so far as the
			 * current capturing_piece.  That's why the nesting order of the two
			 * captured_piece and capturing_piece loops is important above.  First we
			 * look for a candidate futuremove, then we try to bust it by looking for
			 * overlaps.
			 */

			for (piece = 0; piece < capturing_piece; piece ++) {
			    if (tb->pieces[piece].color != tb->pieces[capturing_piece].color) continue;
			    if (promotion_captures[piece][captured_piece][promotion] != NO_FUTUREMOVE) {
				if ((! (possible_captures[capturing_piece] & possible_captures[piece]))
				    && (! strcmp(candidate_movestr, movestr[tb->pieces[piece].color][promotion_captures[piece][captured_piece][promotion]]))) {
				    candidate_futuremove = promotion_captures[piece][captured_piece][promotion];
				}
			    }
			}

			if (candidate_futuremove != NO_FUTUREMOVE) {
			    for (piece = 0; piece < capturing_piece; piece ++) {
				if (tb->pieces[piece].color != tb->pieces[capturing_piece].color) continue;
				if (! (possible_captures[capturing_piece] & possible_captures[piece])) continue;
				if (promotion_captures[piece][captured_piece][promotion] != NO_FUTUREMOVE) {
				    if (promotion_captures[piece][captured_piece][promotion] == candidate_futuremove) {
					candidate_futuremove = NO_FUTUREMOVE;
					break;
				    }
				}
			    }
			}

			if (candidate_futuremove == NO_FUTUREMOVE) {
			    candidate_futuremove = num_futuremoves[tb->pieces[capturing_piece].color] ++;
			    strcpy(movestr[tb->pieces[capturing_piece].color][candidate_futuremove], candidate_movestr);
			}

			promotion_captures[capturing_piece][captured_piece][promotion] = candidate_futuremove;

		    }
		}
	    }
	}
    }

    /* We also want to consider all promotions.  We don't wrap this into the pawn code that follows
     * because we want to count all promotions together, not a set for each destination square.
     * This is a special case of a more general problem that this code doesn't address yet.  We want
     * to minimize the assigned numbers to keep the futuremove bit vector small, so we want to reuse
     * those numbers if we're sure that two moves can't happen from different squares.  I.e, if a
     * king is restricted to the f1/h3 rectangle, then it can move to e1 from f1 and it can move to
     * h4 from h3, but there is no single position from which it can move to both e1 and h4.  So we
     * can use the same position in the bit vector for Ke1 and Kh4.  But we don't (yet).
     */

    for (piece = 0; piece < tb->num_pieces; piece ++) {
	for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
	    promotions[piece][promotion] = NO_FUTUREMOVE;
	}
	if (tb->pieces[piece].piece_type == PAWN) {
	    for (sq = (tb->pieces[piece].color == WHITE ? 48 : 8);
		 sq <= (tb->pieces[piece].color == WHITE ? 55 : 15); sq++) {
		if (tb->pieces[piece].legal_squares & BITVECTOR(sq)) {

		    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
			promotions[piece][promotion] = num_futuremoves[tb->pieces[piece].color];
			sprintf(movestr[tb->pieces[piece].color][promotions[piece][promotion]],
				"P=%c", piece_char[promoted_pieces[promotion]]);
			num_futuremoves[tb->pieces[piece].color] ++;
		    }

		    break;
		}
	    }
	}
    }

    /* And now all piece moves outside their restriction.  We record a futuremove for each possible
     * destination square that the piece can reach outside its move restriction, unless we've
     * determined that there are no "normal" futurebases, in which case we flag the pruning right
     * here and now.
     */

    futurebase_cnt = 0;

    for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {
	if (futurebases[fbnum].futurebase_type == FUTUREBASE_NORMAL) futurebase_cnt ++;
    }

    for (piece = 0; piece < tb->num_pieces; piece ++) {

	for (sq = 0; sq < 64; sq ++) futuremoves[piece][sq] = NO_FUTUREMOVE;

	for (sq = 0; sq < 64; sq ++) {

	    /* Consider as _starting_ squares only those within the piece's movement restriction */

	    if (! (tb->pieces[piece].legal_squares & BITVECTOR(sq))) continue;

	    if (tb->pieces[piece].piece_type != PAWN) {

		for (dir = 0; dir < number_of_movement_directions[tb->pieces[piece].piece_type]; dir++) {

		    for (movementptr = movements[tb->pieces[piece].piece_type][sq][dir];
			 movementptr->square != -1; movementptr++) {

			/* If we hit a frozen piece, movement has to stop.  We don't consider
			 * captures here; they were handled above.
			 */

			if (movementptr->vector & tb->frozen_pieces_vector) break;

			/* If the piece is moving outside its semilegal squares, it's a futuremove.
			 * If it's moving from a legal square to a semilegal square, it's also a
			 * futuremove... except for a special case.  Obviously the other piece in
			 * its semilegal group can't be on either the square it's moving from or the
			 * square it's moving to (no other piece can be).  If all remaining legal
			 * squares available to that other piece are also legal squares for this
			 * piece, then we can always successfully flip the two pieces and this isn't
			 * a futuremove.  The converse is that there must be at least one legal
			 * square available to the other piece that isn't a legal square for this
			 * piece; in other words, this piece must have another semilegal square that
			 * isn't legal.
			 */

			if (!(tb->pieces[piece].semilegal_squares & BITVECTOR(movementptr->square))

			    || (!(tb->pieces[piece].legal_squares & BITVECTOR(movementptr->square))
				&& ( tb->pieces[piece].semilegal_squares & ~(tb->pieces[piece].legal_squares)
				     & ~BITVECTOR(movementptr->square) & ~BITVECTOR(sq) ))) {

			    if (futuremoves[piece][movementptr->square] == NO_FUTUREMOVE) {

				sprintf(local_movestr, "%c%c%c", piece_char[tb->pieces[piece].piece_type],
					'a' + COL(movementptr->square), '1' + ROW(movementptr->square));

				if (futurebase_cnt > 0) {
				    futuremoves[piece][movementptr->square]
					= num_futuremoves[tb->pieces[piece].color];
				    strcpy(movestr[tb->pieces[piece].color][num_futuremoves[tb->pieces[piece].color]],
					   local_movestr);
				    num_futuremoves[tb->pieces[piece].color] ++;
				} else {
				    switch (match_pruning_statement(tb, tb->pieces[piece].color,
								    local_movestr)) {
				    case RESTRICTION_DISCARD:
					futuremoves[piece][movementptr->square] = DISCARD_FUTUREMOVE;
					break;
				    case RESTRICTION_CONCEDE:
					futuremoves[piece][movementptr->square] = CONCEDE_FUTUREMOVE;
					break;
				    }
				}
			    }
			}
		    }
		}

	    } else {

		/* Pawns, as always, are special */

		for (movementptr = normal_pawn_movements[sq][tb->pieces[piece].color];
		     movementptr->square != -1; movementptr++) {

		    /* If we hit a frozen piece, movement has to stop.  We don't consider captures
		     * here; they were handled above.
		     */

		    if (movementptr->vector & tb->frozen_pieces_vector) break;

		    if ((ROW(movementptr->square) == 7) || (ROW(movementptr->square) == 0)) {

			/* might want to put the promotion code here */

		    } else if (! tb->pawngen) {

			/* If the pawn is moving outside its restricted squares, it's a futuremove,
			 * unless the pawn is blocked, in which case the pawn will never be able to
			 * move outside its restriction (except via capture).
			 *
			 * If we're using 'pawngen', then we never assign futuremoves here, because
			 * pawngen has taken all possible normal pawn moves into account.
			 */

			if (!(tb->pieces[piece].semilegal_squares & BITVECTOR(movementptr->square))

			    || (!(tb->pieces[piece].legal_squares & BITVECTOR(movementptr->square))
				&& ( tb->pieces[piece].semilegal_squares & ~(tb->pieces[piece].legal_squares)
				     & ~BITVECTOR(movementptr->square) & ~BITVECTOR(sq) ))) {

			    if (tb->pieces[piece].blocking_piece == -1) {

				if (futuremoves[piece][movementptr->square] == NO_FUTUREMOVE) {
				    futuremoves[piece][movementptr->square]
					= num_futuremoves[tb->pieces[piece].color];
				    sprintf(movestr[tb->pieces[piece].color][num_futuremoves[tb->pieces[piece].color]],
					    "%c%c%c", piece_char[tb->pieces[piece].piece_type],
					    'a' + COL(movementptr->square), '1' + ROW(movementptr->square));
				    num_futuremoves[tb->pieces[piece].color] ++;
				}
			    }
			}
		    }
		}
	    }
	}
    }

    info("%d possible WHITE futuremoves\n", num_futuremoves[WHITE]);
    if (tb->encode_stm) info("%d possible BLACK futuremoves\n", num_futuremoves[BLACK]);

    if (num_futuremoves[WHITE] > sizeof(futurevector_t)*8) {
	fatal("Too many futuremoves - %d!  (only %d bits futurevector_t)\n",
	      num_futuremoves[WHITE], sizeof(futurevector_t)*8);
	terminate();
    }
    if (num_futuremoves[BLACK] > sizeof(futurevector_t)*8) {
	fatal("Too many futuremoves - %d!  (only %d bits futurevector_t)\n",
	      num_futuremoves[BLACK], sizeof(futurevector_t)*8);
	terminate();
    }

}

void print_futuremoves(void)
{
    unsigned int i;

    info("%d unpruned WHITE futuremoves\n", num_futuremoves[WHITE]);
    if (current_tb->encode_stm) info("%d unpruned BLACK futuremoves\n", num_futuremoves[BLACK]);

    for (i=0; i < num_futuremoves[WHITE]; i ++) {
	info("WHITE Futuremove %i: %s\n", i, movestr[WHITE][i]);
    }
    for (i=0; i < num_futuremoves[BLACK]; i ++) {
	if (current_tb->encode_stm) info("BLACK Futuremove %i: %s\n", i, movestr[BLACK][i]);
    }
}

/* This is where we parse pruning statements.  Fill in the pruned_futuremoves bit vector with bits
 * set for the various pruned moves.  We call this routine after assign_numbers_to_futuremoves(),
 * which also prints strings into the movestr array, and now we use those strings to match against
 * pruning statements.  To make this routine easier, assign_pruning_statement() can be called with a
 * '-1' futuremove, in which case it will do nothing.
 *
 * XXX something else I'd like to do here is to flag all of the pruning statements to make
 * sure we've used each one, and complain if any are left unused.
 */

bool compute_pruned_futuremoves(tablebase_t *tb)
{
    xmlpp::NodeSet result;

    /* Check pruning statements for consistency, and record stalemate pruning if specified */

    result = tb->xml->get_root_node()->find("//prune");

    for (auto prune = result.begin(); prune != result.end(); prune ++) {

	Glib::ustring prune_color = (*prune)->eval_to_string("@color");
	Glib::ustring prune_type = (*prune)->eval_to_string("@type");

	int color = colors.at(prune_color);
	int type = restriction_types.at(prune_type);

	if (! (type & tb->prune_enable[color])) {
	    fatal("Prune statements don't match tablebase prune-enables\n");
	}
    }

    if (fatal_errors != 0) return false;

    for (auto color = WHITE; color <= BLACK; color ++) {
	for (auto fm = 0U; fm < num_futuremoves[color]; fm ++) {
	    assign_pruning_statement(tb, color, fm);
	}
    }

    unpruned_futuremoves[WHITE] = ~pruned_futuremoves[WHITE];
    unpruned_futuremoves[BLACK] = ~pruned_futuremoves[BLACK];

    return (fatal_errors == 0);
}


/* check_pruning()
 *
 * We run this function after we've assigned numbers to the futuremoves and then matched pruning
 * statements against them, but before we initialize the tablebase.
 *
 * Check the futurebases to see if there are any for a given futuremove.  If not, check to make sure
 * the futuremove is pruned.  Otherwise, signal an error and exit right now.  Just because this test
 * is passed doesn't mean a particular futuremove is handled in a particular position (that's why we
 * use the bit vector), but if the test fails, well, then we know (almost) for sure that we'd get to
 * the end of program with unhandled futurebases, so we can save ourselves a long computation by
 * making this basic check now.
 *
 * If no futurebases exist for a given futuremove and it is correctly pruned, then flag it for
 * optimization, since there is no need to track its futurebase back propagation.
 *
 * There is an off chance that piece restrictions will prevent a futuremove from taking place, but
 * this code will conclude nevertheless that it is possible and demand either a prune statement or a
 * futurebase.  In this rare case, introducing an extraneous prune statement or two should solve the
 * problem.
 */

bool check_pruning(tablebase_t *tb) {

    int fbnum;
    int piece;
    int captured_piece;
    int capturing_piece;
    int pawn;
    int sq;
    int futurebase_cnt;

    /* for each possible captured_piece (i.e, everything but the two kings) check for capture
     * futurebases
     */

    for (captured_piece = 0; captured_piece < tb->num_pieces; captured_piece ++) {

	// XXX suicide?

	if ((captured_piece == tb->white_king) || (captured_piece == tb->black_king)) continue;

	futurebase_cnt = 0;

	/* I've made this a bit more liberal now, because if we're dealing with move restrictions,
	 * then we might have a missing piece in the futurebase line up with one of our pieces that
	 * is identical to captured_piece in the sense that it's the same color and type, but not
	 * identical in the sense of next_piece_in_semilegal_group.
	 */

	for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {
	    if (tb->pieces[captured_piece].piece_type == PAWN) {
		if ((futurebases[fbnum].extra_piece == -1)
		    && (futurebases[fbnum].missing_pawn != -1)
		    && (tb->pieces[futurebases[fbnum].missing_pawn].color == tb->pieces[captured_piece].color)
		    && (futurebases[fbnum].missing_non_pawn == -1)) futurebase_cnt ++;
	    } else {
		if ((futurebases[fbnum].extra_piece == -1)
		    && (futurebases[fbnum].missing_non_pawn != -1)
		    && (tb->pieces[futurebases[fbnum].missing_non_pawn].color == tb->pieces[captured_piece].color)
		    && (futurebases[fbnum].missing_pawn == -1)) futurebase_cnt ++;
	    }
	}

	/* If no such futurebase exists, then for every other piece, see if the piece restrictions
	 * would permit it to capture the original piece in question.  If so, there must be a prune
	 * statement, or it's an error.
	 */

	if (futurebase_cnt == 0) {

	    for (capturing_piece = 0; capturing_piece < tb->num_pieces; capturing_piece ++) {

		/* If we're not encoding side-to-move, then all of the positions in the tablebase
		 * are WHITE positions, so we don't care if the capturing piece is BLACK
		 */

		if ((! tb->encode_stm) && (tb->pieces[capturing_piece].color == BLACK)) continue;

		if (futurecaptures[capturing_piece][captured_piece] >= 0) {

		    if (! (pruned_futuremoves[tb->pieces[capturing_piece].color]
			   & FUTUREVECTOR(futurecaptures[capturing_piece][captured_piece]))) {
			fatal("No futurebase or pruning for %s move %s\n",
			      colors[tb->pieces[capturing_piece].color].c_str(),
			      movestr[tb->pieces[capturing_piece].color][futurecaptures[capturing_piece][captured_piece]]);
			return false;
		    } else if (discarded_futuremoves[tb->pieces[capturing_piece].color]
			       & FUTUREVECTOR(futurecaptures[capturing_piece][captured_piece])) {
			optimized_futuremoves[tb->pieces[capturing_piece].color]
			    |= FUTUREVECTOR(futurecaptures[capturing_piece][captured_piece]);
			futurecaptures[capturing_piece][captured_piece] = DISCARD_FUTUREMOVE;
		    } else if (conceded_futuremoves[tb->pieces[capturing_piece].color]
			       & FUTUREVECTOR(futurecaptures[capturing_piece][captured_piece])) {
			optimized_futuremoves[tb->pieces[capturing_piece].color]
			    |= FUTUREVECTOR(futurecaptures[capturing_piece][captured_piece]);
			futurecaptures[capturing_piece][captured_piece] = CONCEDE_FUTUREMOVE;
		    } else {
			fatal("Internal error: pruned move is neither conceded nor discarded?!?\n");
		    }
		}
	    }
	}
    }

    /* Pawns - check for both promotion and promotion capture futurebases here.  Same idea. */

    for (pawn = 0; pawn < tb->num_pieces; pawn ++) {

	int promotion;

	if (tb->pieces[pawn].piece_type != PAWN) continue;

	if ((! tb->encode_stm) && (tb->pieces[pawn].color == BLACK)) continue;

	/* First, we're looking for promotion capture futurebases. */

	for (captured_piece = 0; captured_piece < tb->num_pieces; captured_piece ++) {

	    if ((captured_piece == tb->white_king) || (captured_piece == tb->black_king)) continue;

	    /* Check to see if the pawn can even be on a square where a promotion capture is
	     * possible.
	     */

	    if (tb->pieces[pawn].color == WHITE) {
		if (! (tb->pieces[pawn].legal_squares & 0x00ff000000000000LL)) break;
	    } else {
		if (! (tb->pieces[pawn].legal_squares & 0x000000000000ff00LL)) break;
	    }

	    /* Check to see that the other piece can be on a square where it could be promotion
	     * captured.  It's still possible that the other piece could be on a back rank, but
	     * never on a square where it could be captured by the pawn, but we leave that
	     * possibility unchecked.  It'd probably be best to tie this code in with the code in
	     * assign_numbers_to_futuremoves() - maybe by flagging which captures it was determined
	     * that promotion was possible in?
	     */

	    if (tb->pieces[pawn].color == WHITE) {
		if (! (tb->pieces[captured_piece].legal_squares & 0xff00000000000000LL)) continue;
	    } else {
		if (! (tb->pieces[captured_piece].legal_squares & 0x00000000000000ffLL)) continue;
	    }

	    /* check all futurebases for a 'promotion capture' with captured_piece missing */

	    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {

		int promoted_piece_handled = 0;

		if (promotion_captures[pawn][captured_piece][promotion] < 0) continue;

		for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {
		    if ((futurebases[fbnum].extra_piece != -1)
			&& (futurebases[fbnum].pieces[futurebases[fbnum].extra_piece].color
			    == (futurebases[fbnum].invert_colors ? 1 - tb->pieces[pawn].color : tb->pieces[pawn].color))
			&& (futurebases[fbnum].missing_non_pawn != -1)
			&& (tb->pieces[futurebases[fbnum].missing_non_pawn].color
			    == tb->pieces[captured_piece].color)
			&& (tb->pieces[futurebases[fbnum].missing_non_pawn].piece_type
			    == tb->pieces[captured_piece].piece_type)
			&& (futurebases[fbnum].missing_pawn != -1)
			&& (tb->pieces[futurebases[fbnum].missing_pawn].color == tb->pieces[pawn].color)
			&& (futurebases[fbnum].pieces[futurebases[fbnum].extra_piece].piece_type == promoted_pieces[promotion])) {

			promoted_piece_handled = 1;
		    }
		}

		/* If no such futurebase exists, then there must be a prune statement, or it's an
		 * error.
		 */

		if (promoted_piece_handled) continue;

		if (! (pruned_futuremoves[tb->pieces[pawn].color]
		       & FUTUREVECTOR(promotion_captures[pawn][captured_piece][promotion]))) {
		    fatal("No futurebase or pruning for %s move %s\n",
			  colors[tb->pieces[pawn].color].c_str(),
			  movestr[tb->pieces[pawn].color][promotion_captures[pawn][captured_piece][promotion]]);
		    return false;
		} else if (discarded_futuremoves[tb->pieces[pawn].color]
			   & FUTUREVECTOR(promotion_captures[pawn][captured_piece][promotion])) {
		    optimized_futuremoves[tb->pieces[pawn].color] |= FUTUREVECTOR(promotion_captures[pawn][captured_piece][promotion]);
		    promotion_captures[pawn][captured_piece][promotion] = DISCARD_FUTUREMOVE;
		} else if (conceded_futuremoves[tb->pieces[pawn].color]
			   & FUTUREVECTOR(promotion_captures[pawn][captured_piece][promotion])) {
		    optimized_futuremoves[tb->pieces[pawn].color] |= FUTUREVECTOR(promotion_captures[pawn][captured_piece][promotion]);
		    promotion_captures[pawn][captured_piece][promotion] = CONCEDE_FUTUREMOVE;
		} else {
		    fatal("Internal error: pruned move is neither conceded nor discarded?!?\n");
		}

	    }
	}

	/* straight promotion futurebases */

	for (promotion = 0; promotion < promotion_possibilities; promotion ++) {

	    int promoted_piece_handled = 0;

	    if (promotions[pawn][promotion] < 0) continue;

	    for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {
		if ((futurebases[fbnum].extra_piece != -1)
		    && (futurebases[fbnum].missing_non_pawn == -1)
		    && (futurebases[fbnum].missing_pawn != -1)
		    && (futurebases[fbnum].pieces[futurebases[fbnum].extra_piece].piece_type == promoted_pieces[promotion])) {

		    promoted_piece_handled = 1;
		}
	    }


	    if (promoted_piece_handled) continue;

	    if (! (pruned_futuremoves[tb->pieces[pawn].color] & FUTUREVECTOR(promotions[pawn][promotion]))) {
		fatal("No futurebase or pruning for %s move %s\n",
		      colors[tb->pieces[pawn].color].c_str(),
		      movestr[tb->pieces[pawn].color][promotions[pawn][promotion]]);
		return false;
	    } else if (discarded_futuremoves[tb->pieces[pawn].color] & FUTUREVECTOR(promotions[pawn][promotion])) {
		optimized_futuremoves[tb->pieces[pawn].color] |= FUTUREVECTOR(promotions[pawn][promotion]);
		promotions[pawn][promotion] = DISCARD_FUTUREMOVE;
	    } else if (conceded_futuremoves[tb->pieces[pawn].color] & FUTUREVECTOR(promotions[pawn][promotion])) {
		optimized_futuremoves[tb->pieces[pawn].color] |= FUTUREVECTOR(promotions[pawn][promotion]);
		promotions[pawn][promotion] = CONCEDE_FUTUREMOVE;
	    } else {
		fatal("Internal error: pruned move is neither conceded nor discarded?!?\n");
	    }
	}
    }

    /* Check for any futurebases that match our piece types exactly.  It (or they) must correspond
     * to restricted piece movements.
     */

    futurebase_cnt = 0;

    for (fbnum = 0; fbnum < num_futurebases; fbnum ++) {
	if ((futurebases[fbnum].extra_piece == -1)
	    && (futurebases[fbnum].missing_pawn == -1)
	    && (futurebases[fbnum].missing_non_pawn == -1)) futurebase_cnt ++;
    }

    /* I'd like to construct a mask of all allowable squares for each color and type of piece, and
     * verify that the futurebases or pruning actually account for all possible restricted
     * movements.  This would let me catch early things like forgetting to specify a g4 tablebase
     * for a pawn frozen on g2.  For now, we only check for missing pruning if there are no "normal"
     * futurebases at all.
     */

    if (futurebase_cnt == 0) {
	for (piece = 0; piece < tb->num_pieces; piece ++) {
	    if ((! tb->encode_stm) && (tb->pieces[piece].color == BLACK)) continue;
	    for (sq = 0; sq < 64; sq ++) {
		if (futuremoves[piece][sq] >= 0) {

		    if (! (pruned_futuremoves[tb->pieces[piece].color] & FUTUREVECTOR(futuremoves[piece][sq]))) {
			fatal("No futurebase or pruning for %s move %s\n",
			      colors[tb->pieces[piece].color].c_str(),
			      movestr[tb->pieces[piece].color][futuremoves[piece][sq]]);
			return false;
		    }
		}
	    }
	}
    }

    return true;
}


/* optimize_futuremoves()
 *
 * Once we've assigned futuremove numbers, then gone and checked pruning, some of those futuremoves
 * might now be completely pruned.  If so, flag them for pruning during initialization (by changing
 * their numbers to -2 or -3) and collapse the remaining futuremoves down into a smaller set.
 */

void remove_futuremove(futurevector_t *fvp, int fm)
{
    *fvp = ((*fvp) & (FUTUREVECTOR(fm)-1)) | (((*fvp) & ~(FUTUREVECTOR(fm+1)-1)) >> 1);
}

void optimize_futuremoves(tablebase_t *tb)
{
    int color, fm, fm2, piece, piece2, sq, promotion;

    for (color = WHITE; color <= BLACK; color ++) {

	for (fm = 0; fm < (int) num_futuremoves[color]; fm++) {

	    if (optimized_futuremoves[color] & FUTUREVECTOR(fm)) {

		for (piece = 0; piece < tb->num_pieces; piece ++) {

		    if (tb->pieces[piece].color == color) {

			for (piece2 = 0; piece2 < tb->num_pieces; piece2 ++) {
			    if (futurecaptures[piece][piece2] > fm) {
				futurecaptures[piece][piece2] --;
			    }
			    if (tb->pieces[piece].piece_type == PAWN) {
				for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
				    if (promotion_captures[piece][piece2][promotion] > fm) {
					promotion_captures[piece][piece2][promotion] --;
				    }
				}
			    }
			}

			for (sq = 0; sq < 64; sq ++) {
			    if (futuremoves[piece][sq] > fm) {
				futuremoves[piece][sq] --;
			    }
			}

			if (tb->pieces[piece].piece_type == PAWN) {
			    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {
				if (promotions[piece][promotion] > fm) {
				    promotions[piece][promotion] --;
				}
			    }
			}
		    }
		}

		remove_futuremove(&(pruned_futuremoves[color]), fm);
		remove_futuremove(&(conceded_futuremoves[color]), fm);
		remove_futuremove(&(discarded_futuremoves[color]), fm);
		remove_futuremove(&(optimized_futuremoves[color]), fm);

		info("Pruned %s futuremove %s\n", colors[color].c_str(), movestr[color][fm]);

		for (fm2 = fm + 1; fm2 < (int) num_futuremoves[color]; fm2++) {
		    strcpy(movestr[color][fm2-1], movestr[color][fm2]);
		}

		num_futuremoves[color] --;
		fm --;
	    }
	}
    }
}

/***** INTRA-TABLE MOVE PROPAGATION *****/

/* We've got a move that needs to be propagated, so we back out one half-move to all of the
 * positions that could have gotten us here and update their counters in various obscure ways.
 */

void propagate_one_minimove_within_table(tablebase_t *tb, index_t future_index, local_position_t *current_position)
{
    index_t current_index;
    int dtm = entriesTable[future_index].get_DTM();

    current_index = local_position_to_index(tb, current_position);

    if (current_index == INVALID_INDEX) {
#ifdef DEBUG_MOVE
	if (future_index == DEBUG_MOVE) {
	    info("propagate_one_minimove_within_table:  current_index=INVALID"
		 "; future_index=%" PRIindex "; dtm=%d\n",
		 future_index, dtm);
	}
#endif
	return;
    }

#ifdef DEBUG_MOVE
    if ((current_index == DEBUG_MOVE) || (future_index == DEBUG_MOVE))
	info("propagate_one_minimove_within_table:  current_index=%"
	     PRIindex "; future_index=%" PRIindex "; dtm=%d\n",
	     current_index, future_index, dtm);
#endif

    /* Parent position is the FUTURE position.  We now back-propagate to
     * the current position, which is the PAST position.
     *
     * If the player to move in the FUTURE position wins, then we add one to that
     * player's win count in the PAST position.  On other other hand, if the player not
     * to move in the FUTURE position wins, then the player to move in the PAST position
     * has a winning move (the one we're considering).
     */

    if (dtm > 0) {
	commit_update(current_index, -dtm, 1, NO_FUTUREMOVE);
    } else if (dtm < 0) {
	commit_update(current_index, -dtm+1, 1, NO_FUTUREMOVE);
    } else if (entriesTable[future_index].does_PTM_win()) {
	commit_update(current_index, -2, 1, NO_FUTUREMOVE);
    } else if (entriesTable[future_index].does_PNTM_win()) {
	commit_update(current_index, 2, 1, NO_FUTUREMOVE);
    } else {
	fatal("Intra-table back prop doesn't match dtm or movecnt\n");
    }
}

void propagate_one_move_within_table(tablebase_t *tb, index_t future_index, local_position_t *position)
{
    int piece;

    propagate_one_minimove_within_table(tb, future_index, position);

    /* En passant:
     *
     * We should never enter this function with en-passant set.
     *
     * However, we may need to consider a bunch of additional positions here that are identical to
     * the base position except that a single one of the pawns on the fourth or fifth ranks was
     * capturable en passant.  Those positions are identical to the base position except that one
     * extra en passant capture is possible.  Since this is intra-table, we don't do captures.  Just
     * back-prop into any extra en passant positions that might exist.
     */

    if (position->en_passant_square != ILLEGAL_POSITION) {
	fatal("position->en_passant_square != ILLEGAL_POSITION in propagate_one_move_within_table()\n");
    }

    for (piece = 0; piece < tb->num_pieces; piece ++) {

	if (tb->pieces[piece].color == position->side_to_move) continue;
	if (tb->pieces[piece].piece_type != PAWN) continue;

	/* I've taken care to update board_vector in the routine that calls here specifically so we
	 * can check for en passant legality here.
	 */

	if ((tb->pieces[piece].color == WHITE)
	    && (ROW(position->piece_position[piece]) == 3)
	    && !(position->board_vector & BITVECTOR(position->piece_position[piece] - 8))
	    && !(position->board_vector & BITVECTOR(position->piece_position[piece] - 16))) {
	    position->set_en_passant_square(position->piece_position[piece] - 8);
	    propagate_one_minimove_within_table(tb, future_index, position);
	}

	if ((tb->pieces[piece].color == BLACK)
	    && (ROW(position->piece_position[piece]) == 4)
	    && !(position->board_vector & BITVECTOR(position->piece_position[piece] + 8))
	    && !(position->board_vector & BITVECTOR(position->piece_position[piece] + 16))) {
	    position->set_en_passant_square(position->piece_position[piece] + 8);
	    propagate_one_minimove_within_table(tb, future_index, position);
	}

	position->clear_en_passant_square();
    }
}

/* back_propagate_index_within_table()
 *
 * Once the final status of an index has been determined, this function back propagates all moves
 * (within the tablebase) from the corresponding position.
 */

void back_propagate_index_within_table(index_t index, int reflection)
{
    local_position_t position(current_tb);
    int piece;
    int dir;
    int origin_square;
    struct movement *movementptr;

    /* This can fail if the reflection isn't valid for this index */

    if (! index_to_local_position(current_tb, index, reflection, &position)) {
#ifdef DEBUG_MOVE
	if (index == DEBUG_MOVE)
	    info("back_propagate_index_within_table; index=%" PRIindex "; reflection %d; INVALID\n",
		 index, reflection);
#endif
	return;
    }

#ifdef DEBUG_MOVE
    if (index == DEBUG_MOVE)
	info("back_propagate_index_within_table; index=%" PRIindex "; reflection %d\n", index, reflection);
#endif

    position.flip_side_to_move();

    /* If there are any en passant capturable pawns in the position, then the last move had to
     * have been a pawn move.  In fact, in this case, we already know exactly what the last move
     * had to have been.
     */

    if (position.en_passant_square != ILLEGAL_POSITION) {

	int en_passant_pawn = -1;

	/* XXX let's store en_passant_pawn in the local position structure and avoid this loop */

	for (piece = 0; piece < current_tb->num_pieces; piece++) {

	    if (current_tb->pieces[piece].color != position.side_to_move) continue;
	    if (current_tb->pieces[piece].piece_type != PAWN) continue;

	    if (((current_tb->pieces[piece].color == WHITE)
		 && (position.piece_position[piece] - 8 == position.en_passant_square))
		|| ((current_tb->pieces[piece].color == BLACK)
		    && (position.piece_position[piece] + 8 == position.en_passant_square))) {
		if (en_passant_pawn != -1) fatal("Two en passant pawns in back prop?!\n");
		en_passant_pawn = piece;
	    }
	}
	if (en_passant_pawn == -1) {
	    fatal("No en passant pawn in back prop!?\n");
	} else {

	    int square;

	    if (current_tb->pieces[en_passant_pawn].color == WHITE)
		square = position.piece_position[en_passant_pawn] - 16;
	    else
		square = position.piece_position[en_passant_pawn] + 16;

	    /* We never back out into a restricted position.  Since we've already decided that this
	     * is the only legal back-move from this point, well...
	     */

	    if (! (current_tb->pieces[en_passant_pawn].semilegal_squares & BITVECTOR(square))) {
		return;
	    }

	    local_position_t new_position = position;

	    new_position.clear_en_passant_square();

	    new_position.move_piece(en_passant_pawn, square);

	    propagate_one_move_within_table(current_tb, index, &new_position);
	}

	return;
    }

    /* foreach (mobile piece of player NOT TO PLAY) { */

    for (piece = 0; piece < current_tb->num_pieces; piece++) {

	/* We've moving BACKWARDS in the game, so we want the pieces of the player who is NOT TO
	 * PLAY here - this is the LAST move we're considering, not the next move.
	 */

	if (current_tb->pieces[piece].color != position.side_to_move)
	    continue;

	origin_square = position.piece_position[piece];

	if (current_tb->pieces[piece].piece_type != PAWN) {

	    for (dir = 0; dir < number_of_movement_directions[current_tb->pieces[piece].piece_type]; dir++) {

		/* What about captures?  Well, first of all, there are no captures here!  We're
		 * moving BACKWARDS in the game... and pieces don't appear out of thin air.
		 * Captures are handled by back-propagation from futurebases, not here in the
		 * movement code.  The piece moving had to come from somewhere, and that somewhere
		 * will now be an empty square, so once we've hit another piece along a movement
		 * vector, there's absolutely no need to consider anything further.
		 */

		for (movementptr = movements[current_tb->pieces[piece].piece_type][origin_square][dir];
		     (movementptr->vector & position.board_vector) == 0;
		     movementptr++) {

		    /* We never back out into a restricted position (obviously) */

		    if (! (current_tb->pieces[piece].semilegal_squares & movementptr->vector)) continue;

		    /* Back stepping a half move here involves several things: flipping the
		     * side-to-move flag, clearing any en passant pawns into regular pawns, moving
		     * the piece (backwards), and considering a bunch of additional positions
		     * identical to the base position except that a single one of the pawns on the
		     * fourth or fifth ranks was capturable en passant.
		     *
		     * Of course, the only way we could have gotten an en passant pawn is if THIS
		     * MOVE created it.  Since this isn't a pawn move, that can't happen.  Checking
		     * additional en passant positions is taken care of in
		     * propagate_one_move_within_table()
		     */

		    local_position_t new_position = position;

		    new_position.move_piece(piece, movementptr->square);

		    propagate_one_move_within_table(current_tb, index, &new_position);
		}
	    }

	} else {

	    /* Usual special case for pawns */

	    for (movementptr = normal_pawn_movements_bkwd[origin_square][current_tb->pieces[piece].color];
		 (movementptr->vector & position.board_vector) == 0;
		 movementptr++) {

		/* We never back out into a restricted position (obviously) */

		if (! (current_tb->pieces[piece].semilegal_squares & movementptr->vector)) continue;

		/* En passant.
		 *
		 * The only way we could have gotten an en passant pawn is if THIS MOVE created it.
		 * We handle that as a special case above, so we shouldn't have to worry about
		 * clearing en passant pawns here - there should be none.  Checking additional en
		 * passant positions is taken care of in propagate_one_move_within_table()
		 *
		 * There are three basic possibilities, depending on the index type:
		 *
		 * 1. Our index has en passant positions for all positions with pawns on the fourth
		 * or fifth rank.  (most of them)
		 *
		 * In this case, we skip all double pawn moves here.  We only consider double pawn
		 * moves when we handle en passant positions at the beginning of this function.
		 *
		 * 2. Our index has no en passant positions. (no-en-passant)
		 *
		 * In this case, we process all double pawn moves here, as there are no en passant
		 * positions to process at the beginning of this function.
		 *
		 * 3. Our index has en passant positions only if a pawn is capturable en
		 * passant. (pawngen)
		 *
		 * In this case, we process here only double pawn moves that do not create en
		 * passant possibilities.
		 *
		 * In short, we're considering a position without en passant set, but from which a
		 * backwards double pawn move is possible.  We want to know if it has a matching
		 * position with en passant set.  If so, we do nothing here, since the double pawn
		 * move will be handled by the en passant position.  If not, we process the double
		 * pawn move here.
		 *
		 * XXX what a mess...
		 */

		if (((movementptr->square - origin_square) == 16)
		    || ((movementptr->square - origin_square) == -16)) {

		    local_position_t new_position = position;

		    if (new_position.side_to_move == WHITE) {
			new_position.set_en_passant_square(origin_square - 8);
		    } else {
			new_position.set_en_passant_square(origin_square + 8);
		    }
		    new_position.flip_side_to_move();

		    bool en_passant_position_exists = (local_position_to_index(current_tb, &new_position) != INVALID_INDEX);

		    if (en_passant_position_exists) continue;
		}

		local_position_t new_position = position;

		new_position.move_piece(piece, movementptr->square);

		propagate_one_move_within_table(current_tb, index, &new_position);
	    }
	}
    }
}

/* In-check tests
 *
 * We use board masks for quickly testing a position to see if we're in check.
 *
 * The test works by indexing an array by piece type, piece square, and king square, which returns a
 * mask that is ANDed with the board mask.  If the result is non-zero, then no capture is possible.
 * If the result is zero, then the king's in check from that piece.  For sliding piece attacks, we
 * use a mask with ones along the path between the two squares.  For positions where capture is
 * always possible, we use a zero mask.  For positions where no capture is possible, we use an
 * all-1s mask.
 *
 * We segregate pawn checks by color; they are a special case.
 *
 * sizeof(board_mask) = 229376, so this array should fit in your average L2 cache (mine is 2 MB)
 *
 * XXX could use this to speed up the routines after PTM_in_check(), but none of them are used
 * during generation, so they're not as important.
 */

uint64_t board_mask[7][64][64];

void initialize_board_masks(void)
{
    /* Initialize entire array with ALL_ONES_BITVECTOR */
    memset(board_mask, 0xff, sizeof(board_mask));

    for (int piece = KING; piece <= PAWN+1; piece++) {

	for (int piece_square = 0; piece_square < 64; piece_square ++) {

	    if (piece < PAWN) {

		for (int dir = 0; dir < number_of_movement_directions[piece]; dir++) {

		    uint64_t mask = 0;

		    for (auto movementptr = movements[piece][piece_square][dir];
			 movementptr->square != -1; movementptr++) {

			board_mask[piece][piece_square][movementptr->square] = mask;

			mask |= movementptr->vector;
		    }

		}

	    } else {
		for (auto movementptr = capture_pawn_movements[piece_square][piece - PAWN];
		     movementptr->square != -1; movementptr++) {

		    board_mask[piece][piece_square][movementptr->square] = 0;
		}
	    }
	}
    }
}

bool PTM_in_check(const tablebase_t *tb, const local_position_t *position)
{
    int king_position = position->piece_position[(position->side_to_move == WHITE) ? tb->white_king : tb->black_king];

    /* The concept of check doesn't exist in suicide - kings are normal pieces */

    if (tb->variant == VARIANT_SUICIDE) return false;

    for (int piece = 0; piece < tb->num_pieces; piece++) {

	/* We only want to consider pieces of the side which is NOT to move... */

	if (tb->pieces[piece].color == position->side_to_move) continue;

	/* We might have removed the piece from the position... */

	if (position->piece_position[piece] == ILLEGAL_POSITION) continue;

	if (tb->pieces[piece].piece_type != PAWN) {

	    if ((board_mask[tb->pieces[piece].piece_type][position->piece_position[piece]][king_position]
		 & position->board_vector) == 0) return true;

	} else {

	    if (board_mask[tb->pieces[piece].piece_type + tb->pieces[piece].color][position->piece_position[piece]][king_position]
		== 0) return true;

	}
    }

    return false;
}

bool global_PTM_in_check(global_position_t *position)
{
    int piece_type;
    int piece_color = 1 - position->side_to_move;
    int square;
    int dir;
    struct movement *movementptr;

    if (position->variant == VARIANT_SUICIDE) return false;

    for (square = 0; square < 64; square ++) {

	/* We only want to consider pieces of the side which is NOT to move... */

	for (piece_type = 0; piece_type < NUM_PIECES; piece_type ++) {
	    if (position->board[square] == global_pieces[piece_color][piece_type]) break;
	}
	if (piece_type == NUM_PIECES) continue;

	if (piece_type != PAWN) {

	    for (dir = 0; dir < number_of_movement_directions[piece_type]; dir++) {

		for (movementptr = movements[piece_type][square][dir];
		     ((movementptr->square != -1) && (position->board[movementptr->square] == 0));
		     movementptr++) {
		}

		/* Now check to see if the movement ended because we hit against the king
		 * of the opposite color.  If so, we're in check.
		 */

		if ((position->side_to_move == WHITE) && (position->board[movementptr->square] == 'K'))
		    return true;
		if ((position->side_to_move == BLACK) && (position->board[movementptr->square] == 'k'))
		    return true;

	    }
	} else {
	    for (movementptr = capture_pawn_movements[square][piece_color];
		 movementptr->square != -1;
		 movementptr++) {

		if ((position->side_to_move == WHITE) && (position->board[movementptr->square] == 'K'))
		    return true;
		if ((position->side_to_move == BLACK) && (position->board[movementptr->square] == 'k'))
		    return true;

	    }
	}
    }

    return false;
}

bool global_PNTM_in_check(global_position_t *position)
{
    int piece_type;
    int piece_color = position->side_to_move;
    int square;
    int dir;
    struct movement *movementptr;

    if (position->variant == VARIANT_SUICIDE) return false;

    for (square = 0; square < 64; square ++) {

	/* We only want to consider pieces of the side which is to move... */

	for (piece_type = 0; piece_type < NUM_PIECES; piece_type ++) {
	    if (position->board[square] == global_pieces[piece_color][piece_type]) break;
	}
	if (piece_type == NUM_PIECES) continue;

	if (piece_type != PAWN) {

	    for (dir = 0; dir < number_of_movement_directions[piece_type]; dir++) {

		for (movementptr = movements[piece_type][square][dir];
		     ((movementptr->square != -1) && (position->board[movementptr->square] == 0));
		     movementptr++) {
		}

		/* Now check to see if the movement ended because we hit against the king
		 * of the opposite color.  If so, we're in check.
		 */

		if (movementptr->square != -1) {
		    if ((position->side_to_move == WHITE) && (position->board[movementptr->square] == 'k'))
			return true;
		    if ((position->side_to_move == BLACK) && (position->board[movementptr->square] == 'K'))
			return true;
		}

	    }
	} else {
	    for (movementptr = capture_pawn_movements[square][piece_color];
		 movementptr->square != -1;
		 movementptr++) {

		if ((position->side_to_move == WHITE) && (position->board[movementptr->square] == 'k'))
		    return true;
		if ((position->side_to_move == BLACK) && (position->board[movementptr->square] == 'K'))
		    return true;

	    }
	}
    }

    return false;
}

bool PNTM_in_check(tablebase_t *tb, local_position_t *position)
{
    int piece;
    int dir;
    int origin_square;
    struct movement *movementptr;

    if (tb->variant == VARIANT_SUICIDE) return false;

    for (piece = 0; piece < tb->num_pieces; piece++) {

	/* We only want to consider pieces of the side which is to move... */

	if (tb->pieces[piece].color != position->side_to_move) continue;

	origin_square = position->piece_position[piece];

	if (tb->pieces[piece].piece_type != PAWN) {

	    for (dir = 0; dir < number_of_movement_directions[tb->pieces[piece].piece_type]; dir++) {

		for (movementptr = movements[tb->pieces[piece].piece_type][origin_square][dir];
		     (movementptr->vector & position->board_vector) == 0;
		     movementptr++) {
		}

		/* Now check to see if the movement ended because we hit against the king
		 * of the opposite color.  If so, we're in check.
		 */

		if ((position->side_to_move == WHITE)
		    && (movementptr->square == position->piece_position[tb->black_king])) return true;

		if ((position->side_to_move == BLACK)
		    && (movementptr->square == position->piece_position[tb->white_king])) return true;

	    }
	} else {
	    for (movementptr = capture_pawn_movements[origin_square][tb->pieces[piece].color];
		 movementptr->square != -1;
		 movementptr++) {

		if ((position->side_to_move == WHITE)
		    && (movementptr->square == position->piece_position[tb->black_king])) return true;

		if ((position->side_to_move == BLACK)
		    && (movementptr->square == position->piece_position[tb->white_king])) return true;

	    }
	}
    }

    return false;
}

/* initialize_tablebase()
 *
 * This is another critical function; don't be deceived by the tame word 'initialize'.
 *
 * We determine that a position is won for the player not to move (PNTM) if all possible moves (of
 * the player to move) lead to a won game for PNTM.  We count down this total during back
 * propagation, so it stands to reason that we need an accurate count to start with.  Thus the
 * importance of this function.
 *
 * We don't count moves into check at all.
 *
 * Basically, there are two types of moves we need to consider in each position:
 *
 * 1. non-capture, non-promotion, non-restricted moves
 *
 * We just add these up and then count them down during intra-table propagation, depending on the
 * integrity of the program's algorithm to make sure that every move counted forward gets considered
 * as a move backward.
 *
 * 2. everything else (futuremoves)
 *
 * These always lead to a different tablebase (a futurebase).  The only way we handle them is
 * through inter-table back propagation.  We keep a seperate count of futuremoves because, unlike
 * intratable moves, we might miss some of these moves if we don't have a complete set of
 * futurebases.  So we count futuremoves by themselves (as well as part of the standard count), and
 * count them down normally during a single sweep through our futurebases.  If that takes care of
 * everything fine.  Otherwise, during our first pass through the current tablebase, we'll find that
 * some of the futuremoves remain unaccounted for.  If they occur with the "good guys" as PTM, we
 * just double-check that the restriction is OK, subtract the remaining futuremoves out from the
 * standard count, and keep going.  But if the "bad guys" are PTM, then the position has to be
 * assumed won for PTM.
 *
 */

/* There are three different variants of initialize_tablebase_entry(), that differ in their third
 * argument.  The first one, that does all the work, takes a const local_position_t to protect
 * against bugs in that code, the second takes a non-const local_position_t and performs an extra
 * index_to_local_position conversion on it, and the third takes nothing and creates a
 * local_position_t on the stack.  The third is deprecated since we now like to call
 * index_to_local_position on an existing position, if possible, because it's often faster
 * than creating a new position from scratch.
 */

futurevector_t initialize_tablebase_entry(const tablebase_t *tb, const index_t index, const local_position_t &position)
{
    /* Now we need to count moves.  FORWARD moves. */
    unsigned int movecnt = 0;
    unsigned int capturecnt = 0;
    unsigned int futuremovecnt = 0;
    futurevector_t futurevector = 0;
    futurevector_t capture_futurevector = 0;

    bool concede_prune = false;
    bool resign_prune = false;

    /* En passant:
     *
     * We're just counting moves here.  In particular, we don't compute the indices of the resulting
     * positions.  If we did, we'd have to worry about clearing en passant status from any of fourth
     * or fifth rank pawns, but we don't have to worry about it.
     *
     * We do have to count one or two possible extra en passant pawn captures, though...
     */

    for (int piece = 0; piece < tb->num_pieces; piece++) {

	/* We only want to consider pieces of the side which is to move... */

	if (tb->pieces[piece].color != position.side_to_move) continue;

	int origin_square = position.piece_position[piece];

	if (tb->pieces[piece].piece_type != PAWN) {

	    for (int dir = 0; dir < number_of_movement_directions[tb->pieces[piece].piece_type]; dir++) {

		struct movement * movementptr;

		for (movementptr = movements[tb->pieces[piece].piece_type][origin_square][dir];
		     (movementptr->vector & position.board_vector) == 0;
		     movementptr++) {

		    /* Move the piece, so we can test the new position for check */

		    local_position_t new_position = position;

		    new_position.move_piece(piece, movementptr->square);

		    /* If we're NOT moving into check AND the piece is moving outside its legal
		     * squares AND we can't permute the pieces into a position where everything is
		     * legal, we regard this as a futuremove (since it will require back prop from
		     * futurebases).  We could just check if local_position_to_index() returns a
		     * valid index, but checking the legal_squares bitvector first makes this a
		     * little faster.
		     */

		    if (! PTM_in_check(tb, &new_position)) {

			if (!(tb->pieces[piece].legal_squares & BITVECTOR(movementptr->square))
			    && (local_position_to_index(tb, &new_position) == INVALID_INDEX)) {

			    if (futuremoves[piece][movementptr->square] == DISCARD_FUTUREMOVE) {
				/* it's a discard - decrement movecnt so net change is zero */
				movecnt --;
			    } else if (futuremoves[piece][movementptr->square] == CONCEDE_FUTUREMOVE) {
				concede_prune = true;
			    } else if (futuremoves[piece][movementptr->square] == RESIGN_FUTUREMOVE) {
				resign_prune = true;
			    } else if (futuremoves[piece][movementptr->square] < 0) {
				global_position_t global;
				index_to_global_position(tb, index, &global);
				fatal("No futuremove: %s %c%c%c\n", global_position_to_FEN(&global),
				      piece_char[tb->pieces[piece].piece_type],
				      'a' + COL(movementptr->square), '1' + ROW(movementptr->square));
			    } else if (futurevector
				       & FUTUREVECTOR(futuremoves[piece][movementptr->square])) {
				fatal("Duplicate futuremove!\n");
			    } else {
				futurevector |= FUTUREVECTOR(futuremoves[piece][movementptr->square]);
				futuremovecnt ++;
			    }
			}

			movecnt ++;
		    }

		}

		/* Now check to see if the movement ended because we hit against another piece of
		 * the opposite color.  If so, add another move for the capture.  As before, ignore
		 * moves into check.
		 *
		 * Actually, we check to see that we DIDN'T hit a piece of our OWN color.  The
		 * difference is that this way we don't register a capture if we hit the end of the
		 * list of movements in a given direction.
		 *
		 * We also check to see if the capture was against the enemy king! in which case
		 * this position is a PNTM-mated.
		 */

		if ((movementptr->vector & position.PTM_vector) == 0) {

		    int captured_piece;

		    for (captured_piece = 0; captured_piece < tb->num_pieces; captured_piece ++) {
			if (movementptr->square == position.piece_position[captured_piece]) {
			    if ((captured_piece == tb->black_king) || (captured_piece == tb->white_king)) {
				entriesTable->initialize_entry_with_PNTM_mated(index);
				return 0;
			    }

			    local_position_t new_position = position;

			    new_position.capture_piece(piece, captured_piece);

			    if (! PTM_in_check(tb, &new_position)) {

				if (futurecaptures[piece][captured_piece] == DISCARD_FUTUREMOVE) {
				    /* discard prune - do nothing */
				} else if (futurecaptures[piece][captured_piece] == CONCEDE_FUTUREMOVE) {
				    concede_prune = true;
				} else if (futurecaptures[piece][captured_piece] == RESIGN_FUTUREMOVE) {
				    resign_prune = true;
				} else if (futurecaptures[piece][captured_piece] < 0) {
				    global_position_t global;
				    index_to_global_position(tb, index, &global);
				    fatal("No futuremove: %s %cx%c\n", global_position_to_FEN(&global),
					  piece_char[tb->pieces[piece].piece_type],
					  piece_char[tb->pieces[captured_piece].piece_type]);
				} else if (futurevector & FUTUREVECTOR(futurecaptures[piece][captured_piece])) {
				    fatal("Duplicate futuremove!\n");
				} else {
				    capture_futurevector |= FUTUREVECTOR(futurecaptures[piece][captured_piece]);
				    futurevector |= FUTUREVECTOR(futurecaptures[piece][captured_piece]);
				    futuremovecnt ++;
				    capturecnt ++;
				    movecnt ++;
				}
			    }

			    break;
			}
		    }
		    if (captured_piece == tb->num_pieces) {
			fatal("Couldn't match capture!\n");
		    }
		}
	    }

	} else {

	    /* Pawns, as always, are special */

	    for (auto movementptr = normal_pawn_movements[origin_square][tb->pieces[piece].color];
		 (movementptr->vector & position.board_vector) == 0;
		 movementptr++) {

		local_position_t new_position = position;

		new_position.move_piece(piece, movementptr->square);

		/* What about pawn promotions here?  Well, we're looking to see if the moving side
		 * is in check after the pawn move, and the only way the pawn could affect this is
		 * by blocking the check.  It still blocks no matter what it promotes into, so we
		 * don't have to distinguish between promotion and non-promotion moves here.
		 */

		if (! PTM_in_check(tb, &new_position)) {

		    /* If the piece is a pawn and we're moving to the last rank, then this has to be
		     * a promotion move, in fact, promotion_possibilities moves.  (queen, knight,
		     * maybe rook and bishop, king for suicide).  As such, they will require back
		     * propagation from futurebases and must therefore be flagged as futuremoves.
		     */

		    if ((ROW(movementptr->square) == 7) || (ROW(movementptr->square) == 0)) {

			for (int promotion = 0; promotion < promotion_possibilities; promotion ++) {

			    if (promotions[piece][promotion] == DISCARD_FUTUREMOVE) {
				/* discard prune - do nothing */
			    } else if (promotions[piece][promotion] == CONCEDE_FUTUREMOVE) {
				concede_prune = true;
			    } else if (promotions[piece][promotion] == RESIGN_FUTUREMOVE) {
				resign_prune = true;
			    } else if (promotions[piece][promotion] < 0) {
				global_position_t global;
				index_to_global_position(tb, index, &global);
				fatal("No futuremove: %s %c=%c\n", global_position_to_FEN(&global),
				      piece_char[tb->pieces[piece].piece_type], piece_char[promoted_pieces[promotion]]);
			    } else if (futurevector & FUTUREVECTOR(promotions[piece][promotion])) {
				global_position_t global;
				index_to_global_position(tb, index, &global);
				fatal("Duplicate futuremove: %s %s\n", global_position_to_FEN(&global),
				      movestr[tb->pieces[piece].color][promotions[piece][promotion]]);
			    } else {
				futurevector |= FUTUREVECTOR(promotions[piece][promotion]);
				futuremovecnt ++;
				movecnt ++;
			    }
			}

		    } else {

			/* If a piece is moving outside its legal squares AND we can't permute the
			 * pieces into a position where everything is legal, we regard this as a
			 * futuremove (since it will require back prop from futurebases).
			 */

			if (!(tb->pieces[piece].legal_squares & BITVECTOR(movementptr->square))
			    && (local_position_to_index(tb, &new_position) == INVALID_INDEX)) {

			    if (futuremoves[piece][movementptr->square] == DISCARD_FUTUREMOVE) {
				/* discard prune */
				movecnt --;
			    } else if (futuremoves[piece][movementptr->square] == CONCEDE_FUTUREMOVE) {
				concede_prune = true;
			    } else if (futuremoves[piece][movementptr->square] == RESIGN_FUTUREMOVE) {
				resign_prune = true;
			    } else if (futuremoves[piece][movementptr->square] < 0) {
				global_position_t global;
				index_to_global_position(tb, index, &global);
				fatal("No futuremove: %s %c%c%c\n", global_position_to_FEN(&global),
				      piece_char[tb->pieces[piece].piece_type],
				      'a' + COL(movementptr->square), '1' + ROW(movementptr->square));
			    } else if (futurevector
				       & FUTUREVECTOR(futuremoves[piece][movementptr->square])) {
				fatal("Duplicate futuremove!\n");
			    } else {
				futurevector |= FUTUREVECTOR(futuremoves[piece][movementptr->square]);
				futuremovecnt ++;
			    }
			}

			movecnt ++;
		    }
		}
	    }


	    /* Pawn captures.
	     *
	     * In this part of the code, we're just counting forward moves, and all captures are
	     * futurebase moves, so the only difference to us whether this is a promotion move or
	     * not is how many futuremoves get recorded.
	     */

	    struct movement * movementptr;

	    for (movementptr = capture_pawn_movements[origin_square][tb->pieces[piece].color];
		 movementptr->square != -1;
		 movementptr++) {

		/* If we're capturing to the last rank, then this has to be a promotion move, in
		 * fact, promotion_possibilities moves.
		 */

		bool is_promotion_capture =
		    ((ROW(movementptr->square) == 7) || (ROW(movementptr->square) == 0));

		/* A special check for en passant captures.  */

		if (movementptr->square == position.en_passant_square) {

		    /* XXX record en_passant_pawn in local position to avoid this loop */

		    for (int captured_piece = 0; captured_piece < tb->num_pieces; captured_piece ++) {
			//if ((i == tb->white_king) || (i == tb->black_king)) continue;
			if (movementptr->square + (tb->pieces[piece].color == WHITE ? -8 : 8)
			    == position.piece_position[captured_piece]) {

			    local_position_t new_position = position;

			    new_position.move_piece(captured_piece, position.en_passant_square);
			    new_position.capture_piece(piece, captured_piece);

			    if (! PTM_in_check(tb, &new_position)) {
				if (futurecaptures[piece][captured_piece] == DISCARD_FUTUREMOVE) {
				    /* discard prune - do nothing */
				} else if (futurecaptures[piece][captured_piece] == CONCEDE_FUTUREMOVE) {
				    concede_prune = true;
				} else if (futurecaptures[piece][captured_piece] == RESIGN_FUTUREMOVE) {
				    resign_prune = true;
				} else if (futurecaptures[piece][captured_piece] < 0) {
				    global_position_t global;
				    index_to_global_position(tb, index, &global);
				    fatal("No futuremove: %s %cx%c\n", global_position_to_FEN(&global),
					  piece_char[tb->pieces[piece].piece_type],
					  piece_char[tb->pieces[captured_piece].piece_type]);
				} else if (futurevector & FUTUREVECTOR(futurecaptures[piece][captured_piece])) {
				    fatal("Duplicate futuremove!\n");
				} else {
				    capture_futurevector |= FUTUREVECTOR(futurecaptures[piece][captured_piece]);
				    futurevector |= FUTUREVECTOR(futurecaptures[piece][captured_piece]);
				    futuremovecnt ++;
				    capturecnt ++;
				    movecnt ++;
				}
			    }

			    break;
			}
		    }
		    continue;
		}

		if (((movementptr->vector & position.board_vector) == 0)
		    || ((movementptr->vector & position.PTM_vector) != 0)) continue;

		int captured_piece;

		for (captured_piece = 0; captured_piece < tb->num_pieces; captured_piece ++) {
		    if (movementptr->square == position.piece_position[captured_piece]) {
			if ((captured_piece == tb->black_king) || (captured_piece == tb->white_king)) {
			    entriesTable->initialize_entry_with_PNTM_mated(index);
			    return 0;
			}

			local_position_t new_position = position;

			new_position.capture_piece(piece, captured_piece);

			if (! PTM_in_check(tb, &new_position)) {
			    if (! is_promotion_capture) {
				if (futurecaptures[piece][captured_piece] == DISCARD_FUTUREMOVE) {
				    /* discard prune - do nothing */
				} else if (futurecaptures[piece][captured_piece] == CONCEDE_FUTUREMOVE) {
				    concede_prune = true;
				} else if (futurecaptures[piece][captured_piece] == RESIGN_FUTUREMOVE) {
				    resign_prune = true;
				} else if (futurecaptures[piece][captured_piece] < 0) {
				    global_position_t global;
				    index_to_global_position(tb, index, &global);
				    fatal("No futuremove: %s %cx%c\n", global_position_to_FEN(&global),
					  piece_char[tb->pieces[piece].piece_type],
					  piece_char[tb->pieces[captured_piece].piece_type]);
				} else if (futurevector & FUTUREVECTOR(futurecaptures[piece][captured_piece])) {
				    fatal("Duplicate futuremove!\n");
				} else {
				    capture_futurevector |= FUTUREVECTOR(futurecaptures[piece][captured_piece]);
				    futurevector |= FUTUREVECTOR(futurecaptures[piece][captured_piece]);
				    futuremovecnt ++;
				    capturecnt ++;
				    movecnt ++;
				}
			    } else {

				for (int promotion = 0; promotion < promotion_possibilities; promotion ++) {

				    if (promotion_captures[piece][captured_piece][promotion] == DISCARD_FUTUREMOVE) {
					/* discard prune - do nothing */
				    } else if (promotion_captures[piece][captured_piece][promotion] == CONCEDE_FUTUREMOVE) {
					concede_prune = true;
				    } else if (promotion_captures[piece][captured_piece][promotion] == RESIGN_FUTUREMOVE) {
					resign_prune = true;
				    } else if (promotion_captures[piece][captured_piece][promotion] < 0) {
					global_position_t global;
					index_to_global_position(tb, index, &global);
					fatal("No futuremove: %s %cx%c=%c\n", global_position_to_FEN(&global),
					      piece_char[tb->pieces[piece].piece_type],
					      piece_char[tb->pieces[captured_piece].piece_type],
					      piece_char[promoted_pieces[promotion]]);
				    } else if (futurevector & FUTUREVECTOR(promotion_captures[piece][captured_piece][promotion])) {
					fatal("Duplicate futuremove!\n");
				    } else {
					capture_futurevector |= FUTUREVECTOR(promotion_captures[piece][captured_piece][promotion]);
					futurevector |= FUTUREVECTOR(promotion_captures[piece][captured_piece][promotion]);
					futuremovecnt ++;
					capturecnt ++;
					movecnt ++;
				    }
				}
			    }
			}

			break;
		    }
		}

		if (captured_piece == tb->num_pieces) {
		    fatal("Couldn't match pawn capture!\n");
		}

	    }

	}

    }

    if (concede_prune) {
	entriesTable->initialize_entry_with_concede(index);
	return 0;
    }

    if (resign_prune) {
	entriesTable->initialize_entry_with_resign(index);
	return 0;
    }

    /* Finally, if every possible moves leads us into check, we determine if we're in check, being
     * the difference between this being checkmate or stalemate.  In suicide analysis, a stalemate
     * is a win for the stalemated player (international rules).
     */

    if (movecnt == 0) {

	if (tb->variant == VARIANT_SUICIDE) {
	    entriesTable->initialize_entry_with_PNTM_mated(index);
	} else if (PTM_in_check(tb, &position)) {
	    entriesTable->initialize_entry_with_PTM_mated(index);
	} else {
	    entriesTable->initialize_entry_with_stalemate(index);
	}
	return 0;

    } else {

	total_moves += movecnt;
	total_futuremoves += futuremovecnt;

	/* In suicide, captures are forced, so if any captures are possible they are our only moves.
	 * Of course, if we can capture the opponent's last piece, then we win!
	 */

	if ((tb->variant == VARIANT_SUICIDE) && (capturecnt != 0)) {
	    movecnt = capturecnt;
	    futurevector = capture_futurevector;
	}

	/* Symmetry and multiplicity.  If we're using a symmetric index, then there might be more
	 * than one actual board position that corresponds to a given index value.  The number of
	 * non-identical board positions for a given index is called its multiplicity.  So here we
	 * multiply the movecnt by the multiplicity of the position to get the total number of moves
	 * out of all possible positions that correspond to this index.
	 *
	 * Actually, when computing position.multiplicity, we ignore horizontal and vertical
	 * symmetry because they always result in doubled (or quadrupled) board positions.  Diagonal
	 * symmetry is more difficult to handle because the pieces along the diagonal don't move
	 * when you reflect the board.  So we need to use position.multiplicity to distinguish
	 * between the two kings being on the a1/h8 diagonal (multiplicity 1), and one of them being
	 * off the diagonal (multiplicity 2).
	 */

	entriesTable->initialize_entry_with_movecnt(index, movecnt * position.multiplicity);

	entriesTable[index].set_capture_possible_flag((capturecnt != 0));

#ifdef DEBUG_MOVE
	if (index == DEBUG_MOVE) {
	    /* other fields were printed by DEBUG_MOVE statement in initialize_entry() */
	    info("   futurevector " FUTUREVECTOR_HEX_FORMAT "\n", futurevector);
	}
#endif

	return futurevector;
    }
}

futurevector_t initialize_tablebase_entry(const tablebase_t *tb, const index_t index, local_position_t &position)
{
#ifdef DEBUG_MOVE
    if (index == DEBUG_MOVE)
	info("Initializing %" PRIindex "\n", index);
#endif

    print_progress_dot(current_tb);

    if (! index_to_local_position(tb, index, REFLECTION_NONE, &position)) {

	entriesTable->initialize_entry_as_illegal(index);
	return 0;

    } else {

	return initialize_tablebase_entry(tb, index, (const local_position_t) position);

    }
}

futurevector_t initialize_tablebase_entry(tablebase_t *tb, index_t index)
{
    local_position_t position(tb);

    return initialize_tablebase_entry(tb, index, position);
}

/* Tablebase initialization is the first important place where we can use threads to speed things up
 * on a multi-processor machine, though my experience is that actual gains are highly architecture
 * specific.  Since initialization only touches single entries in the tablebase (no propagation at
 * this point), thread synchronization is fairly trivial.  We do initialize entire sections instead
 * of individual entries to avoid processors fighting over cache lines.
 */

void initialize_tablebase_section(index_t start_index, index_t end_index)
{
    index_t index;
    local_position_t position(current_tb);

    for (index=start_index; index <= end_index; index++) {
	long long bit_offset = ((long long)index * current_tb->futurevector_bits);

	set_unsigned_int_field(current_tb->futurevectors, bit_offset, current_tb->futurevector_bits,
			       initialize_tablebase_entry(current_tb, index, position));
    }
}

void initialize_tablebase(void)
{
    std::thread t[num_threads];
    unsigned int thread;
    index_t block_size = current_tb->num_indices /num_threads;

    reset_progress_dots(current_tb);

    for (thread = 0; thread < num_threads; thread ++) {
	index_t start_index = thread*block_size;
	index_t end_index;

	if (thread != num_threads-1) {
	    end_index = (thread+1)*block_size - 1;
	} else {
	    end_index = current_tb->num_indices - 1;
	}

	t[thread] = std::thread(initialize_tablebase_section, start_index, end_index);
    }

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread].join();
    }
}

/* Intra-table propagation is (almost) trivial.  Keep making passes over the tablebase first until
 * we've processed everything from the futurebases, then until no more progress can be made.  We
 * don't even have to make every pass, just the ones that have mates in the entries table (and we
 * track that as we finalize the mates).  Once we're past all the mates that came in from the
 * futurebases (that's what max_tracked_dtm and min_tracked_dtm show), the only way we can have new
 * mates is by following a line that's completely within this tablebase, so we keep going until one
 * of the passes didn't finalize any positions.
 *
 * We have to be a little bit careful when we're using proptables, since we can have stuff queued up
 * in the current proptable that hasn't be reflected in the positive_passes_needed[] and
 * negative_passes_needed[] arrays, so if we're using proptables, then we ALWAYS run the next pass
 * after a pass that finalized some positions.
 */

void propagate_all_moves_within_tablebase(tablebase_t *tb)
{
    int dtm = 1;
    int positions_finalized_on_last_pass = 0;

    /* DTM 1 positions are illegal (PNTM is in check), so back prop from these positions is not
     * needed or desired because we don't count moves into check as part of movecnt.
     */

    positive_passes_needed[1] = false;

    /* If we're tracking DTM, then run at least until we've looked at all the DTM values that came
     * in from the futurebases.
     */

    if (tracking_dtm) {

	while ((dtm <= max_tracked_dtm) || (-dtm >= min_tracked_dtm)) {

	    /* PTM wins */
	    if (((dtm <= max_tracked_dtm) && positive_passes_needed[dtm])
		|| (positions_finalized_on_last_pass > 0))
		positions_finalized_on_last_pass = propagation_pass(dtm);
	    else
		positions_finalized_on_last_pass = 0;

	    if (dtm <= max_tracked_dtm) positive_passes_needed[dtm] = false;

	    /* PNTM wins */
	    if (((-dtm >= min_tracked_dtm) && negative_passes_needed[dtm])
		|| (positions_finalized_on_last_pass > 0))
		positions_finalized_on_last_pass = propagation_pass(-dtm);
	    else
		positions_finalized_on_last_pass = 0;

	    if (-dtm >= min_tracked_dtm) negative_passes_needed[dtm] = false;

	    dtm ++;
	}

    } else {

	positions_finalized_on_last_pass = 1;

    }

    /* Now keep running until there's nothing left to process */

    while (1) {

	/* PTM wins */
	if (positions_finalized_on_last_pass > 0)
	    positions_finalized_on_last_pass = propagation_pass(dtm);
	else break;

	/* PNTM wins */
	if (positions_finalized_on_last_pass > 0)
	    positions_finalized_on_last_pass = propagation_pass(-dtm);
	else break;

	dtm ++;
    }

}

/* The 'filename' argument passed in here can either be a filename or a URL.  We don't distinguish
 * between them except by looking at their prefix (though it would be easy to add an extra flag
 * argument to do so), so hopefully nobody will try to create tablebases starting with 'ftp:'.  Much
 * of the error checking on 'filename' is done by the caller, since we'd like that error checking to
 * occur prior to a time consuming generation run, rather than when we're ready to write the
 * finished product out.
 *
 * XXX put URL support back in
 *
 * XXX figure out boost iostreams error handling
 */

void write_tablebase_to_file(tablebase_t *tb, Glib::ustring filename)
{
    xmlpp::Document * doc;
    int dtm_bits;
    int size;
    int padded_size;
    char entrybuf[MAX_FORMAT_BYTES];

    for (dtm_bits = 1; (1 << (dtm_bits - 1) <= max_dtm) || (1 << (dtm_bits - 1) < -min_dtm); dtm_bits ++);

    if ((tb->format.dtm_offset != -1) && (tb->format.dtm_bits == 0)) {
	tb->format.dtm_bits = dtm_bits;
	tb->format.bits += dtm_bits;
    } else if (tb->format.dtm_bits > 0) {
	if (tb->format.dtm_bits < dtm_bits) {
	    fatal("Requested DTM field size too small\n");
	    terminate();
	}
    }

    doc = finalize_XML_header(tb);

    /* We want at least one zero byte after the XML header, because that's how we figure out where
     * it ends when we read it back in, and I also want to align the tablebase on a four-byte
     * boundary for the hell of it.  (size+5)&(~3) achieves these goals.  I then modify the XML
     * header with the updated string that gives the offset to the tablebase, and make sure that its
     * size hasn't changed.
     */

    size = doc->write_to_string().length();

    padded_size = (size+5)&(~3);

    doc->get_root_node()->set_attribute("offset", boost::lexical_cast<std::string>(padded_size));

    size = doc->write_to_string().length();

    padded_size = (size+5)&(~3);

    doc->get_root_node()->set_attribute("offset", boost::lexical_cast<std::string>(padded_size));

    size = doc->write_to_string().length();

    if (padded_size != ((size+5)&(~3))) {
	fatal("sizes don't match in write_tablebase_to_file\n");
	terminate();
    }

    info("Writing '%s'\n", filename.c_str());

    std::ofstream output_file;
    output_file.exceptions(std::ofstream::failbit | std::ofstream::badbit);
    output_file.open(filename, std::ofstream::out | std::ofstream::binary | std::ofstream::trunc);

    io::filtering_ostream outstream;

    outstream.push(io::gzip_compressor());
    outstream.push(output_file);

    /* First we write an XML header */

    doc->write_to_stream(outstream);

    for (; size < padded_size; size ++) outstream << '\0';

    /* Then we write the tablebase data */

    for (index_t index = 0; index < tb->num_indices; index ++) {

#ifdef DEBUG_MOVE
	if (index == DEBUG_MOVE) {
	    info("Writing %" PRIindex ": DTM %d; movecnt %d\n", index,
		 entriesTable[index].get_DTM(), entriesTable[index].get_movecnt());
	}
#endif

	/* Right now, there's only three possible fields in the tablebase format itself (as opposed
	 * to the intermediate entries and proptable formats) - dtm, basic, and flag.
	 */

	if (tb->format.dtm_bits > 0) {
	    set_int_field(entrybuf,
			  tb->format.dtm_offset + ((index % 8) * tb->format.bits),
			  tb->format.dtm_bits,
			  entriesTable[index].get_DTM());
	}

	if (tb->format.basic_offset != -1) {
	    int basic;

	    /* "3" is reserved to flag an illegal position, but we don't do that now, because we
	     * don't distinguish illegal positions from draws - see initialize_entry_as_illegal()
	     */

	    if (entriesTable[index].does_PTM_win()) {
		basic = 1;
	    } else if (entriesTable[index].does_PNTM_win()) {
		basic = 2;
	    } else {
		basic = 0;
	    }
	    set_unsigned_int_field(entrybuf,
				   tb->format.basic_offset + ((index % 8) * tb->format.bits), 2,
				   basic);
	}

	switch (tb->format.flag_type) {
	case FORMAT_FLAG_WHITE_WINS:
	    set_bit_field(entrybuf,
			  tb->format.flag_offset + ((index % 8) * tb->format.bits),
			  (index_to_side_to_move(tb, index) == WHITE)
			  ? entriesTable[index].does_PTM_win() : entriesTable[index].does_PNTM_win());
	    break;
	case FORMAT_FLAG_WHITE_DRAWS:
	    set_bit_field(entrybuf,
			  tb->format.flag_offset + ((index % 8) * tb->format.bits),
			  (index_to_side_to_move(tb, index) == WHITE)
			  ? ! entriesTable[index].does_PNTM_win() : ! entriesTable[index].does_PTM_win());
	    break;
	}

	/* If the next index will be aligned on a byte boundary, write out what we've buffered.  The
	 * logic here is that if each index requires 'bits' bits, we write eight indices at a time
	 * and that requires exactly 'bits' bytes.
	 */

	if ((index % 8 == 7) || (index == tb->num_indices - 1)) {
	    outstream.write(entrybuf, tb->format.bits);
	}
    }

    /* File close is done implicitly by the destructor. */
}

/* The "master routine" for tablebase generation.
 *
 * Many of these subroutines have already printed error messages of their own if they return
 * an error indication, which is why we just silently return in many cases.
 */

bool generate_tablebase_from_control_file(char *control_filename, Glib::ustring output_filename)
{
    tablebase_t *tb;
    xmlpp::NodeSet result;
    size_t futurevector_bytes;

#if defined(RLIMIT_MEMLOCK) && LOCK_MEMORY
    struct rlimit rlimit;
#endif

    tb = parse_XML_control_file(control_filename);
    if (tb == nullptr) return false;

    /* Need this no matter what.  I want to replace it with a global static tablebase for everything. */
    current_tb = tb;
    info("Total indices: %" PRIindex "\n", tb->num_indices);

    /* Figure out where we want to write the finished product. */

    result = tb->xml->get_root_node()->find("//output");
    if (result.empty() && output_filename.empty()) {
	fatal("Output filename must be specified either on command line or with <output> tag\n");
	return false;
    }
    if (! result.empty()) {
	if (! output_filename.empty()) {
	    warning("Output filename specified on command line overrides <output> tag\n");
	} else {
	    // XXX use C++ casts
	    output_filename = ((xmlpp::Element *) result[0])->get_attribute_value("filename");
	    if (output_filename.empty()) {
		output_filename = ((xmlpp::Element *) result[0])->get_attribute_value("url");
	    }
	}
    }

    if (output_filename.empty()) {
	fatal("No output filename or URL specified\n");
	return false;
    }

    // XXX make case insensitive

    if (output_filename.substr(0,5) == "http:") {
	fatal("http URLs currently unsupported for tablebase I/O\n");
	return false;
    }

    if (output_filename.substr(0,4) == "ftp:") {
	fatal("ftp URLs currently unsupported for tablebase I/O\n");
	return false;
    }

    int proptable_size_in_XML = eval_to_number_or_zero(tb->xml->get_root_node(), "//enable-proptables/@MB");
    if (proptable_size_in_XML > 0) {
	if (using_proptables) {
	    warning("Proptable size specified on command line (%zd MB) overrides <enable-proptables> tag\n", proptable_MBs);
	} else {
	    using_proptables = true;
	    proptable_MBs = proptable_size_in_XML;
	}
    }

    if (! preload_all_futurebases(tb)) return false;
    assign_numbers_to_futuremoves(tb);
    if (! compute_pruned_futuremoves(tb)) return false;
    if (! check_pruning(tb)) return false;
    optimize_futuremoves(tb);
    print_futuremoves();

    if (! check_1000_indices(tb)) return false;
    if (! check_1000_positions(tb)) return false;

    /* This actually initializes the statistics arrays the first time it's called, and it
     * initializes for 100 passes, so these first few passes below here don't need any extra checks
     * to see if they would overflow the arrays.
     */
    expand_per_pass_statistics();

    /* Part of preloading the futurebases was to compute the smallest and largest DTMs in them, so
     * we now know what the sizes of these two arrays have to be.
     */
    positive_passes_needed = new bool[max_tracked_dtm + 1] ();
    negative_passes_needed = new bool[-min_tracked_dtm + 1] ();

    if (!using_proptables) {

	/* No proptables.  Allocate a futurevectors array, initialize the tablebase, back propagate
	 * the futurebases (noting which futuremoves have been handled in the futurevectors array),
	 * and run through the futurevectors array checking for unhandled futuremoves.
	 */

	entriesTable = new MemoryEntriesTable;

	/* tb->futurevectors = (futurevector_t *) calloc(tb->num_indices + 1, sizeof(futurevector_t)); */
        if (num_futuremoves[WHITE] > num_futuremoves[BLACK])
	    tb->futurevector_bits = num_futuremoves[WHITE];
	else
	    tb->futurevector_bits = num_futuremoves[BLACK];

	futurevector_bytes = (((tb->num_indices * tb->futurevector_bits) + 7) >> 3) + 2*sizeof(int);
	tb->futurevectors = (char *) malloc(futurevector_bytes);
	if (tb->futurevectors == nullptr) {
	    fatal("Can't malloc %zdMB for tablebase futurevectors: %s\n", futurevector_bytes/(1024*1024),
		  strerror(errno));
	    return false;
	} else {
	    if (futurevector_bytes < 1024*1024) {
		info("Malloced %zdKB for tablebase futurevectors\n", futurevector_bytes/1024);
	    } else {
		info("Malloced %zdMB for tablebase futurevectors\n", futurevector_bytes/(1024*1024));
	    }
	}
	/* Don't really need this, since they will all get initialized anyway */
	memset(tb->futurevectors, 0, futurevector_bytes);

	/* Due to the heavily random access pattern of memory during back propagation, this
	 * application performs horribly if required to swap.  Attempt to lock all of its pages into
	 * memory, and die with a fatal error if we couldn't.  It seems better to die here, so we
	 * can detect this condition and rerun with either simpler tablebases (if there are pawns
	 * that can be factored) or using proptables.
	 *
	 * I'm finding that this system call is dangerous on Linux.  If you haven't set a resource
	 * limit, it can hang the machine if you try to lock more memory than the system physically
	 * possesses.  So I check first to make sure that a limit has been set before attempting the
	 * lock.
	 *
	 * The #ifdef keeps this from even being attempted on a Windows system.
	 */

#if defined(RLIMIT_MEMLOCK) && LOCK_MEMORY

	if (getrlimit(RLIMIT_MEMLOCK, &rlimit) == -1) {
	    warning("Can't getrlimit RLIMIT_MEMLOCK: %s\n", strerror(errno));
	} else if (rlimit.rlim_cur != 0) {
	    if ((mlockall(MCL_CURRENT) == -1) && (errno != EPERM)) {
		fatal("Can't mlockall memory: %s\n", strerror(errno));
		return false;
	    }
	}

#endif

	pass_type[total_passes] = "initialization";

	info("Initializing tablebase\n");
	initialize_tablebase();

	finalize_pass_statistics();
	total_passes ++;

	info("Total legal positions: %" PRIu64 "\n", (uint64_t) total_legal_positions);
	info("Total moves: %" PRIu64 "\n", (uint64_t) total_moves);

	pass_type[total_passes] = "futurebase backprop";

	if (! back_propagate_all_futurebases(tb)) return false;

	finalize_pass_statistics();
	total_passes ++;

	pass_type[total_passes] = "futuremove check";

	info("Checking futuremoves...\n");
	/* propagation_pass(0); */
	if (! have_all_futuremoves_been_handled(tb)) return false;
	info("All futuremoves handled under move restrictions\n");

	finalize_pass_statistics();
	total_passes ++;

	free(tb->futurevectors);
	tb->futurevectors=nullptr;

    } else {

	/* Using proptables.  No futurevectors array.  We back propagate the futurebases into the
	 * proptable, then in a single pass initialize the entries array and commit the proptable
	 * into it, checking each position move as we go to make sure its futuremoves are handled.
	 *
	 * Required field sizes for futurebase back-propagation:
	 *
	 *   index - figure out from num_indices
	 *   dtm - figure out from futurebase preload, unless it isn't being tracked
	 *   movecnt - 0 (DTM 0 only), 1, or 2 for 8-way symmetry conversion
	 *   futuremove - figure out from total_futuremoves
	 *
	 * Note: movecnt 0 / DTM 0 is handled as a special case in proptable_pass_thread()
	 *
	 * XXX turn off movecnt if we don't have 8-way symmetry
	 */

	proptable_format format(tb->num_indices, min_tracked_dtm, max_tracked_dtm,
				1, std::max(num_futuremoves[WHITE], num_futuremoves[BLACK]));

	info("Initial proptable format: %d bits index; %d bits dtm; %d bit movecnt; %d bits futuremove\n",
	     format.index_bits, format.dtm_bits, format.movecnt_bits, format.futuremove_bits);

	try {
	    entriesTable = new DiskEntriesTable;
	} catch (std::exception &ex) {
	    throw nested_exception("Constructing initial disk entries table", ex);
	}

	try {
	    output_proptable = new proptable(format, proptable_MBs << 20);
	} catch (std::exception& ex) {
	    throw nested_exception("Constructing initial proptable", ex);
	}

	pass_type[total_passes] = "futurebase backprop";

	if (! back_propagate_all_futurebases(tb)) return false;

	finalize_pass_statistics();
	total_passes ++;

	info("Initializing tablebase\n");
	pass_type[total_passes] = "initialization";
	propagation_pass(0);

	info("Total legal positions: %" PRIu64 "\n", (uint64_t) total_legal_positions);
	info("Total moves: %" PRIu64 "\n", (uint64_t) total_moves);

	info("All futuremoves handled under move restrictions\n");
    }

    futurebases.clear();

    info("Intra-table propagating\n");
    propagate_all_moves_within_tablebase(tb);

    write_tablebase_to_file(tb, output_filename);

    /* We alloced entriesTable in this routine, but we might still use it to verify itself
     * internally.  That will only happen if we've got a MemoryEntriesTable, since a
     * DiskEntriesTable can't be accessed randomly.  Furthermore, a DiskEntriesTable will leave
     * temporary files lying around if it isn't destroyed properly.
     */

    if (using_proptables) {
	delete entriesTable;
	entriesTable = nullptr;
    }

    return true;
}

/***** VERIFYING TABLEBASES *****/

/* A tablebase can be checked for internal consistency to see if all moves from PNTM won positions
 * lead to PTM won positions.  We can also check drawn positions, to make sure that none of their
 * moves lead to PNTM won positions.  We can't make a similar check for PTM won positions, because
 * these only require a single move to win, and that move might be in a futurebase.
 *
 * This test will be run at the end of a generation run if the '-v' flag is specified in addition to
 * the '-g' flag.  Doesn't work on proptable runs; the tablebase has to be in memory.  This is only
 * used for software testing, since properly generated tablebases are always internally consistent!
 */

std::atomic<index_t> next_verify_index;

void verify_tablebase_internally_thread(void)
{
    while (1) {
	index_t index = (next_verify_index ++);
	index_t next_index;
	local_position_t position(current_tb);
	int piece;
	int dir;
	int origin_square;
	struct movement *movementptr;

	if (index >= current_tb->num_indices) break;

	print_progress_dot(current_tb);

	if (!index_to_local_position(current_tb, index, REFLECTION_NONE, &position)) continue;

	position.flip_side_to_move();
	position.clear_en_passant_square();

	for (piece = 0; piece < current_tb->num_pieces; piece++) {

	    /* We only want to consider pieces of the side which is to move, but we flipped it... */

	    if (current_tb->pieces[piece].color == position.side_to_move) continue;

	    origin_square = position.piece_position[piece];

	    if (current_tb->pieces[piece].piece_type != PAWN) {

		for (dir = 0; dir < number_of_movement_directions[current_tb->pieces[piece].piece_type]; dir++) {

		    for (movementptr = movements[current_tb->pieces[piece].piece_type][origin_square][dir];
			 (movementptr->vector & position.board_vector) == 0;
			 movementptr++) {

			/* Move the piece, so we can test the new position for check */

			local_position_t new_position = position;

			new_position.move_piece(piece, movementptr->square);

			/* We could just check if local_position_to_index() returns a valid index,
			 * but checking the legal_squares bitvector first makes this a little
			 * faster.
			 *
			 * XXX what really should we use here?
			 */

			if (! PNTM_in_check(current_tb, &new_position)
			    && (current_tb->pieces[piece].legal_squares & BITVECTOR(movementptr->square))
			    && ((next_index = local_position_to_index(current_tb, &new_position)) != INVALID_INDEX)) {

			    /* check this position */
			    int n = entriesTable[index].get_DTM();
			    if (n < 0) {
				/* PNTM mates in (-n)-1 after this move, so next_index must be a PTM wins
				 * in -n moves or less.
				 */
				if ((entriesTable[next_index].get_DTM() <= 0)
				    || (entriesTable[next_index].get_DTM() > -n)) {

				    fatal("index %" PRIindex " DTM %d inconsistent with %" PRIindex " DTM %d\n",
					  index, n, next_index, entriesTable[next_index].get_DTM());
				}
			    } else if (n == 0) {
				if (entriesTable[next_index].get_DTM() < 0) {

				    fatal("index %" PRIindex " DTM %d inconsistent with %" PRIindex " DTM %d\n",
					  index, n, next_index, entriesTable[next_index].get_DTM());
				}
			    }
			}
		    }
		}

	    } else {

		/* Pawns, as always, are special */

		for (movementptr = normal_pawn_movements[origin_square][current_tb->pieces[piece].color];
		     (movementptr->vector & position.board_vector) == 0;
		     movementptr++) {

		    local_position_t new_position = position;

		    new_position.move_piece(piece, movementptr->square);

		    if (abs(movementptr->square - origin_square) == 16) {
			new_position.set_en_passant_square((movementptr->square + origin_square) / 2);
		    }

		    if (! PNTM_in_check(current_tb, &new_position)
			&& (ROW(movementptr->square) != 7) && (ROW(movementptr->square) != 0)
			&& (current_tb->pieces[piece].legal_squares & BITVECTOR(movementptr->square))
			&& ((next_index = local_position_to_index(current_tb, &new_position)) != INVALID_INDEX)) {

			/* check this position */
			int n = entriesTable[index].get_DTM();
			if (n < 0) {
			    /* PNTM mates in (-n)-1 after this move, so next_index must be a PTM wins
			     * in -n moves or less.
			     */
			    if ((entriesTable[next_index].get_DTM() <= 0)
				|| (entriesTable[next_index].get_DTM() > -n)) {

				fatal("index %" PRIindex " DTM %d inconsistent with %" PRIindex " DTM %d\n",
				      index, n, next_index, entriesTable[next_index].get_DTM());
			    }
			} else if (n == 0) {
			    if (entriesTable[next_index].get_DTM() < 0) {

				fatal("index %" PRIindex " DTM %d inconsistent with %" PRIindex " DTM %d\n",
				      index, n, next_index, entriesTable[next_index].get_DTM());
			    }
			}
		    }
		}
	    }
	}
    }
}

bool verify_tablebase_internally(void)
{
    std::thread t[num_threads];
    unsigned int thread;

    /* XXX this routine doesn't work on suicide */
    if (current_tb->variant != VARIANT_NORMAL) return false;

    info("Verifying internal consistency of tablebase\n");

    entriesTable->set_threads(num_threads);
    reset_progress_dots(current_tb);
    next_verify_index = 0;

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread] = std::thread(verify_tablebase_internally_thread);
    }

    for (thread = 0; thread < num_threads; thread ++) {
	t[thread].join();
    }

    entriesTable->set_threads(1);

    info("");
    
    return (fatal_errors == 0);
}


/***** PROBING NALIMOV TABLEBASES *****/

#ifdef USE_NALIMOV

extern "C" {
    int EGTBProbe(int wtm, unsigned char board[64], int sqEnP, int *score);

    int IInitializeTb(char *pszPath);

    int FTbSetCacheSize(void    *pv, unsigned long   cbSize );
}

#define EGTB_CACHE_DEFAULT (1024*1024)

void *EGTB_cache;

char *nalimov_path = (char *) ".";

int nalimov_num = 0;

void init_nalimov_code(void)
{
    nalimov_num = IInitializeTb(nalimov_path);
    if (nalimov_num > 0) {
	info("%d piece Nalimov tablebases found\n", nalimov_num);
    }
    EGTB_cache = malloc(EGTB_CACHE_DEFAULT);
    if (EGTB_cache == nullptr) {
	fatal("Can't malloc EGTB cache\n");
    } else {
	FTbSetCacheSize(EGTB_cache, EGTB_CACHE_DEFAULT);
    }
}

char * nalimov_to_english(int score)
{
    static char buffer[256];

    if (score > 0) {
	sprintf(buffer, "mate in %d", ((65536-4)/2)-score+1);
    } else if (score < 0) {
	sprintf(buffer, "mated in %d", ((65536-4)/2)+score);
    } else {
	sprintf(buffer, "draw");
    }

    return buffer;
}

void verify_tablebase_against_nalimov(tablebase_t *tb)
{
    index_t index;
    global_position_t global;
    local_position_t local(tb);
    int score;

    info("Verifying tablebase against Nalimov\n");

    for (index = 0; index < tb->num_indices; index++) {
	if (index_to_global_position(tb, index, &global)) {

	    index_to_local_position(tb, index, REFLECTION_NONE, &local);

	    if (PNTM_in_check(tb, &local)) {

		/* I've learned the hard way not to probe a Nalimov tablebase for an illegal position... */

	    } else if ((global.en_passant_square != ILLEGAL_POSITION)
		       && ((global.board[global.en_passant_square - 9] != 'P')
			   || (global.en_passant_square == 40)
			   || (global.side_to_move == BLACK))
		       && ((global.board[global.en_passant_square - 7] != 'P')
			   || (global.en_passant_square == 47)
			   || (global.side_to_move == BLACK))
		       && ((global.board[global.en_passant_square + 7] != 'p')
			   || (global.en_passant_square == 16)
			   || (global.side_to_move == WHITE))
		       && ((global.board[global.en_passant_square + 9] != 'p')
			   || (global.en_passant_square == 23)
			   || (global.side_to_move == WHITE))) {

		/* Nor does Nalimov like it if the en passant pawn can't actually be captured by
		 * another pawn.
		 */

	    } else if (EGTBProbe(global.side_to_move == WHITE, global.board,
				 global.en_passant_square == ILLEGAL_POSITION ? -1 : global.en_passant_square, &score) == 1) {

		if (tb->format.dtm_bits > 0) {

		    int dtm = tb->get_DTM(index);

		    if (dtm > 0) {
			if ((dtm-1) != ((65536-4)/2)-score+1) {
			    fatal("%s (%" PRIindex "): Nalimov says %s (%d), but we say mate in %d\n",
				  global_position_to_FEN(&global), index,
				  nalimov_to_english(score), score, dtm-1);
			}
		    } else if (dtm < 0) {
			if ((-dtm-1) != ((65536-4)/2)+score) {
			    fatal("%s (%" PRIindex "): Nalimov says %s (%d), but we say mated in %d\n",
				  global_position_to_FEN(&global), index,
				  nalimov_to_english(score), score, -dtm-1);
			}
		    } else if (dtm == 0) {
			if (score != 0) {
			    fatal("%s (%" PRIindex "): Nalimov says %s (%d), but we say draw\n",
				  global_position_to_FEN(&global), index,
				  nalimov_to_english(score), ((65536-4)/2)+score);
			}
		    }
		}

		if (tb->format.basic_offset != -1) {

		    int basic = tb->get_basic(index);
		    static const char * basic_meaning[3] = {"draw", "PTM wins", "PNTM wins"};

		    if ((basic != 2) && (score < 0)) {
			fatal("%s (%" PRIindex "): Nalimov says PNTM wins, but we say %s\n",
			      global_position_to_FEN(&global), index, basic_meaning[basic]);
		    } else if ((basic != 1) && (score > 0)) {
			fatal("%s (%" PRIindex "): Nalimov says PTM wins, but we say %s\n",
			      global_position_to_FEN(&global), index, basic_meaning[basic]);
		    } else if ((basic != 0) && (score == 0)) {
			fatal("%s (%" PRIindex "): Nalimov says draw, but we say %s\n",
			      global_position_to_FEN(&global), index, basic_meaning[basic]);
		    }

		}

		if (tb->format.flag_type != FORMAT_FLAG_NONE) {

		    bool flag = tb->get_flag(index);

		    if (global.side_to_move == BLACK) score *= -1;

		    if (flag && (score < 0)) {
			fatal("%s (%" PRIindex "): Nalimov says black wins, but we say white wins or draws\n",
			      global_position_to_FEN(&global), index);
		    } else if (flag && (tb->format.flag_type == FORMAT_FLAG_WHITE_WINS) && (score == 0)) {
			fatal("%s (%" PRIindex "): Nalimov says draw, but we say white wins\n",
			      global_position_to_FEN(&global), index);
		    } else if ((!flag) && (score > 0)) {
			fatal("%s (%" PRIindex "): Nalimov says white wins, but we say black wins or draws\n",
			      global_position_to_FEN(&global), index);
		    } else if ((!flag) && (tb->format.flag_type == FORMAT_FLAG_WHITE_DRAWS) && (score == 0)) {
			fatal("%s (%" PRIindex "): Nalimov says draw, but we say black wins\n",
			      global_position_to_FEN(&global), index);
		    }
		}
	    } else {
		fatal("%s (%" PRIindex "): Nalimov says illegal, but we don't\n",
		      global_position_to_FEN(&global), index);
	    }
	}
    }
}

#endif /* USE_NALIMOV */


/***** SEARCHING TABLEBASES *****/

/* search_tablebases_for_global_position() searches an array of tablebases for a global position,
 * returning a search_result, which can be evaluated as a boolean and is true if the search
 * succeeded.  Tablebase array should be terminated with nullptr.  Also probes an inverted copy of
 * the position, so we can find a kqkqq position in a kqqkq tablebase, for example.
 *
 * search_result provides a print_score() method that fetches a tablebase score for a given index
 * and prints the results in English.  Pass it an offset to add to PNTM results.  The offset is
 * either 0 or 1, depending on whether we're printing the score for a single position, or printing
 * the scores for a list of moves from a position.
 *
 * XXX Tablebases are becoming more complicated, so the result strings should be stored in the XML
 * headers, like "wins", "draws", "queens", "queens and draws", "queens or draws", etc.
 *
 * XXX Since tablebases can be big, tablebase searches can be slow, so we should be able to queue up
 * a set of indices that we want to score, then search each tablebase once for all of them.  Modify
 * this function to take a list of tablebase/indices, or maybe add a wrapper function that takes the
 * list, sorts the indices, and passes each one to this function.
 */

class search_result {

public:
    tablebase_t *tb;
    index_t index;
    bool inverted;

    search_result():
	tb(nullptr), index(INVALID_INDEX), inverted(false)
    { }

    search_result(tablebase_t *tb, index_t index, bool inverted):
	tb(tb), index(index), inverted(inverted)
    { }

    operator bool() {
	return tb != nullptr;
    }

    void print_score(int pntm_offset) {

	const char *white;
	const char *black;
	const char *ptm;
	const char *pntm;

	if (! inverted) {
	    white = "White";
	    black = "Black";
	} else {
	    white = "Black";
	    black = "White";
	}

	if (index_to_side_to_move(tb, index) == WHITE) {
	    ptm = white;
	    pntm = black;
	} else {
	    ptm = black;
	    pntm = white;
	}

	if (pntm_offset == 1) printf("(%" PRIindex ") ", index);

	if (tb->format.dtm_bits > 0) {

	    int dtm = tb->get_DTM(index);

	    if (dtm == 0) {
		printf("Draw\n");
	    } else if (dtm == 1) {
		printf("Illegal position (%s mated)\n", pntm);
	    } else if (dtm > 1) {
		printf("%s wins in %d\n", ptm, dtm-1);
	    } else if (dtm < 0) {
		printf("%s wins in %d\n", pntm, pntm_offset-dtm-1);
	    }

	} else if (tb->format.basic_offset != -1) {

	    int basic = tb->get_basic(index);

	    if (basic == 1) {
		printf("%s wins\n", ptm);
	    } else if (basic == 2) {
		printf("%s wins\n", pntm);
	    } else {
		printf("Draw\n");
	    }

	} else if (tb->format.flag_type != FORMAT_FLAG_NONE) {

	    bool flag = tb->get_flag(index);

	    if (tb->format.flag_type == FORMAT_FLAG_WHITE_WINS) {
		if (flag) printf("%s wins\n", white);
		else printf("%s wins or draws\n", black);
	    } else {
		if (flag) printf("%s wins or draws\n", white);
		else printf("%s wins\n", black);
	    }

	} else {
	    printf("NO SCORE AVAILABLE\n");
	}
    }
};

search_result search_tablebases_for_global_position(tablebase_t **tbs, global_position_t *global_position)
{
    global_position_t inverted_global_position = *global_position;
    invert_colors_of_global_position(&inverted_global_position);

    index_t index;

    for (; *tbs; tbs++) {
	index = global_position_to_index(*tbs, global_position);
	if (index != INVALID_INDEX) {
	    return search_result(*tbs, index, global_position->side_to_move != index_to_side_to_move(*tbs, index));
	}

	index = global_position_to_index(*tbs, &inverted_global_position);
	if (index != INVALID_INDEX) {
	    return search_result(*tbs, index, inverted_global_position.side_to_move == index_to_side_to_move(*tbs, index));
	}
    }

    return search_result();
}

int print_move_list(tablebase_t **tbs, tablebase_t *tb, global_position_t *global_position_ptr,
		    bool print_non_captures, bool print_captures)
{
    global_position_t global_position, saved_global_position;
    int dir, square;
    int piece_color;
    int piece_type;
    int promotion;
    struct movement * movementptr;
    int moves_printed = 0;

    saved_global_position = *global_position_ptr;
    piece_color = saved_global_position.side_to_move;

    for (square = 0; square < 64; square ++) {

	if (saved_global_position.board[square] == 0) continue;

	global_position = saved_global_position;
	global_position.en_passant_square = ILLEGAL_POSITION;

	flip_side_to_move_global(&global_position);

	/* We only want to consider pieces of the side which is to move... */

	for (piece_type = 0; piece_type < NUM_PIECES; piece_type ++) {
	    if (global_position.board[square] == global_pieces[piece_color][piece_type]) break;
	}

	if (piece_type == NUM_PIECES) continue;

	global_position.board[square] = 0;

	if (piece_type != PAWN) {

	    for (dir = 0; dir < number_of_movement_directions[piece_type]; dir++) {

		for (movementptr = movements[piece_type][square][dir];
		     (movementptr->square != -1) && (global_position.board[movementptr->square] == 0);
		     movementptr++) {

		    global_position.board[movementptr->square]
			= global_pieces[piece_color][piece_type];

		    if (! global_PNTM_in_check(&global_position) && print_non_captures) {
			search_result result = search_tablebases_for_global_position(tbs, &global_position);
			if (result) {
			    printf("   %c%s%s    ", piece_char[piece_type],
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square]);
			    result.print_score(1);
			} else {
			    printf("   %c%s%s    NO DATA\n", piece_char[piece_type],
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square]);
			}
			moves_printed ++;
		    }

		    global_position.board[movementptr->square] = 0;

		}

		/* Now we consider possible captures */

		if (movementptr->square == -1) continue;

		if (((piece_color == WHITE)
		     && (global_position.board[movementptr->square] >= 'a')
		     && (global_position.board[movementptr->square] <= 'z'))
		    || ((piece_color == BLACK)
			&& (global_position.board[movementptr->square] >= 'A')
			&& (global_position.board[movementptr->square] <= 'Z'))) {

		    char captured_piece = global_position.board[movementptr->square];

		    if ((global_position.variant != VARIANT_SUICIDE)
			&& ((captured_piece == 'K') || (captured_piece == 'k'))) {

			/* printf("MATE\n"); */

		    } else {

			place_piece_in_global_position(&global_position, movementptr->square,
						       piece_color, piece_type);

			if (! global_PNTM_in_check(&global_position) && print_captures) {
			    search_result result = search_tablebases_for_global_position(tbs, &global_position);
			    if (result) {
				printf ("   %c%sx%s   ", piece_char[piece_type],
					algebraic_notation[square],
					algebraic_notation[movementptr->square]);
				result.print_score(1);
			    } else if ((tb->variant == VARIANT_SUICIDE)
				       && (tb->num_pieces_by_color[1 - piece_color] == 1)) {
				printf("   %c%sx%s   %s WINS\n", piece_char[piece_type],
				       algebraic_notation[square],
				       algebraic_notation[movementptr->square],
				       colors[1 - piece_color].c_str());
			    } else {
				printf("   %c%sx%s   NO DATA\n", piece_char[piece_type],
				       algebraic_notation[square],
				       algebraic_notation[movementptr->square]);
			    }
			    moves_printed ++;
			}

		    }

		    global_position.board[movementptr->square] = captured_piece;
		}

		/* end of capture search */
	    }

	    global_position.board[square] = global_pieces[piece_color][piece_type];

	} else {

	    /* PAWNs */

	    for (movementptr = normal_pawn_movements[square][piece_color];
		 movementptr->square != -1;
		 movementptr++) {

		/* break, not continue, because pawns can't jump over pieces */
		if (global_position.board[movementptr->square] != 0) break;

		if ((ROW(movementptr->square) != 0) && (ROW(movementptr->square) != 7)) {

		    global_position.board[movementptr->square] = global_pieces[piece_color][PAWN];

		    if ((movementptr->square == square + 16)
			&& (((square % 8 != 0) && (global_position.board[square + 16 - 1] == 'p'))
			    || ((square % 8 != 7) && (global_position.board[square + 16 + 1] == 'p')))) {

			global_position.en_passant_square = square + 8;
		    }

		    if ((movementptr->square == square - 16)
			&& (((square % 8 != 0) && (global_position.board[square - 16 - 1] == 'P'))
			    || ((square % 8 != 7) && (global_position.board[square - 16 + 1] == 'P')))) {

			global_position.en_passant_square = square - 8;
		    }

		    if (! global_PNTM_in_check(&global_position) && print_non_captures) {
			search_result result = search_tablebases_for_global_position(tbs, &global_position);
			if (result) {
			    printf("   P%s%s    ",
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square]);
			    result.print_score(1);
			} else {
			    printf("   P%s%s    NO DATA\n",
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square]);
			}
			moves_printed ++;
		    }

		    global_position.board[movementptr->square] = 0;
		    global_position.en_passant_square = ILLEGAL_POSITION;

		} else {

		    /* non-capture promotion */

		    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {

			place_piece_in_global_position(&global_position, movementptr->square,
						       piece_color, promoted_pieces[promotion]);


			if (! global_PNTM_in_check(&global_position) && print_non_captures) {
			    search_result result = search_tablebases_for_global_position(tbs, &global_position);
			    if (result) {
				printf ("   P%s%s=%c  ",
					algebraic_notation[square],
					algebraic_notation[movementptr->square],
					piece_char[promoted_pieces[promotion]]);
				result.print_score(1);
			    } else {
				printf("   P%s%s=%c  NO DATA\n",
				       algebraic_notation[square],
				       algebraic_notation[movementptr->square],
				       piece_char[promoted_pieces[promotion]]);
			    }
			    moves_printed ++;
			}
		    }

		    global_position.board[movementptr->square] = 0;
		}
	    }

	    /* capture pawn moves */

	    for (movementptr = capture_pawn_movements[square][piece_color];
		 movementptr->square != -1;
		 movementptr++) {

		if (movementptr->square == saved_global_position.en_passant_square) {

		    /* en passant capture */

		    place_piece_in_global_position(&global_position, movementptr->square,
						   piece_color, PAWN);

		    if (piece_color == WHITE) {
			global_position.board[saved_global_position.en_passant_square - 8] = 0;
		    } else {
			global_position.board[saved_global_position.en_passant_square + 8] = 0;
		    }

		    if (! global_PNTM_in_check(&global_position) && print_captures) {
			search_result result = search_tablebases_for_global_position(tbs, &global_position);
			if (result) {
			    printf ("   P%sx%s   ",
				    algebraic_notation[square],
				    algebraic_notation[movementptr->square]);
			    result.print_score(1);
			} else if ((tb->variant == VARIANT_SUICIDE)
				   && (tb->num_pieces_by_color[1 - piece_color] == 1)) {
			    printf("   P%sx%s   %s WINS\n",
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square],
				   colors[1 - piece_color].c_str());
			} else {
			    printf("   P%sx%s   NO DATA\n",
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square]);
			}
			moves_printed ++;
		    }

		    if (piece_color == WHITE) {
			global_position.board[saved_global_position.en_passant_square - 8] = 'p';
		    } else {
			global_position.board[saved_global_position.en_passant_square + 8] = 'P';
		    }

		    continue;
		}

		if (global_position.board[movementptr->square] == 0) continue;

		if (((piece_color == WHITE)
		     && (global_position.board[movementptr->square] >= 'A')
		     && (global_position.board[movementptr->square] <= 'Z'))
		    || ((piece_color == BLACK)
			&& (global_position.board[movementptr->square] >= 'a')
			&& (global_position.board[movementptr->square] <= 'z'))) {
		    continue;
		}

		if ((global_position.variant != VARIANT_SUICIDE)
		    && ((global_position.board[movementptr->square] == 'K')
			|| (global_position.board[movementptr->square] == 'k'))) {

		    /* printf("MATE\n"); */
		    continue;

		}

		if ((ROW(movementptr->square) == 7) || (ROW(movementptr->square) == 0)) {

		    /* promotion capture */

		    char captured_piece = global_position.board[movementptr->square];

		    for (promotion = 0; promotion < promotion_possibilities; promotion ++) {

			place_piece_in_global_position(&global_position, movementptr->square,
						       piece_color, promoted_pieces[promotion]);

			if (! global_PNTM_in_check(&global_position) && print_captures) {
			    search_result result = search_tablebases_for_global_position(tbs, &global_position);
			    if (result) {
				printf ("   P%sx%s=%c ",
					algebraic_notation[square],
					algebraic_notation[movementptr->square],
					piece_char[promoted_pieces[promotion]]);
				result.print_score(1);
			    } else if ((tb->variant == VARIANT_SUICIDE)
				       && (tb->num_pieces_by_color[1 - piece_color] == 1)) {
				printf("   P%sx%s=%c %s WINS\n",
				       algebraic_notation[square],
				       algebraic_notation[movementptr->square],
				       piece_char[promoted_pieces[promotion]],
				       colors[1 - piece_color].c_str());
			    } else {
				printf("   P%sx%s=%c NO DATA\n",
				       algebraic_notation[square],
				       algebraic_notation[movementptr->square],
				       piece_char[promoted_pieces[promotion]]);
			    }
			    moves_printed ++;
			}
		    }

		    global_position.board[movementptr->square] = captured_piece;

		    continue;

		} else {

		    char captured_piece = global_position.board[movementptr->square];

		    global_position.board[square] = 0;
		    place_piece_in_global_position(&global_position, movementptr->square,
						   piece_color, PAWN);

		    if (! global_PNTM_in_check(&global_position) && print_captures) {
			search_result result = search_tablebases_for_global_position(tbs, &global_position);
			if (result) {
			    printf ("   P%sx%s   ",
				    algebraic_notation[square],
				    algebraic_notation[movementptr->square]);
			    result.print_score(1);
			} else if ((tb->variant == VARIANT_SUICIDE)
				   && (tb->num_pieces_by_color[1 - piece_color] == 1)) {
			    printf("   P%sx%s   %s WINS\n",
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square],
				   colors[1 - piece_color].c_str());
			} else {
			    printf("   P%sx%s   NO DATA\n",
				   algebraic_notation[square],
				   algebraic_notation[movementptr->square]);
			}
			moves_printed ++;
		    }

		    global_position.board[movementptr->square] = captured_piece;
		}
	    }
	    /* end of capture search */

	}
    }

    return moves_printed;
}

void probe_tablebases(tablebase_t **tbs) {
    global_position_t global_position;
    bool global_position_valid = false;

    if (tbs[0] == nullptr) {
	fatal("No valid tablebases to probe!\n");
	terminate();
    }

    for (int i=1; tbs[i]; i ++) {
	if (tbs[i]->variant != tbs[0]->variant) {
	    fatal("All probed tablebases must use same variant!\n");
	    terminate();
	}
    }

#ifdef HAVE_LIBREADLINE
    read_history(".hoffman_history");
#endif

    while (true) {
	index_t index;
	bool index_valid = false;
	search_result result;
#ifdef USE_NALIMOV
	int score;
#endif

	/* print current position */
	if (global_position_valid) {
	    for (int i = 0; i < 64; i++) {
		char c = global_position.board[i % 8 + 8*(7-i/8)];
		if (i % 8 == 0)
		    printf("%c |",'8'-i/8);
		printf(" %s%c\e[0m", c >= 'a' ? "\e[7m" : "", c ? c : '.');
		if (i % 8 == 7)
		    printf("\n");
	    }
	    printf("  +----------------\n");
	    printf("    a b c d e f g h\n");
	    printf("FEN %s\n", global_position_to_FEN(&global_position));
	    //printf("%s to move\n", colors[global_position.side_to_move]);
	}

	/* Loop until we've read a valid input string */
	while (true) {

	    char *endptr;

#ifdef HAVE_LIBREADLINE
	    char *buffer;

	    buffer = readline(global_position_valid ? "Index, FEN or move? " : "Index or FEN? ");
	    if (buffer == nullptr) {
		write_history(".hoffman_history");
		printf("\n");
		return;
	    }
	    if (*buffer == '\0') continue;
	    add_history(buffer);
#else
	    char buffer[256];

	    printf(global_position_valid ? "Index, FEN or move? " : "Index or FEN? ");
	    if (fgets(buffer, sizeof(buffer), stdin) == nullptr) {
		printf("\n");
		return;
	    }

	    if (strchr(buffer, '\n') != NULL) {
		* strchr(buffer, '\n') = '\0';
	    }
#endif

	    if (global_position_valid && parse_move_in_global_position(buffer, &global_position))
		break;
	    if (parse_FEN_to_global_position(buffer, &global_position))
		break;

	    /* Check to see if the entire string parses as an integer.  Otherwise, a corrupt FEN
	     * might parse as something like "8", and that's very confusing.
	     */

	    index = strtol(buffer, &endptr, 10);
	    if (*endptr == '\0') {
		if (index >= tbs[0]->num_indices) {
		    printf("Index out of range (%" PRIindex " max)\n", tbs[0]->num_indices - 1);
		} else {
		    index_valid = true;
		    break;
		}
	    }

	    printf("Bad input\n\n");
	}

	global_position.variant = tbs[0]->variant;
	global_position_valid = true;

	if (! index_valid) {
	    result = search_tablebases_for_global_position(tbs, &global_position);
	} else {
	    result = search_result(tbs[0], index, false);
	    index_to_global_position(tbs[0], index, &global_position);
	}

	if (result) {

	    const char *ptm;
	    const char *pntm;

	    printf("Index %" PRIindex " (%s)\n", result.index, result.tb->filename.c_str());

	    if (global_position.side_to_move == WHITE) {
		ptm = "White";
		pntm = "Black";
	    } else {
		ptm = "Black";
		pntm = "White";
	    }

	    result.print_score(0);

#ifdef USE_NALIMOV
	    if ((global_position.variant == VARIANT_NORMAL) && (nalimov_num > 0)
		&& EGTBProbe(global_position.side_to_move == WHITE, global_position.board, -1, &score) == 1) {
		printf("\nNalimov score: ");
		if (score > 0) {
		    printf("%s wins in %d.5\n", ptm, ((65536-4)/2)-score+1);
		} else if (score < 0) {
		    printf("%s wins in %d\n", pntm, ((65536-4)/2)+score);
		} else {
		    printf("DRAW\n");
		}
	    }
#endif

	    /* In suicide, capture moves are forced, so if any exist they are the only moves. */

	    if (global_position.variant != VARIANT_SUICIDE) {
		print_move_list(tbs, result.tb, &global_position, true, true);
	    } else {
		if (print_move_list(tbs, result.tb, &global_position, false, true) == 0) {
		    print_move_list(tbs, result.tb, &global_position, true, false);
		}
	    }
	}
    }
}

void usage(char *program_name)
{
    fprintf(stderr, "\n");
    fprintf(stderr, "Usage: %s -g [GENERATING-OPTIONS] XML-CONTROL-FILE   (generate)\n", program_name);
    fprintf(stderr, "   or: %s -p TABLEBASE                               (probe)\n", program_name);
    fprintf(stderr, "   or: %s -i TABLEBASE                               (info)\n", program_name);
#ifdef USE_NALIMOV
    fprintf(stderr, "   or: %s -v [-n NALIMOV-PATH] TABLEBASE             (verify)\n", program_name);
#endif
    fprintf(stderr, "\n");
    fprintf(stderr, "Possible GENERATING-OPTIONS are:\n");
    fprintf(stderr, "   -o OUTPUT-FILENAME    set output filename (overrides control file)\n");
    fprintf(stderr, "   -P PROPTABLE-SIZE     enable proptables and sets size in MBs\n");
    fprintf(stderr, "   -t NUM-THREADS        sets number of threads to use (default 1)\n");
    fprintf(stderr, "   -q                    quiet mode; suppress informational messages\n");
    fprintf(stderr, "   --compress-files      compress intermediate files in proptable mode\n");
    fprintf(stderr, "\n");
    fprintf(stderr, "Other options:\n");
#ifdef USE_NALIMOV
    fprintf(stderr, "   -n NALIMOV-PATH       sets path to find Nalimov tablebases\n");
#endif
    fprintf(stderr, "   -h                    display this help message and exit\n");
}

struct option options[] = {{"compress-files", no_argument, NULL, 1},
			   {NULL, 0, NULL, 0}};

int main(int argc, char *argv[])
{
    /* Make sure this tablebase array is one bigger than we need, so it can be nullptr terminated */
    tablebase_t **tbs;
    int argi;
    int i;
    int c;
    int generating=0;
    int probing=0;
    int verify=0;
    int summarize=0;
    int dump_info=0;
    std::string output_filename;
    extern char *optarg;
    extern int optind;
    char *options_string_ptr = options_string;
    struct sigaction action;

    /* Set signal handlers */

    memset(&action, 0, sizeof(action));
    action.sa_flags = SA_SIGINFO;
    action.sa_sigaction = sigaction_user_interrupt;
    if (sigaction(SIGINT, &action, nullptr) == -1) {
	warning("Can't install SIGINTR handler: %s\n", strerror(errno));
    }

    action.sa_sigaction = sigaction_internal_error;
    if (sigaction(SIGSEGV, &action, nullptr) == -1) {
	warning("Can't install SIGSEGV handler: %s\n", strerror(errno));
    }
    if (sigaction(SIGILL, &action, nullptr) == -1) {
	warning("Can't install SIGILL handler: %s\n", strerror(errno));
    }
    if (sigaction(SIGFPE, &action, nullptr) == -1) {
	warning("Can't install SIGFPE handler: %s\n", strerror(errno));
    }
    if (sigaction(SIGBUS, &action, nullptr) == -1) {
	warning("Can't install SIGBUS handler: %s\n", strerror(errno));
    }

    /* Note program start time */

    gettimeofday(&program_start_time, nullptr);

    /* Print a greating banner with program version number. */

    fprintf(stderr, "Hoffman Version %d%s\n", Hoffman_program_version,
	    Hoffman_program_modified ? " (modified)" : "");

    /* Figure how we were called.  This is just to record in the XML output for reference purposes. */

    for (i=0; i<argc; i++) {
	strncpy(options_string_ptr, argv[i], options_string + sizeof(options_string) - options_string_ptr);
	options_string_ptr += strlen(argv[i]);
	if (options_string_ptr >= options_string + sizeof(options_string)) break;
	*options_string_ptr = ' ';
	options_string_ptr ++;
	if (options_string_ptr >= options_string + sizeof(options_string)) break;
    }
    options_string[sizeof(options_string) - 1] = '\0';

    /* Initialize various global data structures */
    init_movements();
    verify_movements();
    init_reflections();
    initialize_board_masks();

#ifdef DEBUG_MOVE
#define DEBUG_FLAG "d:"
#else
#define DEBUG_FLAG ""
#endif

    while (1) {
	c = getopt_long (argc, argv, "hiqgpsvo:n:P:t:" DEBUG_FLAG, options, NULL);

	if (c == -1) break;

	switch (c) {

#ifdef DEBUG_MOVE
	case 'd':
	    /* XXX might want strtoll or something here */
	    if (strtol(optarg, nullptr, 0) > 0) {
		debug_move = strtol(optarg, nullptr, 0);
	    } else if (strtol(optarg, nullptr, 0) < 0) {
		debug_futuremove = -strtol(optarg, nullptr, 0);
	    } else {
		fatal("can't parse debugging index %s\n", optarg);
	    }
	    break;
#endif
	case 'i':
	    dump_info = 1;
	    break;
	case 'g':
	    generating = 1;
	    break;
	case 'p':
	    probing = 1;
	    break;
	case 's':
	    summarize = 1;
	    break;
	case 'v':
	    verify = 1;
	    break;
	case 'h':
	    usage(argv[0]);
	    terminate();
	    break;
	case 'q':
	    verbose = 0;
	    break;
#ifdef USE_NALIMOV
	case 'n':
	    nalimov_path = optarg;
	    break;
#endif
	case 'o':
	    output_filename = optarg;
	    break;
	case 'P':
	    /* set size of proptable in megabytes */
	    proptable_MBs = strtol(optarg, nullptr, 0);
	    using_proptables = true;
	    break;
	case 't':
	    num_threads = strtol(optarg, nullptr, 0);
	    break;
	case 1:
	    compress_proptables = true;
	    compress_entries_table = true;
	    break;
	case '?':
	    terminate();
	    break;
	}
    }

    // XXX need to consider other invalid possibilities like -g and -s
    if (generating && probing) {
	fatal("Only one of the generating (-g) and probing (-p) options can be specified\n");
	usage(argv[0]);
	terminate();
    }

    if (!generating && !probing && !verify && !dump_info && !summarize) {
#if USE_NALIMOV
	fatal("At least one of -g, -p, -i, -s, or -v must be specified\n");
#else
	fatal("At least one of -g, -p, -s, or -i must be specified\n");
#endif
	usage(argv[0]);
	terminate();
    }

    if (!generating && ! output_filename.empty()) {
	fatal("An output filename can not be specified when probing or verifying\n");
	usage(argv[0]);
	terminate();
    }

#if !USE_NALIMOV
    if (!generating && verify) {
	fatal("Can't verify - program compiled without Nalimov support\n");
	usage(argv[0]);
	terminate();
    }
#endif

    /* Summarize */

    if (summarize) {
	tablebase_t * tb = parse_XML_control_file(argv[optind]);
	if (tb != nullptr) {
	    std::cout << "Total indices: " << tb->num_indices << std::endl;
	}
	terminate();
    }

    /* Generating.
     *
     * We want to make sure we destroy any intermediate files instead of leaving them lying around
     * on disk.  That's the point of deleting entriesTable no matter what happens.
     *
     * XXX should delete proptables, too
     *
     * XXX verify_tablebase_internally needs to work with proptables
     */

    if (generating) {
	try {
	    bool success = generate_tablebase_from_control_file(argv[optind], output_filename);
	    if (success && verify && !using_proptables) verify_tablebase_internally();

	    if (entriesTable != nullptr) {
		delete entriesTable;
		entriesTable = nullptr;
	    }
	} catch (std::exception) {
	    if (entriesTable != nullptr) {
		delete entriesTable;
		entriesTable = nullptr;
	    }
	    throw;
	}
	terminate();
    }

    /* Probing / Verifying */

#ifdef USE_NALIMOV
    init_nalimov_code();
#endif

    i = 0;
    /* calloc (unlike malloc) zeros memory */
    tbs = (tablebase_t **) calloc(argc - optind + 1, sizeof(tablebase_t *));

    for (argi=optind; argi<argc; argi++) {
	info("Loading '%s'\n", argv[argi]);
	try {
	    tbs[i] = new tablebase_t(argv[argi]);
	} catch (const char *msg) {
	    fatal("Error loading tablebase '%s': %s\n", argv[argi], msg);
	} catch (std::exception &ex) {
	    fatal("Error loading tablebase '%s': %s\n", argv[argi], ex.what());
	}

	if (dump_info) tbs[i]->xml->write_to_stream(std::cout);
#ifdef USE_NALIMOV
	if (verify) verify_tablebase_against_nalimov(tbs[i]);
#endif
	i++;
    }

    if (!probing) terminate();

    probe_tablebases(tbs);
    terminate();
}

/*
 * Why did I learn writing Hoffman?
 * 
 * My biggest regret is that I started writing it the program at all.  Why?  It's among the best in
 * the world at what it does.  But it just plays endgames in chess.  That's it.
 *
 * So what?
 *
 * At 44, I've become more utilitarian than Magnus Carlsen or Payton Manning.  I expect my programs
 * to do something useful.  Just being among the best at something isn't good enough.  Being the
 * best isn't good enough!  Let's see a computer endgame showdown between Nalimov, Lomosolov (who's
 * gonna win that round?), Freezer, FinalGen, and Hoffman.  Even if Hoffman won, it's still not
 * good enough.  At it does is play a game!
 *
 * My second biggest regret is writing it in C++11.  We need templates in Java, but we need dynamic,
 * run-time type checking built into the language for testing.  My code has too many bugs.  I spend
 * too much time staring at strange seg faults.
 *
 * We need software that can build with all kinds of run-time type checking, run it through 15,000
 * test cases to convince yourself that it's right, then build a version that runs without all the
 * type checking and runs fast.
 *
 * Still sounds like Java!  To build with run-time typing, we need a language that makes sure it's
 * possible!  Right?  So we can build it when we need it and turn it off later?  Maybe they already
 * know that in grad schools but the C++ standards committee seems unaware.  They're coming out with
 * C++14!
 *
 * You believe that?  I regret writing this program and I regret using this crazy language to do it?
 *
 * I don't know if I do either.
 */
