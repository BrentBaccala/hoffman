
- general speed improvements

The program can operate in two modes (in-memory or proptables), and
the two behave radically differently performance-wise.

For in-memory operation, the most immediate place that can probably
use attention is the initialization code.  Bitboard representation can
probably be used more effectively; see some of the papers on Bob
Hyatt's website for ideas.  Intel processors have bit scan
instructions (BSF/BSR) that search a register for the first or last 1
bit, we probably want to make sure we use these when counting
movements (logical AND to find what pieces we can hit, then bit scan
to find which one we hit first).  Also, when we advance the loop by a
single index, we're typically moving a single piece (or none at all,
just flipping the side-to-move flag), so this can be optimized.  This
would also be useful during futurebase backprop.  Might want to
hand-code critical sections of this loop in assembly, and there should
be a big difference between a 32-bit and a 64-bit architecture (since
bitboards have 64 bits).  I'll also note that some things (PTM_vector)
only need to be computed during initialization.

The tablebase operation, the main thing right now is to insure that
the program really becomes disk-bound, then look at some ideas like
compressing the proptable/entries files on disk.  For proptables, I
see no reason not to compress them so long as we can push the
program's performance so that it stays disk-bound even with the extra
CPU overhead of decompression.  For entries files, the issue isn't so
clear because I'm still thinking that we should have a single entries
file instead of a pair of in/out files, which would preclude
compressing the file.  Needs investigation.  Also want to check to see
if keeping the input and output files (or some similar split) on
seperate disks/controllers can be exploited.


- investigate the Library Sort of Bender, et al. (2004)

Get the paper (FUN04.pdf) on-line.  Looks like it might have
comparable performance to our bucket sort without requiring finite
field inversion, which is itself costly.  It's probably hard to make a
direct comparison since inversion costs CPU cycles and Library Sort
costs memory accesses, but so long as we stay disk-bound it really
doesn't matter either way.  Getting rid of inversion, though, is
probably the single best thing we can do to improve compressibility of
the resulting tablebases.  Something to investigate is keeping the
current bucket sort if inversion is enabled, and using Library Sort if
it's not, which would at least make proptables useful without
inversion.


- analyze and improve on bucket sort in proptable code

Right now, the proptable insertion code runs until it has to move 25
items to make room for a new one, then trips into the code where it
writes the proptable out to disk and starts a new one.  The exact
condition of 25 moves was a total guess on my part.


- trim size of proptables

Because I use an integer scaling factor during proptable insertion,
the trailing part of a proptable (that would correspond to the
truncated decimal part) is unused.  There's no need to either malloc
it or check it for entries when writing the table out.


- improve compressibility

Hoffman tablebases are significantly larger than Nalimovs.  Probably
not much can be done for proptable-generated files with finite field
inversion, because they'll be hard to compress no matter what.  But
for tablebases without inversion, probably the biggest help would be
to clump like positions together (exactly what we're trying to avoid
with inversion).  Right now, the index LSB is the side-to-move flag,
we'd really like it to be elsewhere (like the MSB) when one side is
dominant and is going to have the bulk of the mates.  A couple places
in the code depend on the side-to-move flag being LSB; they need to be
found, investigated, and made more flexible.  Then we can add a
<side-to-move-flag/> element to the XML, that gets put into the pieces
list at the position that we'd like the flag to be.


- ability to reformat tablebases

Only once we're all done making a tablebase do we know stuff like the
max DTM.  I've got several that I build with 16-bit dtm that I now
know only need 8-bit.  It would be nice to reformat them.  It'd also
be nice to play around with different piece orderings (see item above)
to see which one gives the best compression without having to
re-generate the entire tablebase.  Note that attempting to reformat a
tablebase with finite field inversion into one without (it would be
nice) presents the same problem that inversion was designed to avoid
in the first place.


- improved checkpointing ability

Right now, we have a limited checkpointing ability if we're running
with proptables (the most time consuming case anyway) - the program
will write a checkpoint.xml file at the start of each pass which can
be used to restart the last pass in the event of something like a
system crash.  This could be really be cleaned up and improved upon.
With separate input and output entries files, I don't see any reason
it can't restart right where it left off, though we do have to be
careful to back up and reconstruct the last proptable that was in
memory at the time of the crash.  Maybe write the checkpoint file with
each proptable write, record the size of the proptables for
verification, and keep a backup copy of the checkpoint file in case we
crash during the checkpoint.  It will have to change significantly,
however, if we switch to using a single entries file in read/write
mode.  I've thought of putting an extra bit into the entries format
that starts off as 0, gets flipped to 1 as we make one pass through
the file, then gets flipped back to 0 on the next pass.  We would also
like to deal with the case where we get well into a calculation and
the dtm field overflows - just checkpoint, terminate, and use our
(unimplemented) reformating ability.


- some things are uint32 right now (indices and futurevectors) that
  sometimes need to be uint64

Add configure switches --with-big-indices and --with-big-futurevectors


- fix libcurl handling of FTP put transactions and use it exclusively

I had a lot of problems using libcurl for FTP writes, so much so that
I switched to ftplib for FTP URLs.  Since libcurl advertises FTP
support, somebody could profitably investigate the problems and fix
them.


- add 'dtc' and 'dtr' formats

The distance to mate (dtm) metric that we use is the simplest but
maybe not the best.  Distance to conversion (dtc) tracks (basically)
how far until the next futurebase, and distance to rule (dtr)
incorporates the 50-move rule into the calculation, but is tricky to
implement - Guy Haworth has written some papers about this.


- be more consistent about current tablebase being a global var


- use two different proptable formats

One for the first (futurebase) pass and one for subsequent passes.
Since the 'futurevector' field is only needed on the first pass, this
would be a fairly simple change that would cut the size of default
proptable entries in half.


- decide whether we need compiled-in proptable formats

Compiling-in entries formats obviously make sense for in-memory
operation (though gcc3 doesn't optimize them well; use gcc4), but it
isn't as clear for proptable formats.  Compiling them in only makes
sense if not doing so would introduce enough overhead that the program
becomes compute-bound instead of disk-bound.


- check indexing logic with an automated theorem prover

I've had a lot of bugs in the indexing logic, especially since there
are two different routines for each index type that need to be kept in
sync.  If we optimize the case where the index number is advanced by
one (see above), then we'll have a third routine to keep in sync.  Can
we use an automated theorem prover like Prover9 to ensure that this
code is right?


- stalemate pruning

This idea is to speed up processing by allowing promotion futurebases
with only queens to substitute for promotions into rooks and bishops,
since the only logical reason to underpromote is to avoid a stalemate.
To this end, a futurebase with an extra queen and stalemates pruned
would be treated as handling all three promotions (queen, rook, and
bishop).  To implement this correctly, you'd have to make sure that
stalemates were pruned not only in the current tablebase, but in all
(and I mean ALL) futurebases.  So this would mean adding an element to
tablebase-statistics, <all-stalemates-pruned color="white|black"/>,
that would flag when all futurebases depending on it had their
stalemates pruned as well.  This element would back propagate through
the futurebases and be dropped at any point where stalemate pruning
was turned off (unless there were no stalemates, like kk.htb).  In any
event, I've got the code to group all three promotions together in
RCS, but I've ripped it out of the main line since this extra logic
has never been implemented.


- ability to back prop from a Nalimov tablebase

Nalimov tablebases have been precomputed for 6-piece endgames;
currently, we've only got 5-piece endgames for Hoffman, so to leverage
the work that's already been done and to make Hoffman fully as
powerful as Freezer, we'd like to back prop directly from a Nalimov
tablebase.  With a good description of the Nalimov file format (which
I don't have), this shouldn't been difficult.  Also consider that
Hoffman tablebases are (currently) much bigger than Nalimov
tablebases, and fully 1TB of storage is required for a full set of
6-piece Nalimovs.


- handle more than two identical pieces

With this current restriction, we can't create tablebases like kpppkr.
This would make Hoffman fully as powerful as the Nalimov program.


- restrict range of indices we look at during a backprop

If we're backproping, say, from kqk into kpk, we need only consider
those positions where the queen is on the eighth rank.  If the queen
is encoded into the MSBs of the index, then we should be able to
figure out at what futurebase index we need to start processing, and
fast forward to that point.  Symmetry might disrupt this, but the
general idea might still work, especially if it was done in a general
enough fashion, maybe by constructing a bitboard of legal board
positions for each piece at the beginning of a backprop (of any kind)
and fast forwarding over chunks of the futurebase that have been
identified as irrelevant.  The index-ordering=reverse attribute was
created to facilitate this, but it's never been implemented.


- add a repeat option for processing multiple XML files

If we're doing distributed batch processing, we'd probably like to
provide a URL to the program to get a generation control file (this
already works), then retry that URL when we're all done to get another
control file, and keep doing this.  Have to make sure the program is
pretty clean in its memory usage for this to work well.  Also should
provide some way to terminate the program at the end of the current
tablebase build.


- prune after some number of passes

If we're looking to trade some accuracy for speed, we can prune at
almost any point in the calculation by conceding every position that
hasn't been resolved.  So, for example, if we anticipate that allowing
black to queen will lose the game, except that we still want to
consider the possibility of immediately capturing the new queen
(Freezer can do this), we can run for one or two passes and then prune
everything else.  Note that in this example, we can already achieve
almost the same result by freezing the queen on the queening square
and conceding any move by the queen as a win to black.  We'd probably
run for several passes, though, checking lines where white can check
black around for a few moves before taking the queen.


- some kind of GUI

I like leaving hoffman as a standalone computation engine.  For one
thing, this makes it easier to compile on a minimal system where
you're not going to do anything except farm out tablebase
calculations.  So my current thought for a GUI would be either a
Perl/Tk script or a Java applet, and I think Java is much cleaner than
Perl.  Freezer seems to have a nice GUI for a tablebase generator; see
the demos on http://www.freezerchess.com/

Even the computation engine could use a GUI, though, especially on
Microsoft systems where it's the standard user interface.  A modal
startup sequence could begin with radio buttons to select either a
file chooser to pick a control file (or files) for processing, or a
URL to connect to a remote webserver and retrieve control files from
there.  An options panel could allow selecting the maximum amount of
RAM to use, along with the location of a temporary files directory and
the maximum amount of disk space to use.  Use of proptable mode would
then be automatic depending on how much RAM is available.  It should
be possible to change these settings while the program is running.
Once the analysis proper starts, you should be able to halt or pause
it, as well as iconize it while it continues to run.


- improve probe mode's move parser

Check illegal moves more aggressively; have a 'back' command; maybe a
'board' command to print a diagram of the chess board.


- warn of incompatibilities between tb and entries formats


- improve portability

There might be some little-endian dependencies in the code, but even
more serious is the usage (in the dynamic structures code and in the
futurevector handling) of non-word-aligned word accesses.  I doubt it
would run on a SPARC.


- revisit all the XXXs

  - check for movecnt overflow when merging proptable entries
  - investigate proptable merge code in more detail
  - check stalemate handling in general
