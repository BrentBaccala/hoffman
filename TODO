
- more clever encoding

En passant is what makes lasker1901 so ridiculously big with
combinadic3 encoding.

Allow kings and side-to-move-flag to be positioned within index. Right
now, side to move flag is always the low bit, and kings always come
next.  Nalimov (and probably Syzygy) put kings in high bits and
side-to-move in separate files.  Putting kings in high bits allows
further index compression - for each king position, you can generate
custom tables for each piece, removing those squares where a piece to
move could capture the adjacent enemy king (Nalimov does this).

The ability to complete mimic Nalimov and Syzygy indexing would speed
up back propagation from those tablebases, allowing sequential instead
of random access.

Allow an 'offset' field to adjust the range of the fields, i.e, allow
DTM field to range from -10 to 5 and still fit into 4 bits.

- fast increment of positions by 1

During initialization, we run through the indices in order

- fast increment of positions by small numbers

During propagation passes, we move sequentially through the table

- fast update of positions by moving a single piece

This is the only way we change them.



  ;

class index_encoding {
  virtual index_to_position(index_t index, local_position_t &pos);
  virtual move_piece(local_position_t, piece, destination_square) {
    // move piece and recompute index
  }
};

class combinadic3 : public index_encoding {
  index_to_position(index_t index, local_position_t &pos) final {
    if (position_valid) {
      if (index - pos.index < small_number) {
	be smart;
      }
    }
  }
  move_piece(local_position_t, piece, destination_square) final {
  }
  combinadic3(tablebase_t *);
 private:
  int last_overlapping_piece[NUM_PIECES];
};

class tablebase_t {
  index_encoding encoding;

  encoding = new combinadic3(this);

  index_to_local_position(index_t index, local_position_t &pos) {
    if (position_valid) {
      if (index - pos.index == 1) {
	maybe flip stm;  // stm is LSB
      }
      if (index - pos.index > small_number) {
	process kings;  // kings are next LSB
	// moving kings affects overlapping pieces
      }
      if (index - pos.index > pawngen_limit) {
	process pawngen;
      }
    } else {
      process stm;
      process kings;
      process pawngen;
    }
    encoding->index_to_position(index, pos);
    compute multiplicity;
    compute board vectors;
  }

}

class local_position_t {
  bool position_valid = false;
  void move_piece(int piece, int destination_square) {
    tablebase->encoding->move_piece(this, piece, destination_square);
  }
  operator++();  // maybe use this

  local_position_t(tablebase) tablebase(tablebase), position_valid(false) { }  
 private:
  const tablebase_t &tablebase;
};

class combinadic3_position : public local_position_t {
  void move_piece(int piece, int destination_square) {
    ...;
  }
 private:
  encoding_information;
};


- fast movecnt generation with perfect hashing

This might be more difficult because of the presence of futuremoves.
Counting moves isn't enough; we have to identify futuremoves as well.
Nevertheless, I think it can be done and should produce a big speedup.
Use a different hash function / magic number for each square a piece
can be on.  Then hash the board vector to move the relevent bits down
to the LSBs and lookup in a table to get movecnt along with flags
to indicate if has the piece moved to a restricted square.


- improve testsuite

Internal verification code doesn't work with proptables, so we still
have some bugs (1.896) that can only be detected by verification
against Nalimov.  Can't verify DTM values against futurebases.  Don't
have anywhere near complete code coverage.


- general speed improvements

The program can operate in two modes (in-memory or proptables), and
the two behave radically differently performance-wise.

For in-memory operation, the most immediate place that can probably
use attention is the initialization code.  Bitboard representation can
probably be used more effectively; see some of the papers on Bob
Hyatt's website for ideas.  Intel processors have bit scan
instructions (BSF/BSR) that search a register for the first or last 1
bit, we probably want to make sure we use these when counting
movements (logical AND to find what pieces we can hit, then bit scan
to find which one we hit first).  Perfect hashing (magic bitboards)
look even better.  Also, when we advance the loop by a single index,
we're typically moving a single piece (or none at all, just flipping
the side-to-move flag), so this can be optimized.  This would also be
useful during futurebase backprop.  Might want to hand-code critical
sections of this loop in assembly, and there should be a big
difference between a 32-bit and a 64-bit architecture (since bitboards
have 64 bits).  I'll also note that some things (PTM_vector) only need
to be computed during initialization.

The tablebase operation, the main thing right now is to insure that
the program really becomes disk-bound.  Also want to check to see if
keeping the input and output files (or some similar split) on seperate
disks/controllers can be exploited.  Proptable code doesn't
multi-thread very well at all.


- use an FPGA

Using one of the knjn.com boards, for example - the PCI-attached
Dragon or the USB-attached Xylo - we could offload the
compute-intensive parts to a pipelined coprocessor.  Initialization
(where we just need to spit out a stream of bytes) and backpropagation
(where we need to back an index out) could both be pipelined
effectively.


- improve compressibility of tablebases

Hoffman tablebases are significantly larger than Nalimovs.  Probably
the biggest help would be to clump like positions together.  Right
now, the index LSB is the side-to-move flag, we'd really like it to be
elsewhere (like the MSB) when one side is dominant and is going to
have the bulk of the mates.  A couple places in the code depend on the
side-to-move flag being LSB; they need to be found, investigated, and
made more flexible.  Then we can add a <side-to-move-flag/> element to
the XML, that gets put into the pieces list at the position that we'd
like the flag to be.

Also, we could use a modified gzip library that lets us flag certain
bytes as 'irrelevant', which instructs the library to fill these bytes
using the shortest possible encoding.  There's always going to be
illegal positions, no matter how cleaver our encoding scheme.

Another idea would be to store DTM information for only positive DTMs.
The negative DTMs would have to be interpolated at decode time, and
their positions in the tablebase file would be filled with a common
(and thus easily compressed) value.  Nalimov uses a variant of this
idea by splitting tablebases into two separate files depending on the
side-to-move.  This idea could be expanded by only storing DTM
information modulo some settable number.


- improve compressibility of entries/proptable files

Towards the end of a generation run, the program's time is dominated
by compressing the entries file.  By that point, we have a pretty good
idea what the entries file looks like, because we're only making a few
changes to it on each pass.  We could probably improve both speed and
compressibility by keeping a count of total entries of each type and
using a statistical encoding scheme based on what the counts were at
the start of each pass (they're not changing much).  Maybe start using
zlib for initial compression, then switch to a statistical scheme at
some point.

We could probably improve proptable compressibility by storing offsets
instead of individual proptable entries (remember, it's sorted).

Maybe play around with compressibility by adding XML controls to set
zlib compression/time tradeoff.


- ability to reformat tablebases

It'd be nice to play around with different piece orderings (see item
above) to see which one gives the best compression without having to
re-generate the entire tablebase.


- checkpointing ability

Right now, we have no checkpointing ability.  We used to have a
limited checkpointing ability with proptables (the most time consuming
case anyway) - the program would write a checkpoint.xml file at the
start of each pass which can be used to restart the last pass in the
event of something like a system crash.  This could be really be
cleaned up and improved upon.  I'm thinking about writing an XML
header on the entries file to enable it to be used to restart the
program.  We need to verify the file size, but if we know the formats,
then we know the (uncompressed) file sizes, so that shouldn't be too
hard.

Restarting in the middle of a pass requires using a partially
constructed entries file, which seems dicey.  Better, I think, would
be to back up and start by reruning the pass that generated the last
complete entries file, but with no input proptables, so it just
generates a new set of output proptables.


- Hadoop port

Apache Hadoop is currently (2012) the state of the art for cluster
computing.  To exploit Hadoop-type parallelism, we should allow for
partial entries files that contain only a sub-range of indices.  A
single program invocation applies a set of proptables to a partial
entries file and produces an output partial entries file, along with
output proptables segmented into sub-ranges.  Then the output
proptables get shuffled around between the compute nodes before the
next pass.


- add 'dtr' format

The distance to mate (dtm) metric that we use is the simplest but
maybe not the best.  Distance to conversion (dtc) tracks (basically)
how far until the next futurebase, and distance to rule (dtr)
incorporates the 50-move rule into the calculation.


- be more consistent about current tablebase being a global var


- check indexing logic with an automated theorem prover

I've had a lot of bugs in the indexing logic, especially since there
are two different routines for each index type that need to be kept in
sync.  If we optimize the case where the index number is advanced by
one (see above), then we'll have a third routine to keep in sync.  Can
we use an automated theorem prover like Prover9 to ensure that this
code is right?


- stalemate pruning

This idea is to speed up processing by allowing promotion futurebases
with only queens to substitute for promotions into rooks and bishops,
since the only logical reason to underpromote is to avoid a stalemate.
To this end, a futurebase with an extra queen and stalemates pruned
would be treated as handling all three promotions (queen, rook, and
bishop).  To implement this correctly, you'd have to make sure that
stalemates were pruned not only in the current tablebase, but in all
(and I mean ALL) futurebases.  So this would mean adding an element to
tablebase-statistics, <all-stalemates-pruned color="white|black"/>,
that would flag when all futurebases depending on it had their
stalemates pruned as well.  This element would back propagate through
the futurebases and be dropped at any point where stalemate pruning
was turned off (unless there were no stalemates, like kk.htb).  In any
event, I've got the code to group all three promotions together in
RCS, but I've ripped it out of the main line since this extra logic
has never been implemented.


- more sophisticated futurebase handling

A current research target is to generate a full set of tablebases to
handle all king-and-pawn endgames, at least up to a queening solution.
We'd like to compute "white to queen and draw", which means that we
only treat a promotion move as a win if we've already got a forced
draw from that position.  So, we need to compute a drawing analysis,
then augment that into a queening analysis.  This can currently be
done with multiple files, but it would be better to have a single file
with multiple bit flags for each position.


- restrict range of indices we look at during a backprop

If we're backproping, say, from kqk into kpk, we need only consider
those positions where the queen is on the eighth rank.  If the queen
is encoded into the MSBs of the index, then we should be able to
figure out at what futurebase index we need to start processing, and
fast forward to that point.  Symmetry might disrupt this, but the
general idea might still work, especially if it was done in a general
enough fashion, maybe by constructing a bitboard of legal board
positions for each piece at the beginning of a backprop (of any kind)
and fast forwarding over chunks of the futurebase that have been
identified as irrelevant.  The index-ordering=reverse attribute was
created to facilitate this, but it's never been implemented.


- add a repeat option for processing multiple XML files

If we're doing distributed batch processing, we'd probably like to
provide a URL to the program to get a generation control file (this
already works), then retry that URL when we're all done to get another
control file, and keep doing this.  Have to make sure the program is
pretty clean in its memory usage for this to work well.  Also should
provide some way to terminate the program at the end of the current
tablebase build.


- prune after some number of passes

If we're looking to trade some accuracy for speed, we can prune at
almost any point in the calculation by conceding every position that
hasn't been resolved.  So, for example, if we anticipate that allowing
black to queen will lose the game, except that we still want to
consider the possibility of immediately capturing the new queen
(Freezer can do this), we can run for one or two passes and then prune
everything else.  Note that in this example, we can already achieve
almost the same result by freezing the queen on the queening square
and conceding any move by the queen as a win to black.  We'd probably
run for several passes, though, checking lines where white can check
black around for a few moves before taking the queen.  Could also be
used to create faster test cases.


- some kind of GUI

I like leaving hoffman as a standalone computation engine.  For one
thing, this makes it easier to compile on a minimal system where
you're not going to do anything except farm out tablebase
calculations.  So my current thought for a GUI would be either a
Perl/Tk script or a Java applet, and I think Java is much cleaner than
Perl.  Freezer seems to have a nice GUI for a tablebase generator; see
the demos on http://www.freezerchess.com/

Even the computation engine could use a GUI, though, especially on
Microsoft systems where it's the standard user interface.  A modal
startup sequence could begin with radio buttons to select either a
file chooser to pick a control file (or files) for processing, or a
URL to connect to a remote webserver and retrieve control files from
there.  An options panel could allow selecting the maximum amount of
RAM to use, along with the location of a temporary files directory and
the maximum amount of disk space to use.  Use of proptable mode would
then be automatic depending on how much RAM is available.  It should
be possible to change these settings while the program is running.
Once the analysis proper starts, you should be able to halt or pause
it, as well as iconize it while it continues to run.


- 'freeze' pruning type

Add 'freeze' pruning type for promotions - promote and freeze new
piece on the promotion square.  This lets us queen a pawn and then let
it sit there on the queening square to ensure that the other side
can't either capture it immediately or queen right after us.

This would basically require a new piece type - a pawn on ranks 2-7,
and a queen+knight on rank 8 that wouldn't move, but if it had any
possible move, that would be a prune.

Not sure about this feature.  Complicated, error prone, and with only
slight improvement in program accuracy.


- improve probe mode's move parser

Check illegal moves more aggressively; have a 'back' command.


- random access to tablebase files

Would require a modified gzip format.  Nalimov used a variant of
Lempel-Ziv developed by Andrew Kadatch; I'm not sure how it works.
Maybe preprocess the file to develop a single, constant Huffman table
and store it at the beginning of the file along with a table of byte
offsets that can be binary searched to figure where in the file you
need to start decompressing.  Other people have looked at this; a
literature search seems to be in order.


- eliminate extra proptable passes

We don't generate any output proptables when initializing the entries
table, then make our first intratable pass without any input
proptables.  Also, the final tablebase generation doesn't modify the
entries table at all, so there's no need to re-write it to disk, with
the corresponding slow encryption.


- revisit all the XXXs

- check stalemate handling in general

- print warning if a prune statement doesn't do anything
  (like "Pe4"  if P isn't restricted)

- autocompute output filename

- eliminate color='invert' futurebase attribute

- "Couldn't find future piece in local tablebase" - should this be a warning, not an error?

- when probing, don't print prunes as "NO DATA"

- replace BITVECTOR with vector<bool> (or something like that)

- error during generation:

../hoffman -t 4 -g carlsen_anand_2014_krk-0-0.xml
Hoffman Version 1033
terminate called after throwing an instance of 'std::runtime_error'
  what():  Pawngen not allowed with symmetric indices (yet)

- control size of DTM field in entries table by setting size of DTM field in XML format

- look at r1045a.xml and figure how to print its results better

- pawngen generation can take a while.  Multi-thread it?
